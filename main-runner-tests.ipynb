{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8bb70c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING DIRECTIONAL CALL SCALPER FOR 20-11-2025 ---\n",
      "1. Downloading Futures: year=2025/month=11/day=20/Futures/NIFTY/NIFTY25NOVFUT.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/696557002.py:76: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Generating Kinetic Signals...\n",
      "   Generated 18 trades.\n",
      "Target Expiry: 25D02\n",
      "3. Downloading Options for Strikes: [26150, 26100, 26200, 26250]\n",
      "\n",
      "4. Running Directional Call Simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/696557002.py:233: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/696557002.py:233: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 318\u001b[0m\n\u001b[1;32m    315\u001b[0m     run_directional_engine(trades_csv, opt_map)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 318\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 315\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m opt_map \u001b[38;5;241m=\u001b[39m download_specific_options(YEAR, MONTH, DAY, SYMBOL, expiry_code, needed_strikes)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# E. Run Engine\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m \u001b[43mrun_directional_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrades_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[49], line 233\u001b[0m, in \u001b[0;36mrun_directional_engine\u001b[0;34m(trades_csv, option_map)\u001b[0m\n\u001b[1;32m    231\u001b[0m ce_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(ce_path)\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ce_df\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m--> 233\u001b[0m      ce_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mce_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mce_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m ce_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastTradedPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ce_df\u001b[38;5;241m.\u001b[39mcolumns: ce_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLTP\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ce_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLastTradedPrice\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from collections import deque\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "DAY = 20\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # Trading symbol of futures on that date\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "RISK_FREE_RATE = 0.0          \n",
    "\n",
    "# COST PARAMETERS (REALISTIC)\n",
    "# We only pay this ONCE per trade now (Single Leg), not twice (Straddle)\n",
    "OPTION_ENTRY_SPREAD = 2.0    \n",
    "OPTION_EXIT_SPREAD = 2.0  \n",
    "OPTION_ENTRY_SLIPPAGE = 1.0  \n",
    "OPTION_EXIT_SLIPPAGE = 1.0\n",
    "\n",
    "# Total costs per leg\n",
    "ENTRY_COST_PER_LEG = OPTION_ENTRY_SPREAD + OPTION_ENTRY_SLIPPAGE  # 3 pts\n",
    "EXIT_COST_PER_LEG = OPTION_EXIT_SPREAD + OPTION_EXIT_SLIPPAGE     # 3 pts\n",
    "\n",
    "BASE_FOLDER = f\"data/{YEAR}-{MONTH:02d}-{DAY:02d}/\"\n",
    "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"--- RUNNING DIRECTIONAL CALL SCALPER FOR {DAY}-{MONTH}-{YEAR} ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation: kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]: keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"): continuation = resp.get(\"NextContinuationToken\")\n",
    "        else: break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return # Skip if already exists\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(obj[\"Body\"].read())\n",
    "\n",
    "# ==========================================\n",
    "# 3. FUTURES & KINETIC LOGIC\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(BASE_FOLDER, \"FUT.parquet\")\n",
    "    print(f\"1. Downloading Futures: {key}\")\n",
    "    download_parquet_to_path(key, local_path)\n",
    "    \n",
    "    # Convert to CSV for easier processing logic\n",
    "    df = pd.read_parquet(local_path)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # Handle Volume vs OpenInterest naming variations\n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(BASE_FOLDER, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.buf = deque(maxlen=50)\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "\n",
    "    def tick(self, ts, ltp, vol):\n",
    "        self.buf.append((ltp, vol))\n",
    "        if len(self.buf) < 50: return 0\n",
    "\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1 # EXIT\n",
    "            return 0 # HOLD\n",
    "\n",
    "        arr = np.array(self.buf)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        disp = abs(prices[-1] - prices[0])\n",
    "        score = traded_vol / (disp + 0.05)\n",
    "\n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = ts\n",
    "            return 1 # ENTER\n",
    "\n",
    "        return 0\n",
    "\n",
    "def build_kinetic_trades(fut_csv):\n",
    "    print(\"2. Generating Kinetic Signals...\")\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = KineticBrain()\n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        sig = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        if sig == 1:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                # FIX: ATM Strike determined at ENTRY, not Average\n",
    "                \"ATM_Strike\": round(ltp / 50.0) * 50\n",
    "            }\n",
    "        elif sig == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(BASE_FOLDER, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    print(f\"   Generated {len(trades_df)} trades.\")\n",
    "    return out_path\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPIRY & OPTION DOWNLOAD LOGIC\n",
    "# ==========================================\n",
    "month_map = {\"JAN\":1,\"FEB\":2,\"MAR\":3,\"APR\":4,\"MAY\":5,\"JUN\":6,\"JUL\":7,\"AUG\":8,\"SEP\":9,\"OCT\":10,\"NOV\":11,\"DEC\":12}\n",
    "\n",
    "def get_expiry_date_obj(code, ref_date):\n",
    "    \"\"\"Converts code like '25NOV' to datetime object\"\"\"\n",
    "    y = 2000 + int(code[:2])\n",
    "    tail = code[2:]\n",
    "    if tail in month_map:\n",
    "        return datetime.datetime(y, month_map[tail], 28) \n",
    "    return datetime.datetime(2025, 11, 27) \n",
    "\n",
    "def find_nearest_expiry(year, month, day, symbol):\n",
    "    # Simplified S3 lookup\n",
    "    base_prefix = f\"year={year}/month={month:02d}/day={day:02d}/Options/{symbol}/\"\n",
    "    keys = list_s3(base_prefix)\n",
    "    expiries = set()\n",
    "    for k in keys:\n",
    "        try:\n",
    "            # key: .../Options/NIFTY/25NOV/CE...\n",
    "            suffix = k.split(base_prefix, 1)[1]\n",
    "            part = suffix.split(\"/\", 1)[0]\n",
    "            expiries.add(part)\n",
    "        except: continue\n",
    "    \n",
    "    if not expiries: raise Exception(\"No Expiries Found\")\n",
    "    return sorted(list(expiries))[0]\n",
    "\n",
    "def download_specific_options(year, month, day, symbol, expiry_code, strikes):\n",
    "    print(f\"3. Downloading Options for Strikes: {strikes}\")\n",
    "    local_map = {} # (Strike, Type) -> Path\n",
    "    \n",
    "    base_prefix = f\"year={year}/month={month:02d}/day={day:02d}/Options/{symbol}/{expiry_code}/\"\n",
    "    \n",
    "    for strike in strikes:\n",
    "        # STRATEGY CHANGE: We only download CE (Call) for Directional Long\n",
    "        for opt_type in [\"CE\"]:\n",
    "            key = f\"{base_prefix}{opt_type}/{strike}/{symbol}{expiry_code}{strike}{opt_type}.parquet\"\n",
    "            local_name = f\"{symbol}{expiry_code}{strike}{opt_type}.parquet\"\n",
    "            local_path = os.path.join(BASE_FOLDER, local_name)\n",
    "            \n",
    "            try:\n",
    "                download_parquet_to_path(key, local_path)\n",
    "                local_map[(strike, opt_type)] = local_path\n",
    "            except Exception:\n",
    "                print(f\"   MISSING: {key}\")\n",
    "                \n",
    "    return local_map\n",
    "\n",
    "# ==========================================\n",
    "# 5. DIRECTIONAL SCALPER ENGINE\n",
    "# ==========================================\n",
    "def run_directional_engine(trades_csv, option_map):\n",
    "    print(\"\\n4. Running Directional Call Simulation...\")\n",
    "    \n",
    "    trades_df = pd.read_csv(trades_csv)\n",
    "    trades_df['Entry_Time'] = pd.to_datetime(trades_df['Entry_Time'])\n",
    "    trades_df['Exit_Time'] = pd.to_datetime(trades_df['Exit_Time'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, row in trades_df.iterrows():\n",
    "        entry_ts = row['Entry_Time']\n",
    "        exit_ts = row['Exit_Time']\n",
    "        K = int(row['ATM_Strike'])\n",
    "        \n",
    "        # We only need the CE file\n",
    "        ce_path = option_map.get((K, 'CE'))\n",
    "        if not ce_path:\n",
    "            print(f\"   Skip Trade {i}: Missing CE file for Strike {K}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            ce_df = pd.read_parquet(ce_path)\n",
    "            if \"DateTime\" not in ce_df.columns:\n",
    "                 ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
    "            ce_df.set_index(\"DateTime\", inplace=True)\n",
    "            if \"LastTradedPrice\" in ce_df.columns: ce_df[\"LTP\"] = ce_df[\"LastTradedPrice\"]\n",
    "            ce_df = ce_df.sort_index()\n",
    "        except Exception as e:\n",
    "            print(f\"   Error reading parquet: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Get Precise Entry/Exit Prices\n",
    "        # We use 'searchsorted' logic implicitly via reindex or nearest lookup\n",
    "        # But slicing is safer to see if data exists\n",
    "        \n",
    "        trade_data = ce_df.loc[entry_ts:exit_ts]\n",
    "        if trade_data.empty:\n",
    "            continue\n",
    "            \n",
    "        # ENTRY LOGIC\n",
    "        # We assume we enter exactly at signal time (or next available tick)\n",
    "        # Realistically: Ask Price + Slippage\n",
    "        # Approximation: LTP + Entry Cost\n",
    "        entry_price_raw = trade_data.iloc[0]['LTP']\n",
    "        entry_price_net = entry_price_raw + ENTRY_COST_PER_LEG\n",
    "        \n",
    "        # EXIT LOGIC\n",
    "        # We exit at signal time\n",
    "        # Realistically: Bid Price - Slippage\n",
    "        # Approximation: LTP - Exit Cost\n",
    "        exit_price_raw = trade_data.iloc[-1]['LTP']\n",
    "        exit_price_net = exit_price_raw - EXIT_COST_PER_LEG\n",
    "        \n",
    "        # PnL Calculation\n",
    "        pnl_points = exit_price_net - entry_price_net\n",
    "        \n",
    "        results.append({\n",
    "            \"Entry_Time\": entry_ts,\n",
    "            \"Exit_Time\": exit_ts,\n",
    "            \"Strike\": K,\n",
    "            \"CE_Entry_Raw\": entry_price_raw,\n",
    "            \"CE_Exit_Raw\": exit_price_raw,\n",
    "            \"PnL_Points\": pnl_points,\n",
    "            \"PnL_INR\": pnl_points * LOT_SIZE\n",
    "        })\n",
    "\n",
    "    # Save Results\n",
    "    res_df = pd.DataFrame(results)\n",
    "    final_csv = os.path.join(BASE_FOLDER, \"directional_scalping_results.csv\")\n",
    "    res_df.to_csv(final_csv, index=False)\n",
    "    \n",
    "    print(\"\\n--- RESULTS ---\")\n",
    "    print(f\"Total Trades: {len(res_df)}\")\n",
    "    if not res_df.empty:\n",
    "        print(f\"Total Net PnL: â‚¹{res_df['PnL_INR'].sum():,.2f}\")\n",
    "        print(f\"Win Rate: {(res_df['PnL_Points'] > 0).mean()*100:.1f}%\")\n",
    "        print(f\"Avg PnL per Trade: â‚¹{res_df['PnL_INR'].mean():,.2f}\")\n",
    "    else:\n",
    "        print(\"No valid trades found.\")\n",
    "    print(f\"Saved to: {final_csv}\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    # A. Get Futures\n",
    "    fut_csv = download_futures_for_day(YEAR, MONTH, DAY, SYMBOL, FUT_TS)\n",
    "    \n",
    "    # B. Generate Signals\n",
    "    trades_csv = build_kinetic_trades(fut_csv)\n",
    "    \n",
    "    # C. Identify Needed Options\n",
    "    trades_df = pd.read_csv(trades_csv)\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades generated.\")\n",
    "        return\n",
    "        \n",
    "    needed_strikes = trades_df[\"ATM_Strike\"].unique().astype(int).tolist()\n",
    "    expiry_code = find_nearest_expiry(YEAR, MONTH, DAY, SYMBOL)\n",
    "    print(f\"Target Expiry: {expiry_code}\")\n",
    "    \n",
    "    # D. Get Options (ONLY CE)\n",
    "    opt_map = download_specific_options(YEAR, MONTH, DAY, SYMBOL, expiry_code, needed_strikes)\n",
    "    \n",
    "    # E. Run Engine\n",
    "    run_directional_engine(trades_csv, opt_map)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff23efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING DEEP ITM CALL SCALPER (DELTA ~0.85) FOR 20-11-2025 ---\n",
      "1. Downloading Futures: year=2025/month=11/day=20/Futures/NIFTY/NIFTY25NOVFUT.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:77: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Generating Kinetic Signals...\n",
      "   Generated 18 trades.\n",
      "\n",
      "--- CONTROL GROUP: RAW FUTURES PERFORMANCE ---\n",
      "Trades: 18\n",
      "Avg Underlying Move: 4.16 pts\n",
      "Total Net PnL (Futures): â‚¹4,260.00\n",
      "Win Rate: 66.7%\n",
      "----------------------------------------------\n",
      "âœ… DIAGNOSIS: The FUTURES signal made money!\n",
      "   If Options lost money, the spread/theta cost is too high.\n",
      "Target Expiry: 25D02\n",
      "3. Downloading Options for Strikes: [25950, 25900, 26000, 26050]\n",
      "\n",
      "4. Running Directional Call Simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- OPTION RESULTS ---\n",
      "Total Trades: 18\n",
      "Total Net PnL: â‚¹-4,522.50\n",
      "Win Rate: 50.0%\n",
      "Avg PnL per Trade: â‚¹-251.25\n",
      "Saved to: data/2025-11-20/directional_scalping_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
      "/var/folders/4r/hrxj1wmn5pz2tdgcm9ppqckh0000gn/T/ipykernel_47008/2614609573.py:273: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S.%f format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from collections import deque\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "DAY = 20\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # Trading symbol of futures on that date\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "RISK_FREE_RATE = 0.0          \n",
    "\n",
    "# COST PARAMETERS (REALISTIC)\n",
    "# We only pay this ONCE per trade now (Single Leg), not twice (Straddle)\n",
    "OPTION_ENTRY_SPREAD = 2.0    \n",
    "OPTION_EXIT_SPREAD = 2.0  \n",
    "OPTION_ENTRY_SLIPPAGE = 1.0  \n",
    "OPTION_EXIT_SLIPPAGE = 1.0\n",
    "FUTURES_SLIPPAGE = 0.5       # Per contract per side (Total 1.0 round trip)\n",
    "\n",
    "# Total costs per leg\n",
    "ENTRY_COST_PER_LEG = OPTION_ENTRY_SPREAD + OPTION_ENTRY_SLIPPAGE  # 3 pts\n",
    "EXIT_COST_PER_LEG = OPTION_EXIT_SPREAD + OPTION_EXIT_SLIPPAGE     # 3 pts\n",
    "\n",
    "BASE_FOLDER = f\"data/{YEAR}-{MONTH:02d}-{DAY:02d}/\"\n",
    "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"--- RUNNING DEEP ITM CALL SCALPER (DELTA ~0.85) FOR {DAY}-{MONTH}-{YEAR} ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation: kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]: keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"): continuation = resp.get(\"NextContinuationToken\")\n",
    "        else: break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return # Skip if already exists\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(obj[\"Body\"].read())\n",
    "\n",
    "# ==========================================\n",
    "# 3. FUTURES & KINETIC LOGIC\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(BASE_FOLDER, \"FUT.parquet\")\n",
    "    print(f\"1. Downloading Futures: {key}\")\n",
    "    download_parquet_to_path(key, local_path)\n",
    "    \n",
    "    # Convert to CSV for easier processing logic\n",
    "    df = pd.read_parquet(local_path)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), errors=\"coerce\")\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # Handle Volume vs OpenInterest naming variations\n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(BASE_FOLDER, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.buf = deque(maxlen=50)\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "\n",
    "    def tick(self, ts, ltp, vol):\n",
    "        self.buf.append((ltp, vol))\n",
    "        if len(self.buf) < 50: return 0\n",
    "\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1 # EXIT\n",
    "            return 0 # HOLD\n",
    "\n",
    "        arr = np.array(self.buf)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        disp = abs(prices[-1] - prices[0])\n",
    "        score = traded_vol / (disp + 0.05)\n",
    "\n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = ts\n",
    "            return 1 # ENTER\n",
    "\n",
    "        return 0\n",
    "\n",
    "def build_kinetic_trades(fut_csv):\n",
    "    print(\"2. Generating Kinetic Signals...\")\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = KineticBrain()\n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        sig = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        if sig == 1:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                # FIX: SELECT DEEP ITM STRIKE (LTP - 200)\n",
    "                # This gives us Delta ~0.85 to capture more of the move\n",
    "                \"ATM_Strike\": (round(ltp / 50.0) * 50) - 200\n",
    "            }\n",
    "        elif sig == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(BASE_FOLDER, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    print(f\"   Generated {len(trades_df)} trades.\")\n",
    "    return out_path\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXPIRY & OPTION DOWNLOAD LOGIC\n",
    "# ==========================================\n",
    "month_map = {\"JAN\":1,\"FEB\":2,\"MAR\":3,\"APR\":4,\"MAY\":5,\"JUN\":6,\"JUL\":7,\"AUG\":8,\"SEP\":9,\"OCT\":10,\"NOV\":11,\"DEC\":12}\n",
    "\n",
    "def get_expiry_date_obj(code, ref_date):\n",
    "    \"\"\"Converts code like '25NOV' to datetime object\"\"\"\n",
    "    y = 2000 + int(code[:2])\n",
    "    tail = code[2:]\n",
    "    if tail in month_map:\n",
    "        return datetime.datetime(y, month_map[tail], 28) \n",
    "    return datetime.datetime(2025, 11, 27) \n",
    "\n",
    "def find_nearest_expiry(year, month, day, symbol):\n",
    "    # Simplified S3 lookup\n",
    "    base_prefix = f\"year={year}/month={month:02d}/day={day:02d}/Options/{symbol}/\"\n",
    "    keys = list_s3(base_prefix)\n",
    "    expiries = set()\n",
    "    for k in keys:\n",
    "        try:\n",
    "            # key: .../Options/NIFTY/25NOV/CE...\n",
    "            suffix = k.split(base_prefix, 1)[1]\n",
    "            part = suffix.split(\"/\", 1)[0]\n",
    "            expiries.add(part)\n",
    "        except: continue\n",
    "    \n",
    "    if not expiries: raise Exception(\"No Expiries Found\")\n",
    "    return sorted(list(expiries))[0]\n",
    "\n",
    "def download_specific_options(year, month, day, symbol, expiry_code, strikes):\n",
    "    print(f\"3. Downloading Options for Strikes: {strikes}\")\n",
    "    local_map = {} # (Strike, Type) -> Path\n",
    "    \n",
    "    base_prefix = f\"year={year}/month={month:02d}/day={day:02d}/Options/{symbol}/{expiry_code}/\"\n",
    "    \n",
    "    for strike in strikes:\n",
    "        # STRATEGY CHANGE: We only download CE (Call) for Directional Long\n",
    "        for opt_type in [\"CE\"]:\n",
    "            key = f\"{base_prefix}{opt_type}/{strike}/{symbol}{expiry_code}{strike}{opt_type}.parquet\"\n",
    "            local_name = f\"{symbol}{expiry_code}{strike}{opt_type}.parquet\"\n",
    "            local_path = os.path.join(BASE_FOLDER, local_name)\n",
    "            \n",
    "            try:\n",
    "                download_parquet_to_path(key, local_path)\n",
    "                local_map[(strike, opt_type)] = local_path\n",
    "            except Exception:\n",
    "                print(f\"   MISSING: {key}\")\n",
    "                \n",
    "    return local_map\n",
    "\n",
    "# ==========================================\n",
    "# 5. CONTROL GROUP: FUTURES BENCHMARK\n",
    "# ==========================================\n",
    "def run_futures_benchmark(trades_csv):\n",
    "    print(\"\\n--- CONTROL GROUP: RAW FUTURES PERFORMANCE ---\")\n",
    "    df = pd.read_csv(trades_csv)\n",
    "    if df.empty:\n",
    "        print(\"No trades found.\")\n",
    "        return\n",
    "\n",
    "    # Raw Move: Exit - Entry\n",
    "    df['Raw_Pts'] = df['Exit_LTP'] - df['Entry_LTP']\n",
    "    \n",
    "    # Futures Costs: Entry Slippage + Exit Slippage (1.0 Total)\n",
    "    # Brokerage is negligible compared to this, but let's assume 0.5 total extra\n",
    "    TOTAL_FUT_COST = FUTURES_SLIPPAGE + FUTURES_SLIPPAGE \n",
    "    \n",
    "    df['Net_Pts'] = df['Raw_Pts'] - TOTAL_FUT_COST\n",
    "    df['Net_INR'] = df['Net_Pts'] * LOT_SIZE\n",
    "    \n",
    "    total_pnl = df['Net_INR'].sum()\n",
    "    win_rate = (df['Net_Pts'] > 0).mean() * 100\n",
    "    avg_move = df['Raw_Pts'].mean()\n",
    "    \n",
    "    print(f\"Trades: {len(df)}\")\n",
    "    print(f\"Avg Underlying Move: {avg_move:.2f} pts\")\n",
    "    print(f\"Total Net PnL (Futures): â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate: {win_rate:.1f}%\")\n",
    "    print(\"----------------------------------------------\")\n",
    "    \n",
    "    if total_pnl < 0:\n",
    "        print(\"ðŸš¨ DIAGNOSIS: The FUTURES signal itself lost money today.\")\n",
    "        print(\"   This means the 'Kinetic Brain' failed to predict direction on this day.\")\n",
    "        print(\"   Options math cannot fix a bad underlying signal.\")\n",
    "    else:\n",
    "        print(\"âœ… DIAGNOSIS: The FUTURES signal made money!\")\n",
    "        print(\"   If Options lost money, the spread/theta cost is too high.\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. DIRECTIONAL SCALPER ENGINE\n",
    "# ==========================================\n",
    "def run_directional_engine(trades_csv, option_map):\n",
    "    print(\"\\n4. Running Directional Call Simulation...\")\n",
    "    \n",
    "    trades_df = pd.read_csv(trades_csv)\n",
    "    trades_df['Entry_Time'] = pd.to_datetime(trades_df['Entry_Time'])\n",
    "    trades_df['Exit_Time'] = pd.to_datetime(trades_df['Exit_Time'])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, row in trades_df.iterrows():\n",
    "        entry_ts = row['Entry_Time']\n",
    "        exit_ts = row['Exit_Time']\n",
    "        K = int(row['ATM_Strike'])\n",
    "        \n",
    "        # We only need the CE file\n",
    "        ce_path = option_map.get((K, 'CE'))\n",
    "        if not ce_path:\n",
    "            # print(f\"   Skip Trade {i}: Missing CE file for Strike {K}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            ce_df = pd.read_parquet(ce_path)\n",
    "            if \"DateTime\" not in ce_df.columns:\n",
    "                ce_df[\"DateTime\"] = pd.to_datetime(ce_df[\"Date\"].astype(str) + \" \" + ce_df[\"Time\"].astype(str))\n",
    "            ce_df.set_index(\"DateTime\", inplace=True)\n",
    "            if \"LastTradedPrice\" in ce_df.columns: ce_df[\"LTP\"] = ce_df[\"LastTradedPrice\"]\n",
    "            ce_df = ce_df.sort_index()\n",
    "        except Exception as e:\n",
    "            print(f\"   Error reading parquet: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Get Precise Entry/Exit Prices\n",
    "        trade_data = ce_df.loc[entry_ts:exit_ts]\n",
    "        if trade_data.empty:\n",
    "            continue\n",
    "            \n",
    "        # ENTRY LOGIC (Price + Cost)\n",
    "        entry_price_raw = trade_data.iloc[0]['LTP']\n",
    "        entry_price_net = entry_price_raw + ENTRY_COST_PER_LEG\n",
    "        \n",
    "        # EXIT LOGIC (Price - Cost)\n",
    "        exit_price_raw = trade_data.iloc[-1]['LTP']\n",
    "        exit_price_net = exit_price_raw - EXIT_COST_PER_LEG\n",
    "        \n",
    "        # PnL Calculation\n",
    "        pnl_points = exit_price_net - entry_price_net\n",
    "        \n",
    "        results.append({\n",
    "            \"Entry_Time\": entry_ts,\n",
    "            \"Exit_Time\": exit_ts,\n",
    "            \"Strike\": K,\n",
    "            \"CE_Entry_Raw\": entry_price_raw,\n",
    "            \"CE_Exit_Raw\": exit_price_raw,\n",
    "            \"PnL_Points\": pnl_points,\n",
    "            \"PnL_INR\": pnl_points * LOT_SIZE\n",
    "        })\n",
    "\n",
    "    # Save Results\n",
    "    res_df = pd.DataFrame(results)\n",
    "    final_csv = os.path.join(BASE_FOLDER, \"directional_scalping_results.csv\")\n",
    "    res_df.to_csv(final_csv, index=False)\n",
    "    \n",
    "    print(\"\\n--- OPTION RESULTS ---\")\n",
    "    print(f\"Total Trades: {len(res_df)}\")\n",
    "    if not res_df.empty:\n",
    "        print(f\"Total Net PnL: â‚¹{res_df['PnL_INR'].sum():,.2f}\")\n",
    "        print(f\"Win Rate: {(res_df['PnL_Points'] > 0).mean()*100:.1f}%\")\n",
    "        print(f\"Avg PnL per Trade: â‚¹{res_df['PnL_INR'].mean():,.2f}\")\n",
    "    else:\n",
    "        print(\"No valid trades found.\")\n",
    "    print(f\"Saved to: {final_csv}\")\n",
    "\n",
    "# ==========================================\n",
    "# 7. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    # A. Get Futures\n",
    "    fut_csv = download_futures_for_day(YEAR, MONTH, DAY, SYMBOL, FUT_TS)\n",
    "    \n",
    "    # B. Generate Signals\n",
    "    trades_csv = build_kinetic_trades(fut_csv)\n",
    "    \n",
    "    # C. RUN FUTURES BENCHMARK (The Truth Serum)\n",
    "    run_futures_benchmark(trades_csv)\n",
    "    \n",
    "    # D. Identify Needed Options\n",
    "    trades_df = pd.read_csv(trades_csv)\n",
    "    if trades_df.empty:\n",
    "        print(\"No trades generated.\")\n",
    "        return\n",
    "        \n",
    "    needed_strikes = trades_df[\"ATM_Strike\"].unique().astype(int).tolist()\n",
    "    expiry_code = find_nearest_expiry(YEAR, MONTH, DAY, SYMBOL)\n",
    "    print(f\"Target Expiry: {expiry_code}\")\n",
    "    \n",
    "    # E. Get Options (ONLY CE)\n",
    "    opt_map = download_specific_options(YEAR, MONTH, DAY, SYMBOL, expiry_code, needed_strikes)\n",
    "    \n",
    "    # F. Run Engine\n",
    "    run_directional_engine(trades_csv, opt_map)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf18f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING LONG/SHORT FUTURES SCALPER FOR 24-11-2025 ---\n",
      "1. Downloading Futures: year=2025/month=11/day=24/Futures/NIFTY/NIFTY25NOVFUT.parquet\n",
      "2. Generating Kinetic Signals...\n",
      "   Generated 17 trades.\n",
      "\n",
      "3. Running Pure Futures Simulation...\n",
      "\n",
      "--- FUTURES RESULTS ---\n",
      "Total Trades:       17\n",
      "Total Net PnL:      â‚¹1,215.00\n",
      "Win Rate:           64.7%\n",
      "Avg Net PnL:        0.95 pts\n",
      "------------------------------\n",
      "Longs: 4 | PnL: â‚¹-4,057.50\n",
      "Shorts: 13 | PnL: â‚¹5,272.50\n",
      "Saved to:           data/2025-11-24/futures_scalping_results.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "DAY = 24\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # Trading symbol of futures on that date\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "RISK_FREE_RATE = 0.0          \n",
    "\n",
    "# COST PARAMETERS (FUTURES ONLY)\n",
    "# Nifty Futures typically have very low spread (0.05-0.10). \n",
    "# We assume 1.0 point TOTAL round-trip cost (Slippage + Brokerage + Taxes)\n",
    "# This is a realistic conservative estimate for scalping.\n",
    "FUTURES_ROUND_TRIP_COST = 1.0 \n",
    "\n",
    "BASE_FOLDER = f\"data/{YEAR}-{MONTH:02d}-{DAY:02d}/\"\n",
    "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"--- RUNNING LONG/SHORT FUTURES SCALPER FOR {DAY}-{MONTH}-{YEAR} ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation: kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]: keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"): continuation = resp.get(\"NextContinuationToken\")\n",
    "        else: break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return # Skip if already exists\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(obj[\"Body\"].read())\n",
    "\n",
    "# ==========================================\n",
    "# 3. FUTURES & KINETIC LOGIC\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(BASE_FOLDER, \"FUT.parquet\")\n",
    "    print(f\"1. Downloading Futures: {key}\")\n",
    "    download_parquet_to_path(key, local_path)\n",
    "    \n",
    "    # Convert to CSV for easier processing logic\n",
    "    df = pd.read_parquet(local_path)\n",
    "    # Fix Date Parsing Warning by enforcing format or dayfirst\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), \n",
    "        dayfirst=True, \n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # Handle Volume vs OpenInterest naming variations\n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(BASE_FOLDER, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.buf = deque(maxlen=50)\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "\n",
    "    def tick(self, ts, ltp, vol):\n",
    "        self.buf.append((ltp, vol))\n",
    "        if len(self.buf) < 50: return 0\n",
    "\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1 # EXIT\n",
    "            return 0 # HOLD\n",
    "\n",
    "        arr = np.array(self.buf)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        disp = abs(prices[-1] - prices[0])\n",
    "        score = traded_vol / (disp + 0.05)\n",
    "\n",
    "        # DIRECTIONAL LOGIC ADDED:\n",
    "        # Check if the price trend in the buffer is UP or DOWN\n",
    "        price_change = prices[-1] - prices[0]\n",
    "\n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = ts\n",
    "            \n",
    "            # Determine Direction\n",
    "            if price_change > 0:\n",
    "                return 1 # LONG SIGNAL\n",
    "            else:\n",
    "                return 2 # SHORT SIGNAL\n",
    "\n",
    "        return 0\n",
    "\n",
    "def build_kinetic_trades(fut_csv):\n",
    "    print(\"2. Generating Kinetic Signals...\")\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = KineticBrain()\n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        sig = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        # START TRADE\n",
    "        if sig == 1 or sig == 2:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                \"Side\": \"LONG\" if sig == 1 else \"SHORT\"\n",
    "            }\n",
    "        \n",
    "        # END TRADE\n",
    "        elif sig == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(BASE_FOLDER, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    print(f\"   Generated {len(trades_df)} trades.\")\n",
    "    return out_path\n",
    "\n",
    "# ==========================================\n",
    "# 4. FUTURES SIMULATION ENGINE\n",
    "# ==========================================\n",
    "def run_futures_simulation(trades_csv):\n",
    "    print(\"\\n3. Running Pure Futures Simulation...\")\n",
    "    df = pd.read_csv(trades_csv)\n",
    "    if df.empty:\n",
    "        print(\"No trades found.\")\n",
    "        return\n",
    "\n",
    "    # CALCULATE PNL BASED ON DIRECTION\n",
    "    # Long: Exit - Entry\n",
    "    # Short: Entry - Exit\n",
    "    df['Raw_Pts'] = np.where(\n",
    "        df['Side'] == 'LONG', \n",
    "        df['Exit_LTP'] - df['Entry_LTP'], \n",
    "        df['Entry_LTP'] - df['Exit_LTP']\n",
    "    )\n",
    "    \n",
    "    # Futures Costs: Fixed per round trip (Slippage + Comm)\n",
    "    df['Net_Pts'] = df['Raw_Pts'] - FUTURES_ROUND_TRIP_COST\n",
    "    df['Net_INR'] = df['Net_Pts'] * LOT_SIZE\n",
    "    \n",
    "    total_pnl = df['Net_INR'].sum()\n",
    "    win_rate = (df['Net_Pts'] > 0).mean() * 100\n",
    "    avg_raw = df['Raw_Pts'].mean()\n",
    "    avg_net = df['Net_Pts'].mean()\n",
    "    \n",
    "    # Breakdown Long vs Short\n",
    "    longs = df[df['Side'] == 'LONG']\n",
    "    shorts = df[df['Side'] == 'SHORT']\n",
    "    \n",
    "    # Save Results\n",
    "    final_csv = os.path.join(BASE_FOLDER, \"futures_scalping_results.csv\")\n",
    "    df.to_csv(final_csv, index=False)\n",
    "    \n",
    "    print(\"\\n--- FUTURES RESULTS ---\")\n",
    "    print(f\"Total Trades:       {len(df)}\")\n",
    "    print(f\"Total Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "    print(f\"Avg Net PnL:        {avg_net:.2f} pts\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Longs: {len(longs)} | PnL: â‚¹{longs['Net_INR'].sum():,.2f}\")\n",
    "    print(f\"Shorts: {len(shorts)} | PnL: â‚¹{shorts['Net_INR'].sum():,.2f}\")\n",
    "    print(f\"Saved to:           {final_csv}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    # A. Get Futures\n",
    "    fut_csv = download_futures_for_day(YEAR, MONTH, DAY, SYMBOL, FUT_TS)\n",
    "    \n",
    "    # B. Generate Signals\n",
    "    trades_csv = build_kinetic_trades(fut_csv)\n",
    "    \n",
    "    # C. Run Simulation\n",
    "    run_futures_simulation(trades_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb7172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING LONG/SHORT FUTURES SCALPER FOR 24-11-2025 ---\n",
      "1. Downloading Futures: year=2025/month=11/day=24/Futures/NIFTY/NIFTY25NOVFUT.parquet\n",
      "2. Generating Kinetic Signals...\n",
      "   Generated 17 trades.\n",
      "\n",
      "3. Running Pure Futures Simulation...\n",
      "\n",
      "--- FUTURES RESULTS ---\n",
      "Total Trades:       17\n",
      "Total Net PnL:      â‚¹2,760.00\n",
      "Win Rate:           52.9%\n",
      "Avg Net PnL:        2.16 pts\n",
      "------------------------------\n",
      "Longs: 10 | PnL: â‚¹-3,735.00\n",
      "Shorts: 7 | PnL: â‚¹6,495.00\n",
      "Saved to:           data/2025-11-24/futures_scalping_results.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # Trading symbol of futures on that date\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "RISK_FREE_RATE = 0.0          \n",
    "\n",
    "# COST PARAMETERS (FUTURES ONLY)\n",
    "# Nifty Futures typically have very low spread (0.05-0.10). \n",
    "# We assume 1.0 point TOTAL round-trip cost (Slippage + Brokerage + Taxes)\n",
    "# This is a realistic conservative estimate for scalping.\n",
    "FUTURES_ROUND_TRIP_COST = 1.0 \n",
    "\n",
    "BASE_FOLDER = f\"data/{YEAR}-{MONTH:02d}-{DAY:02d}/\"\n",
    "os.makedirs(BASE_FOLDER, exist_ok=True)\n",
    "\n",
    "print(f\"--- RUNNING LONG/SHORT FUTURES SCALPER FOR {DAY}-{MONTH}-{YEAR} ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation: kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]: keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"): continuation = resp.get(\"NextContinuationToken\")\n",
    "        else: break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return # Skip if already exists\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        f.write(obj[\"Body\"].read())\n",
    "\n",
    "# ==========================================\n",
    "# 3. FUTURES & KINETIC LOGIC\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(BASE_FOLDER, \"FUT.parquet\")\n",
    "    print(f\"1. Downloading Futures: {key}\")\n",
    "    download_parquet_to_path(key, local_path)\n",
    "    \n",
    "    # Convert to CSV for easier processing logic\n",
    "    df = pd.read_parquet(local_path)\n",
    "    # Fix Date Parsing Warning by enforcing format or dayfirst\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), \n",
    "        dayfirst=True, \n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # Handle Volume vs OpenInterest naming variations\n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(BASE_FOLDER, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.buf = deque(maxlen=50)\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "\n",
    "    def tick(self, ts, ltp, vol):\n",
    "        self.buf.append((ltp, vol))\n",
    "        if len(self.buf) < 50: return 0\n",
    "\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1 # EXIT\n",
    "            return 0 # HOLD\n",
    "\n",
    "        arr = np.array(self.buf)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        disp = abs(prices[-1] - prices[0])\n",
    "        score = traded_vol / (disp + 0.05)\n",
    "\n",
    "        # DIRECTIONAL LOGIC (VWAP BASED):\n",
    "        # We calculate the Volume Weighted Average Price of the current buffer.\n",
    "        # If Current Price > VWAP -> Buyers are in control -> LONG\n",
    "        # If Current Price < VWAP -> Sellers are in control -> SHORT\n",
    "        \n",
    "        # Calculate tick volumes (sanitize negative diffs)\n",
    "        tick_vols = np.where(vol_diff < 0, 0, vol_diff)\n",
    "        \n",
    "        if np.sum(tick_vols) == 0:\n",
    "             # Fallback to simple displacement if no volume\n",
    "             direction = 1 if prices[-1] > prices[0] else 2\n",
    "        else:\n",
    "            # Match prices to volume (prices[1:] aligns with diff)\n",
    "            trade_prices = prices[1:] \n",
    "            vwap = np.average(trade_prices, weights=tick_vols)\n",
    "            \n",
    "            if prices[-1] > vwap:\n",
    "                direction = 1 # LONG\n",
    "            else:\n",
    "                direction = 2 # SHORT\n",
    "\n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = ts\n",
    "            return direction\n",
    "\n",
    "        return 0\n",
    "\n",
    "def build_kinetic_trades(fut_csv):\n",
    "    print(\"2. Generating Kinetic Signals...\")\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = KineticBrain()\n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        sig = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        # START TRADE\n",
    "        if sig == 1 or sig == 2:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                \"Side\": \"LONG\" if sig == 1 else \"SHORT\"\n",
    "            }\n",
    "        \n",
    "        # END TRADE\n",
    "        elif sig == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(BASE_FOLDER, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    print(f\"   Generated {len(trades_df)} trades.\")\n",
    "    return out_path\n",
    "\n",
    "# ==========================================\n",
    "# 4. FUTURES SIMULATION ENGINE\n",
    "# ==========================================\n",
    "def run_futures_simulation(trades_csv):\n",
    "    print(\"\\n3. Running Pure Futures Simulation...\")\n",
    "    df = pd.read_csv(trades_csv)\n",
    "    if df.empty:\n",
    "        print(\"No trades found.\")\n",
    "        return\n",
    "\n",
    "    # CALCULATE PNL BASED ON DIRECTION\n",
    "    # Long: Exit - Entry\n",
    "    # Short: Entry - Exit\n",
    "    df['Raw_Pts'] = np.where(\n",
    "        df['Side'] == 'LONG', \n",
    "        df['Exit_LTP'] - df['Entry_LTP'], \n",
    "        df['Entry_LTP'] - df['Exit_LTP']\n",
    "    )\n",
    "    \n",
    "    # Futures Costs: Fixed per round trip (Slippage + Comm)\n",
    "    df['Net_Pts'] = df['Raw_Pts'] - FUTURES_ROUND_TRIP_COST\n",
    "    df['Net_INR'] = df['Net_Pts'] * LOT_SIZE\n",
    "    \n",
    "    total_pnl = df['Net_INR'].sum()\n",
    "    win_rate = (df['Net_Pts'] > 0).mean() * 100\n",
    "    avg_raw = df['Raw_Pts'].mean()\n",
    "    avg_net = df['Net_Pts'].mean()\n",
    "    \n",
    "    # Breakdown Long vs Short\n",
    "    longs = df[df['Side'] == 'LONG']\n",
    "    shorts = df[df['Side'] == 'SHORT']\n",
    "    \n",
    "    # Save Results\n",
    "    final_csv = os.path.join(BASE_FOLDER, \"futures_scalping_results.csv\")\n",
    "    df.to_csv(final_csv, index=False)\n",
    "    \n",
    "    print(\"\\n--- FUTURES RESULTS ---\")\n",
    "    print(f\"Total Trades:       {len(df)}\")\n",
    "    print(f\"Total Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "    print(f\"Avg Net PnL:        {avg_net:.2f} pts\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Longs: {len(longs)} | PnL: â‚¹{longs['Net_INR'].sum():,.2f}\")\n",
    "    print(f\"Shorts: {len(shorts)} | PnL: â‚¹{shorts['Net_INR'].sum():,.2f}\")\n",
    "    print(f\"Saved to:           {final_csv}\")\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    # A. Get Futures\n",
    "    fut_csv = download_futures_for_day(YEAR, MONTH, DAY, SYMBOL, FUT_TS)\n",
    "    \n",
    "    # B. Generate Signals\n",
    "    trades_csv = build_kinetic_trades(fut_csv)\n",
    "    \n",
    "    # C. Run Simulation\n",
    "    run_futures_simulation(trades_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6d58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RUNNING MONTHLY FUTURES SCALPER (WITH RISK MGMT) FOR 10-2025 ---\n",
      "\n",
      "Processing 1-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 2-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 3-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #4. PnL: -3375.000000000273\n",
      "   Trades: 4 | PnL: â‚¹-3,375.00\n",
      "\n",
      "Processing 4-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 5-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 6-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #3. PnL: -4312.5\n",
      "   Trades: 3 | PnL: â‚¹-4,312.50\n",
      "\n",
      "Processing 7-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #2. PnL: -5790.000000000055\n",
      "   Trades: 2 | PnL: â‚¹-5,790.00\n",
      "\n",
      "Processing 8-10-2025...\n",
      "   Trades: 17 | PnL: â‚¹-1,492.50\n",
      "\n",
      "Processing 9-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #4. PnL: -3007.5000000001637\n",
      "   Trades: 4 | PnL: â‚¹-3,007.50\n",
      "\n",
      "Processing 10-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #1. PnL: -6330.000000000109\n",
      "   Trades: 1 | PnL: â‚¹-6,330.00\n",
      "\n",
      "Processing 11-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 12-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 13-10-2025...\n",
      "   Trades: 17 | PnL: â‚¹10,080.00\n",
      "\n",
      "Processing 14-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #2. PnL: -4897.499999999945\n",
      "   Trades: 2 | PnL: â‚¹-4,897.50\n",
      "\n",
      "Processing 15-10-2025...\n",
      "   Trades: 17 | PnL: â‚¹2,467.50\n",
      "\n",
      "Processing 16-10-2025...\n",
      "   Trades: 18 | PnL: â‚¹1,132.50\n",
      "\n",
      "Processing 17-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #1. PnL: -4919.999999999891\n",
      "   Trades: 1 | PnL: â‚¹-4,920.00\n",
      "\n",
      "Processing 18-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 19-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 20-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #1. PnL: -3772.4999999999454\n",
      "   Trades: 1 | PnL: â‚¹-3,772.50\n",
      "\n",
      "Processing 21-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 22-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 23-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #14. PnL: -6832.499999999891\n",
      "   Trades: 14 | PnL: â‚¹-6,832.50\n",
      "\n",
      "Processing 24-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #3. PnL: -4222.499999999945\n",
      "   Trades: 3 | PnL: â‚¹-4,222.50\n",
      "\n",
      "Processing 25-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 26-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 27-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #1. PnL: -4237.5\n",
      "   Trades: 1 | PnL: â‚¹-4,237.50\n",
      "\n",
      "Processing 28-10-2025...\n",
      "   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #3. PnL: -8707.49999999989\n",
      "   Trades: 3 | PnL: â‚¹-8,707.50\n",
      "\n",
      "Processing 29-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "Processing 30-10-2025...\n",
      "   No data found (Weekend/Holiday or Missing).\n",
      "\n",
      "========================================\n",
      " MONTHLY SUMMARY: 10-2025\n",
      "========================================\n",
      "Total Trading Days: 16\n",
      "Total Trades:       108\n",
      "Total Net PnL:      â‚¹-48,217.50\n",
      "Win Rate:           45.4%\n",
      "Avg Net PnL/Trade:  -5.95 pts\n",
      "------------------------------\n",
      "Longs:  56 | PnL: â‚¹-15,600.00\n",
      "Shorts: 52 | PnL: â‚¹-32,617.50\n",
      "\n",
      "Full report saved to: data/nov_2025_full_results.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 10\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25OCTFUT\"  # Trading symbol of futures on that date\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "RISK_FREE_RATE = 0.0          \n",
    "\n",
    "# Risk Management\n",
    "DAILY_MAX_LOSS = -3000.0  # Stop trading if daily PnL hits -3000\n",
    "\n",
    "# COST PARAMETERS (FUTURES ONLY)\n",
    "FUTURES_ROUND_TRIP_COST = 1.0 \n",
    "\n",
    "# Global Data Path (will be dynamic per day)\n",
    "DATA_ROOT = \"data/\"\n",
    "\n",
    "print(f\"--- RUNNING MONTHLY FUTURES SCALPER (WITH RISK MGMT) FOR {MONTH}-{YEAR} ---\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation: kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]: keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"): continuation = resp.get(\"NextContinuationToken\")\n",
    "        else: break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True # Skip if already exists\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except s3.exceptions.NoSuchKey:\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {key}: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==========================================\n",
    "# 3. FUTURES & KINETIC LOGIC\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    \n",
    "    success = download_parquet_to_path(key, local_path)\n",
    "    if not success:\n",
    "        return None\n",
    "    \n",
    "    # Convert to CSV for easier processing logic\n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    # Fix Date Parsing\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), \n",
    "        dayfirst=True, \n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    # Handle Volume vs OpenInterest naming variations\n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(day_folder, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.buf = deque(maxlen=50)\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "\n",
    "    def tick(self, ts, ltp, vol):\n",
    "        self.buf.append((ltp, vol))\n",
    "        if len(self.buf) < 50: return 0\n",
    "\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1 # EXIT\n",
    "            return 0 # HOLD\n",
    "\n",
    "        arr = np.array(self.buf)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        disp = abs(prices[-1] - prices[0])\n",
    "        score = traded_vol / (disp + 0.05)\n",
    "\n",
    "        # DIRECTIONAL LOGIC (VWAP BASED)\n",
    "        tick_vols = np.where(vol_diff < 0, 0, vol_diff)\n",
    "        \n",
    "        if np.sum(tick_vols) == 0:\n",
    "             # Fallback to simple displacement if no volume\n",
    "             direction = 1 if prices[-1] > prices[0] else 2\n",
    "        else:\n",
    "            trade_prices = prices[1:] \n",
    "            vwap = np.average(trade_prices, weights=tick_vols)\n",
    "            \n",
    "            if prices[-1] > vwap:\n",
    "                direction = 1 # LONG\n",
    "            else:\n",
    "                direction = 2 # SHORT\n",
    "\n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = ts\n",
    "            return direction\n",
    "\n",
    "        return 0\n",
    "\n",
    "def build_kinetic_trades(fut_csv, day_folder):\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = KineticBrain()\n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        sig = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        # START TRADE\n",
    "        if sig == 1 or sig == 2:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                \"Side\": \"LONG\" if sig == 1 else \"SHORT\"\n",
    "            }\n",
    "        \n",
    "        # END TRADE\n",
    "        elif sig == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(day_folder, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    return trades_df\n",
    "\n",
    "# ==========================================\n",
    "# 4. FUTURES SIMULATION ENGINE (WITH RISK)\n",
    "# ==========================================\n",
    "def calculate_pnl_and_risk(df):\n",
    "    if df.empty: return df\n",
    "\n",
    "    # 1. Calculate Raw PnL for every trade\n",
    "    df['Raw_Pts'] = np.where(\n",
    "        df['Side'] == 'LONG', \n",
    "        df['Exit_LTP'] - df['Entry_LTP'], \n",
    "        df['Entry_LTP'] - df['Exit_LTP']\n",
    "    )\n",
    "    \n",
    "    df['Net_Pts'] = df['Raw_Pts'] - FUTURES_ROUND_TRIP_COST\n",
    "    df['Net_INR'] = df['Net_Pts'] * LOT_SIZE\n",
    "\n",
    "    # 2. Apply Daily Stop Loss (Sequential Check)\n",
    "    cumulative_pnl = df['Net_INR'].cumsum()\n",
    "    \n",
    "    # Find the trade where we breached the limit\n",
    "    breach_mask = cumulative_pnl < DAILY_MAX_LOSS\n",
    "    \n",
    "    if breach_mask.any():\n",
    "        # Get the index of the first breach\n",
    "        first_breach_idx = breach_mask.idxmax()\n",
    "        # We allow the trade that caused the breach to finish, but no more after that\n",
    "        # So we keep trades up to first_breach_idx (inclusive)\n",
    "        \n",
    "        # NOTE: If idxmax returns the first True, slicing usually excludes the end if using standard python range\n",
    "        # But loc/iloc is inclusive/exclusive differently.\n",
    "        # Let's use simple filtering.\n",
    "        \n",
    "        # Find the integer location of the breach\n",
    "        locs = np.where(breach_mask)[0]\n",
    "        stop_loc = locs[0]\n",
    "        \n",
    "        # Keep only trades up to this point\n",
    "        df = df.iloc[:stop_loc+1].copy()\n",
    "        \n",
    "        # Mark the last trade as the trigger\n",
    "        print(f\"   [RISK MGMT] Daily Stop Loss Hit! Stopped after trade #{stop_loc+1}. PnL: {df['Net_INR'].sum()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "    \n",
    "    # Loop through all days of November\n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nProcessing {day}-{MONTH}-{YEAR}...\")\n",
    "        \n",
    "        # A. Get Futures\n",
    "        fut_csv = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        \n",
    "        if not fut_csv:\n",
    "            print(f\"   No data found (Weekend/Holiday or Missing).\")\n",
    "            continue\n",
    "            \n",
    "        # B. Generate Signals\n",
    "        trades_df = build_kinetic_trades(fut_csv, day_folder)\n",
    "        \n",
    "        if not trades_df.empty:\n",
    "            # C. Calculate PnL with Risk Management\n",
    "            trades_df = calculate_pnl_and_risk(trades_df)\n",
    "            \n",
    "            # Save daily result\n",
    "            daily_csv = os.path.join(day_folder, \"futures_results.csv\")\n",
    "            trades_df.to_csv(daily_csv, index=False)\n",
    "            \n",
    "            pnl = trades_df['Net_INR'].sum()\n",
    "            print(f\"   Trades: {len(trades_df)} | PnL: â‚¹{pnl:,.2f}\")\n",
    "            \n",
    "            all_trades.append(trades_df)\n",
    "        else:\n",
    "            print(\"   No trades generated.\")\n",
    "    \n",
    "    # D. Aggregate Monthly Results\n",
    "    if all_trades:\n",
    "        full_df = pd.concat(all_trades, ignore_index=True)\n",
    "        \n",
    "        total_pnl = full_df['Net_INR'].sum()\n",
    "        win_rate = (full_df['Net_Pts'] > 0).mean() * 100\n",
    "        avg_net = full_df['Net_Pts'].mean()\n",
    "        \n",
    "        longs = full_df[full_df['Side'] == 'LONG']\n",
    "        shorts = full_df[full_df['Side'] == 'SHORT']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(f\" MONTHLY SUMMARY: {MONTH}-{YEAR}\")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Total Trading Days: {full_df['Date'].nunique()}\")\n",
    "        print(f\"Total Trades:       {len(full_df)}\")\n",
    "        print(f\"Total Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "        print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "        print(f\"Avg Net PnL/Trade:  {avg_net:.2f} pts\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"Longs:  {len(longs)} | PnL: â‚¹{longs['Net_INR'].sum():,.2f}\")\n",
    "        print(f\"Shorts: {len(shorts)} | PnL: â‚¹{shorts['Net_INR'].sum():,.2f}\")\n",
    "        \n",
    "        final_csv = f\"data/nov_{YEAR}_full_results.csv\"\n",
    "        full_df.to_csv(final_csv, index=False)\n",
    "        print(f\"\\nFull report saved to: {final_csv}\")\n",
    "    else:\n",
    "        print(\"\\nNo trades found for the entire month.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ac76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ROBUST FUTURES SCALPER - 11/2025\n",
      "============================================================\n",
      "\n",
      "\n",
      "01/11/2025... No data\n",
      "\n",
      "02/11/2025... No data\n",
      "\n",
      "03/11/2025... No data\n",
      "\n",
      "04/11/2025...    [STOP LOSS] Hit after trade #1. PnL: â‚¹-5,527.50\n",
      "Trades: 1 (L:1/S:0) | PnL: â‚¹-5,528\n",
      "\n",
      "05/11/2025... No data\n",
      "\n",
      "06/11/2025...    [STOP LOSS] Hit after trade #3. PnL: â‚¹-9,742.50\n",
      "Trades: 3 (L:2/S:1) | PnL: â‚¹-9,743\n",
      "\n",
      "07/11/2025...    [STOP LOSS] Hit after trade #1. PnL: â‚¹-4,665.00\n",
      "Trades: 1 (L:1/S:0) | PnL: â‚¹-4,665\n",
      "\n",
      "08/11/2025... No data\n",
      "\n",
      "09/11/2025... No data\n",
      "\n",
      "10/11/2025... No data\n",
      "\n",
      "11/11/2025... Trades: 17 (L:11/S:6) | PnL: â‚¹7,612\n",
      "\n",
      "12/11/2025...    [STOP LOSS] Hit after trade #9. PnL: â‚¹-3,862.50\n",
      "Trades: 9 (L:3/S:6) | PnL: â‚¹-3,862\n",
      "\n",
      "13/11/2025...    [STOP LOSS] Hit after trade #3. PnL: â‚¹-4,237.50\n",
      "Trades: 3 (L:0/S:3) | PnL: â‚¹-4,238\n",
      "\n",
      "14/11/2025... No data\n",
      "\n",
      "15/11/2025... No data\n",
      "\n",
      "16/11/2025... No data\n",
      "\n",
      "17/11/2025... Trades: 16 (L:8/S:8) | PnL: â‚¹-75\n",
      "\n",
      "18/11/2025... Trades: 16 (L:8/S:8) | PnL: â‚¹6,022\n",
      "\n",
      "19/11/2025...    [STOP LOSS] Hit after trade #3. PnL: â‚¹-4,530.00\n",
      "Trades: 3 (L:0/S:3) | PnL: â‚¹-4,530\n",
      "\n",
      "20/11/2025...    [STOP LOSS] Hit after trade #9. PnL: â‚¹-4,147.50\n",
      "Trades: 9 (L:3/S:6) | PnL: â‚¹-4,147\n",
      "\n",
      "21/11/2025... Trades: 17 (L:10/S:7) | PnL: â‚¹150\n",
      "\n",
      "22/11/2025... No data\n",
      "\n",
      "23/11/2025... No data\n",
      "\n",
      "24/11/2025...    [STOP LOSS] Hit after trade #2. PnL: â‚¹-3,405.00\n",
      "Trades: 2 (L:1/S:1) | PnL: â‚¹-3,405\n",
      "\n",
      "25/11/2025...    [STOP LOSS] Hit after trade #5. PnL: â‚¹-6,862.50\n",
      "Trades: 5 (L:3/S:2) | PnL: â‚¹-6,862\n",
      "\n",
      "26/11/2025... No data\n",
      "\n",
      "27/11/2025... No data\n",
      "\n",
      "28/11/2025... No data\n",
      "\n",
      "29/11/2025... No data\n",
      "\n",
      "30/11/2025... No data\n",
      "\n",
      "============================================================\n",
      "MONTHLY SUMMARY: 11/2025\n",
      "============================================================\n",
      "Trading Days:       13\n",
      "Total Trades:       102\n",
      "  - Longs:          51 (â‚¹-12,503)\n",
      "  - Shorts:         51 (â‚¹-20,767)\n",
      "\n",
      "Total Net PnL:      â‚¹-33,270.00\n",
      "Avg PnL/Trade:      -4.35 pts (â‚¹-326.18)\n",
      "Win Rate:           40.2%\n",
      "\n",
      "Directional Accuracy:\n",
      "  - Long Win Rate:  52.9%\n",
      "  - Short Win Rate: 27.5%\n",
      "\n",
      "Results saved: data/nov_2025_robust_results.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS FUTURES SCALPER WITH ROBUST DIRECTIONAL SIGNAL\n",
    "===================================================\n",
    "Kinetic Energy + Multi-Signal Direction Classifier\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "KINETIC_THRESHOLD = 37500\n",
    "HOLD_SECONDS = 1200  # 20 minutes\n",
    "\n",
    "# Risk Management\n",
    "DAILY_MAX_LOSS = -3000.0\n",
    "\n",
    "# Costs\n",
    "FUTURES_ROUND_TRIP_COST = 1.0\n",
    "\n",
    "DATA_ROOT = \"data/\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ROBUST FUTURES SCALPER - {MONTH}/{YEAR}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation:\n",
    "            kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            continuation = resp.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# ROBUST DIRECTIONAL ENGINE\n",
    "# ==========================================\n",
    "class RobustDirectionalEngine:\n",
    "    \"\"\"Multi-signal directional classifier\"\"\"\n",
    "    \n",
    "    def __init__(self, buffer_size=50):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.price_buffer = deque(maxlen=buffer_size)\n",
    "        self.volume_buffer = deque(maxlen=buffer_size)\n",
    "        \n",
    "    def add_tick(self, ltp, volume):\n",
    "        self.price_buffer.append(ltp)\n",
    "        self.volume_buffer.append(volume)\n",
    "    \n",
    "    def calculate_direction(self):\n",
    "        \"\"\"Returns: 1 (LONG), 2 (SHORT), 0 (NEUTRAL)\"\"\"\n",
    "        if len(self.price_buffer) < self.buffer_size:\n",
    "            return 0\n",
    "        \n",
    "        prices = np.array(self.price_buffer)\n",
    "        volumes = np.array(self.volume_buffer)\n",
    "        \n",
    "        # Calculate all signals\n",
    "        signals = {\n",
    "            'vwap_momentum': self._vwap_momentum_signal(prices, volumes),\n",
    "            'aggressor_flow': self._aggressor_flow_signal(prices, volumes),\n",
    "            'price_acceleration': self._price_acceleration_signal(prices, volumes),\n",
    "            'volume_momentum': self._volume_momentum_signal(prices, volumes)\n",
    "        }\n",
    "        \n",
    "        weights = {\n",
    "            'vwap_momentum': 0.35,\n",
    "            'aggressor_flow': 0.30,\n",
    "            'price_acceleration': 0.20,\n",
    "            'volume_momentum': 0.15\n",
    "        }\n",
    "        \n",
    "        # Weighted combination\n",
    "        direction_score = sum(signals[k] * weights[k] for k in signals.keys())\n",
    "        \n",
    "        # Decision thresholds\n",
    "        if direction_score > 0.15:\n",
    "            return 1  # LONG\n",
    "        elif direction_score < -0.15:\n",
    "            return 2  # SHORT\n",
    "        else:\n",
    "            return 0  # NEUTRAL (skip trade)\n",
    "    \n",
    "    def _vwap_momentum_signal(self, prices, volumes):\n",
    "        \"\"\"Compare price to VWAP\"\"\"\n",
    "        vol_deltas = np.diff(volumes)\n",
    "        vol_deltas = np.where(vol_deltas > 0, vol_deltas, 0)\n",
    "        \n",
    "        if vol_deltas.sum() == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        vwap = np.average(prices[1:], weights=vol_deltas)\n",
    "        current = prices[-1]\n",
    "        deviation = (current - vwap) / vwap\n",
    "        \n",
    "        return np.tanh(deviation * 300)\n",
    "    \n",
    "    def _aggressor_flow_signal(self, prices, volumes):\n",
    "        \"\"\"Lee-Ready trade classification\"\"\"\n",
    "        mid = (prices[:-1] + prices[1:]) / 2\n",
    "        trade_signs = np.zeros(len(prices) - 1)\n",
    "        \n",
    "        for i in range(len(prices) - 1):\n",
    "            if prices[i+1] > mid[i]:\n",
    "                trade_signs[i] = 1\n",
    "            elif prices[i+1] < mid[i]:\n",
    "                trade_signs[i] = -1\n",
    "            else:\n",
    "                if i > 0:\n",
    "                    trade_signs[i] = np.sign(prices[i+1] - prices[i])\n",
    "        \n",
    "        vol_deltas = np.diff(volumes)\n",
    "        vol_deltas = np.where(vol_deltas > 0, vol_deltas, 0)\n",
    "        \n",
    "        if vol_deltas.sum() == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        net_flow = (trade_signs * vol_deltas).sum() / vol_deltas.sum()\n",
    "        return np.clip(net_flow * 2, -1, 1)\n",
    "    \n",
    "    def _price_acceleration_signal(self, prices, volumes):\n",
    "        \"\"\"Detect momentum acceleration\"\"\"\n",
    "        mid = len(prices) // 2\n",
    "        first_half = prices[:mid]\n",
    "        second_half = prices[mid:]\n",
    "        \n",
    "        mom_first = (first_half[-1] - first_half[0]) / first_half[0]\n",
    "        mom_second = (second_half[-1] - second_half[0]) / second_half[0]\n",
    "        \n",
    "        acceleration = mom_second - mom_first\n",
    "        return np.tanh(acceleration * 1000)\n",
    "    \n",
    "    def _volume_momentum_signal(self, prices, volumes):\n",
    "        \"\"\"Volume concentration + direction\"\"\"\n",
    "        price_direction = prices[-1] - prices[0]\n",
    "        \n",
    "        if abs(price_direction) < 0.01:\n",
    "            return 0.0\n",
    "        \n",
    "        vol_deltas = np.diff(volumes)\n",
    "        vol_deltas = np.where(vol_deltas > 0, vol_deltas, 0)\n",
    "        \n",
    "        if vol_deltas.sum() == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        recent_vol = vol_deltas[-len(vol_deltas)//4:].sum()\n",
    "        total_vol = vol_deltas.sum()\n",
    "        \n",
    "        concentration = recent_vol / total_vol\n",
    "        strength = concentration * 2 - 0.5\n",
    "        \n",
    "        return np.sign(price_direction) * strength\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# ENHANCED KINETIC BRAIN\n",
    "# ==========================================\n",
    "class EnhancedKineticBrain:\n",
    "    \"\"\"Kinetic Energy + Robust Direction\"\"\"\n",
    "    \n",
    "    def __init__(self, threshold=37500, hold_seconds=1200):\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "        self.in_trade = False\n",
    "        self.entry_time = None\n",
    "        self.ke_buffer = deque(maxlen=50)\n",
    "        self.directional = RobustDirectionalEngine(buffer_size=50)\n",
    "        self.last_score = 0\n",
    "    \n",
    "    def tick(self, ts, ltp, volume):\n",
    "        \"\"\"Process tick and return signal\"\"\"\n",
    "        self.ke_buffer.append((ltp, volume))\n",
    "        self.directional.add_tick(ltp, volume)\n",
    "        \n",
    "        if len(self.ke_buffer) < 50:\n",
    "            return 0\n",
    "        \n",
    "        # Exit check\n",
    "        if self.in_trade:\n",
    "            if (ts - self.entry_time).total_seconds() >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                return -1\n",
    "            return 0\n",
    "        \n",
    "        # Calculate KE\n",
    "        arr = np.array(self.ke_buffer)\n",
    "        prices, vols = arr[:, 0], arr[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        traded_vol = np.sum(np.where(vol_diff > 0, vol_diff, 0))\n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        \n",
    "        ke_score = traded_vol / (displacement + 0.05)\n",
    "        self.last_score = ke_score\n",
    "        \n",
    "        # Entry: KE trigger + Direction\n",
    "        if ke_score > self.threshold:\n",
    "            direction = self.directional.calculate_direction()\n",
    "            \n",
    "            if direction > 0:\n",
    "                self.in_trade = True\n",
    "                self.entry_time = ts\n",
    "                return direction\n",
    "        \n",
    "        return 0\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATA LOADING\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    \n",
    "    success = download_parquet_to_path(key, local_path)\n",
    "    if not success:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), \n",
    "        dayfirst=True, \n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    if \"Volume\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"Volume\"] = 0.0\n",
    "    \n",
    "    csv_path = os.path.join(day_folder, \"FUT.csv\")\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return csv_path\n",
    "\n",
    "def build_kinetic_trades(fut_csv, day_folder):\n",
    "    df = pd.read_csv(fut_csv)\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"DateTime\"])\n",
    "    \n",
    "    brain = EnhancedKineticBrain(threshold=KINETIC_THRESHOLD, hold_seconds=HOLD_SECONDS)\n",
    "    \n",
    "    trades = []\n",
    "    active = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        \n",
    "        signal = brain.tick(ts, ltp, vol)\n",
    "\n",
    "        if signal == 1 or signal == 2:\n",
    "            active = {\n",
    "                \"Date\": ts.date(),\n",
    "                \"Entry_Time\": ts,\n",
    "                \"Entry_LTP\": ltp,\n",
    "                \"Side\": \"LONG\" if signal == 1 else \"SHORT\",\n",
    "                \"KE_Score\": brain.last_score\n",
    "            }\n",
    "        \n",
    "        elif signal == -1 and active is not None:\n",
    "            active[\"Exit_Time\"] = ts\n",
    "            active[\"Exit_LTP\"] = ltp\n",
    "            trades.append(active)\n",
    "            active = None\n",
    "\n",
    "    trades_df = pd.DataFrame(trades)\n",
    "    out_path = os.path.join(day_folder, \"kinetic_trades.csv\")\n",
    "    trades_df.to_csv(out_path, index=False)\n",
    "    \n",
    "    return trades_df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# PNL CALCULATION WITH RISK MGMT\n",
    "# ==========================================\n",
    "def calculate_pnl_and_risk(df):\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    df['Raw_Pts'] = np.where(\n",
    "        df['Side'] == 'LONG', \n",
    "        df['Exit_LTP'] - df['Entry_LTP'], \n",
    "        df['Entry_LTP'] - df['Exit_LTP']\n",
    "    )\n",
    "    \n",
    "    df['Net_Pts'] = df['Raw_Pts'] - FUTURES_ROUND_TRIP_COST\n",
    "    df['Net_INR'] = df['Net_Pts'] * LOT_SIZE\n",
    "\n",
    "    # Daily stop loss\n",
    "    cumulative_pnl = df['Net_INR'].cumsum()\n",
    "    breach_mask = cumulative_pnl < DAILY_MAX_LOSS\n",
    "    \n",
    "    if breach_mask.any():\n",
    "        locs = np.where(breach_mask)[0]\n",
    "        stop_loc = locs[0]\n",
    "        df = df.iloc[:stop_loc+1].copy()\n",
    "        print(f\"   [STOP LOSS] Hit after trade #{stop_loc+1}. PnL: â‚¹{df['Net_INR'].sum():,.2f}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "    \n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{day:02d}/{MONTH}/{YEAR}...\", end=\" \")\n",
    "        \n",
    "        fut_csv = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        \n",
    "        if not fut_csv:\n",
    "            print(\"No data\")\n",
    "            continue\n",
    "        \n",
    "        trades_df = build_kinetic_trades(fut_csv, day_folder)\n",
    "        \n",
    "        if not trades_df.empty:\n",
    "            trades_df = calculate_pnl_and_risk(trades_df)\n",
    "            \n",
    "            daily_csv = os.path.join(day_folder, \"futures_results.csv\")\n",
    "            trades_df.to_csv(daily_csv, index=False)\n",
    "            \n",
    "            pnl = trades_df['Net_INR'].sum()\n",
    "            n_trades = len(trades_df)\n",
    "            longs = len(trades_df[trades_df['Side'] == 'LONG'])\n",
    "            shorts = len(trades_df[trades_df['Side'] == 'SHORT'])\n",
    "            \n",
    "            print(f\"Trades: {n_trades} (L:{longs}/S:{shorts}) | PnL: â‚¹{pnl:,.0f}\")\n",
    "            \n",
    "            all_trades.append(trades_df)\n",
    "        else:\n",
    "            print(\"No signals\")\n",
    "    \n",
    "    # Monthly summary\n",
    "    if all_trades:\n",
    "        full_df = pd.concat(all_trades, ignore_index=True)\n",
    "        \n",
    "        total_pnl = full_df['Net_INR'].sum()\n",
    "        win_rate = (full_df['Net_Pts'] > 0).mean() * 100\n",
    "        avg_net = full_df['Net_Pts'].mean()\n",
    "        \n",
    "        longs = full_df[full_df['Side'] == 'LONG']\n",
    "        shorts = full_df[full_df['Side'] == 'SHORT']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"MONTHLY SUMMARY: {MONTH}/{YEAR}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Trading Days:       {full_df['Date'].nunique()}\")\n",
    "        print(f\"Total Trades:       {len(full_df)}\")\n",
    "        print(f\"  - Longs:          {len(longs)} (â‚¹{longs['Net_INR'].sum():,.0f})\")\n",
    "        print(f\"  - Shorts:         {len(shorts)} (â‚¹{shorts['Net_INR'].sum():,.0f})\")\n",
    "        print(f\"\\nTotal Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "        print(f\"Avg PnL/Trade:      {avg_net:.2f} pts (â‚¹{avg_net*LOT_SIZE:.2f})\")\n",
    "        print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "        \n",
    "        # Direction accuracy\n",
    "        long_wr = (longs['Net_Pts'] > 0).mean() * 100 if len(longs) > 0 else 0\n",
    "        short_wr = (shorts['Net_Pts'] > 0).mean() * 100 if len(shorts) > 0 else 0\n",
    "        \n",
    "        print(f\"\\nDirectional Accuracy:\")\n",
    "        print(f\"  - Long Win Rate:  {long_wr:.1f}%\")\n",
    "        print(f\"  - Short Win Rate: {short_wr:.1f}%\")\n",
    "        \n",
    "        final_csv = f\"data/nov_{YEAR}_robust_results.csv\"\n",
    "        full_df.to_csv(final_csv, index=False)\n",
    "        print(f\"\\nResults saved: {final_csv}\")\n",
    "        print(\"=\"*60)\n",
    "    else:\n",
    "        print(\"\\nNo trades for the month.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f7848",
   "metadata": {},
   "source": [
    "gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e707d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EFFICIENCY HYBRID (2-STRIKE GUARD) - 10/2025\n",
      "Logic: ER Hybrid | Stop after 2 losses | BE @ +20.0\n",
      "============================================================\n",
      "\n",
      "\n",
      "01/10/2025... No data\n",
      "\n",
      "02/10/2025... No data\n",
      "\n",
      "03/10/2025... Trades: 9 (SL:2/BE:2) | PnL: â‚¹-2,025\n",
      "\n",
      "04/10/2025... No data\n",
      "\n",
      "05/10/2025... No data\n",
      "\n",
      "06/10/2025... Trades: 3 (SL:2/BE:1) | PnL: â‚¹-3,240\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "07/10/2025... Trades: 2 (SL:1/BE:1) | PnL: â‚¹-2,415\n",
      "\n",
      "08/10/2025... Trades: 2 (SL:2/BE:0) | PnL: â‚¹-4,860\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "09/10/2025... Trades: 7 (SL:3/BE:3) | PnL: â‚¹-3,923\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "10/10/2025... Trades: 2 (SL:2/BE:0) | PnL: â‚¹-4,823\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "11/10/2025... No data\n",
      "\n",
      "12/10/2025... No data\n",
      "\n",
      "13/10/2025... Trades: 6 (SL:1/BE:3) | PnL: â‚¹1,988\n",
      "\n",
      "14/10/2025... Trades: 15 (SL:1/BE:2) | PnL: â‚¹11,490\n",
      "\n",
      "15/10/2025... Trades: 4 (SL:2/BE:0) | PnL: â‚¹-2,340\n",
      "\n",
      "16/10/2025... Trades: 2 (SL:1/BE:1) | PnL: â‚¹-2,558\n",
      "\n",
      "17/10/2025... Trades: 2 (SL:2/BE:0) | PnL: â‚¹-4,702\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "18/10/2025... No data\n",
      "\n",
      "19/10/2025... No data\n",
      "\n",
      "20/10/2025... Trades: 3 (SL:2/BE:0) | PnL: â‚¹1,170\n",
      "\n",
      "21/10/2025... No data\n",
      "\n",
      "22/10/2025... No data\n",
      "\n",
      "23/10/2025... Trades: 2 (SL:2/BE:0) | PnL: â‚¹-4,680\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "24/10/2025... Trades: 3 (SL:0/BE:3) | PnL: â‚¹1,095\n",
      "\n",
      "25/10/2025... No data\n",
      "\n",
      "26/10/2025... No data\n",
      "\n",
      "27/10/2025... Trades: 2 (SL:2/BE:0) | PnL: â‚¹-4,650\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "28/10/2025... Trades: 3 (SL:1/BE:2) | PnL: â‚¹-1,200\n",
      "\n",
      "29/10/2025... No data\n",
      "\n",
      "30/10/2025... No data\n",
      "\n",
      "============================================================\n",
      "EFFICIENCY HYBRID (GUARDED) SUMMARY: 10/2025\n",
      "============================================================\n",
      "Total Net PnL:      â‚¹-25,672.50\n",
      "Win Rate:           35.8%\n",
      "Total Trades:       67\n",
      "  - Longs:          0 (â‚¹0)\n",
      "  - Shorts:         67 (â‚¹-25,672)\n",
      "\n",
      "Results saved: data/nov_2025_hybrid_guarded_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS FUTURES SCALPER: EFFICIENCY HYBRID + 2-STRIKE GUARD\n",
    "========================================================\n",
    "Logic: \n",
    "1. Core: Efficiency Ratio (ER) + Supertrend (The Brain).\n",
    "2. Defense (New): \n",
    "   - CONSECUTIVE LOSS LIMIT = 2. (If we lose twice in a row, we quit today).\n",
    "   - Trailing Stop: Move to BE at +20 pts to kill risk early.\n",
    "3. Goal: Cut the -4k days down to -1k days, keeping the +13k days intact.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 10\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25OCTFUT\"\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "KINETIC_THRESHOLD = 37500    \n",
    "MAX_HOLD_SECONDS = 1200      # 20 mins\n",
    "\n",
    "# Efficiency Settings\n",
    "ER_PERIOD = 50          \n",
    "ER_TREND_THRESHOLD = 0.50  \n",
    "ER_CHOP_THRESHOLD = 0.30   \n",
    "\n",
    "# Supertrend Settings\n",
    "ATR_PERIOD = 7\n",
    "ATR_MULTIPLIER = 3.0\n",
    "\n",
    "# Trade Management\n",
    "STOP_LOSS_POINTS = 30.0      \n",
    "TAKE_PROFIT_POINTS = 80.0    # Increased to let trailing work\n",
    "\n",
    "# Trailing Settings (THE SHIELD)\n",
    "BE_TRIGGER = 20.0       # At +20 pts, Move SL to Breakeven\n",
    "TRAIL_TRIGGER = 40.0    # At +40 pts, Start Trailing\n",
    "TRAIL_LOCK = 20.0       # Lock 20 pts profit\n",
    "\n",
    "# Risk Management\n",
    "DAILY_MAX_LOSS = -3000.0\n",
    "CONSECUTIVE_LOSS_LIMIT = 2 # The \"2-Strike\" Rule\n",
    "\n",
    "# Costs\n",
    "FUTURES_ROUND_TRIP_COST = 1.0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EFFICIENCY HYBRID (2-STRIKE GUARD) - {MONTH}/{YEAR}\")\n",
    "print(f\"Logic: ER Hybrid | Stop after {CONSECUTIVE_LOSS_LIMIT} losses | BE @ +{BE_TRIGGER}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation:\n",
    "            kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            continuation = resp.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# SUPERTREND INDICATOR\n",
    "# ==========================================\n",
    "class Supertrend:\n",
    "    def __init__(self, period=7, multiplier=3.0):\n",
    "        self.period = period\n",
    "        self.multiplier = multiplier\n",
    "        self.tr_buffer = deque(maxlen=period)\n",
    "        self.prev_close = None\n",
    "        self.trend = 1 \n",
    "        self.upper_band = 0.0\n",
    "        self.lower_band = 0.0\n",
    "        self.supertrend = 0.0\n",
    "        self.initialized = False\n",
    "        \n",
    "    def update(self, high, low, close):\n",
    "        if self.prev_close is None:\n",
    "            tr = high - low\n",
    "        else:\n",
    "            tr = max(high - low, abs(high - self.prev_close), abs(low - self.prev_close))\n",
    "        \n",
    "        self.tr_buffer.append(tr)\n",
    "        self.prev_close = close\n",
    "        \n",
    "        if len(self.tr_buffer) < self.period:\n",
    "            return 0 \n",
    "            \n",
    "        atr = np.mean(self.tr_buffer)\n",
    "        mid = (high + low) / 2\n",
    "        basic_upper = mid + (self.multiplier * atr)\n",
    "        basic_lower = mid - (self.multiplier * atr)\n",
    "        \n",
    "        if not self.initialized:\n",
    "            self.upper_band = basic_upper\n",
    "            self.lower_band = basic_lower\n",
    "            self.initialized = True\n",
    "        \n",
    "        if basic_upper < self.upper_band or self.prev_close > self.upper_band:\n",
    "            self.upper_band = basic_upper\n",
    "        if basic_lower > self.lower_band or self.prev_close < self.lower_band:\n",
    "            self.lower_band = basic_lower\n",
    "            \n",
    "        if self.trend == 1 and close < self.lower_band:\n",
    "            self.trend = -1\n",
    "            self.supertrend = self.upper_band\n",
    "        elif self.trend == -1 and close > self.upper_band:\n",
    "            self.trend = 1\n",
    "            self.supertrend = self.lower_band\n",
    "        elif self.trend == 1:\n",
    "            self.supertrend = self.lower_band\n",
    "        elif self.trend == -1:\n",
    "            self.supertrend = self.upper_band\n",
    "            \n",
    "        return self.trend\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# EFFICIENCY KINETIC BRAIN\n",
    "# ==========================================\n",
    "class EfficiencyKineticBrain:\n",
    "    def __init__(self, threshold=37500):\n",
    "        self.threshold = threshold\n",
    "        self.ke_buffer = deque(maxlen=50)\n",
    "        self.price_buffer = deque(maxlen=ER_PERIOD)\n",
    "        self.st = Supertrend(period=ATR_PERIOD, multiplier=ATR_MULTIPLIER)\n",
    "        self.last_score = 0\n",
    "    \n",
    "    def tick(self, ltp, volume):\n",
    "        self.ke_buffer.append((ltp, volume))\n",
    "        self.price_buffer.append(ltp)\n",
    "        st_dir = self.st.update(ltp, ltp, ltp)\n",
    "        \n",
    "        if len(self.ke_buffer) < 50 or len(self.price_buffer) < ER_PERIOD:\n",
    "            return 0\n",
    "            \n",
    "        # 1. Kinetic Calculation\n",
    "        arr = np.array(self.ke_buffer)\n",
    "        prices_ke = arr[:, 0]\n",
    "        vols_ke = arr[:, 1]\n",
    "        \n",
    "        v_diff = np.diff(vols_ke)\n",
    "        v_diff = np.where(v_diff < 0, 0, v_diff)\n",
    "        traded_vol = np.sum(v_diff)\n",
    "        displacement = abs(prices_ke[-1] - prices_ke[0])\n",
    "        \n",
    "        ke_score = traded_vol / (displacement + 0.05)\n",
    "        self.last_score = ke_score\n",
    "        \n",
    "        # 2. Trigger\n",
    "        if ke_score > self.threshold:\n",
    "            \n",
    "            # 3. Calculate Efficiency Ratio (ER)\n",
    "            prices_er = np.array(self.price_buffer)\n",
    "            net_change = abs(prices_er[-1] - prices_er[0])\n",
    "            sum_changes = np.sum(np.abs(np.diff(prices_er)))\n",
    "            \n",
    "            if sum_changes == 0: \n",
    "                er = 1.0 \n",
    "            else:\n",
    "                er = net_change / sum_changes\n",
    "                \n",
    "            # 4. Hybrid Logic\n",
    "            \n",
    "            # CASE A: High Efficiency (TREND MODE) -> FOLLOW\n",
    "            if er > ER_TREND_THRESHOLD:\n",
    "                if st_dir == 1: return 1 # Follow Long\n",
    "                if st_dir == -1: return 2 # Follow Short\n",
    "                \n",
    "            # CASE B: Low Efficiency (CHOP MODE) -> FADE\n",
    "            elif er < ER_CHOP_THRESHOLD:\n",
    "                if st_dir == 1: return 2 # Fade Long (Go Short)\n",
    "                if st_dir == -1: return 1 # Fade Short (Go Long)\n",
    "            \n",
    "            # CASE C: Middle (NOISE) -> NO TRADE\n",
    "            \n",
    "        return 0\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATA LOADING\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    success = download_parquet_to_path(key, local_path)\n",
    "    if not success: return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except: return None\n",
    "\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), dayfirst=True, errors=\"coerce\")\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_day_trades(df, day_folder):\n",
    "    brain = EfficiencyKineticBrain(threshold=KINETIC_THRESHOLD)\n",
    "    completed_trades = []\n",
    "    \n",
    "    # Active Trade State\n",
    "    in_trade = False\n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    side = None \n",
    "    highest_pnl = 0.0 # Track max profit for trailing\n",
    "    \n",
    "    # Risk State\n",
    "    daily_pnl = 0.0\n",
    "    consecutive_losses = 0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        # GLOBAL STOPS\n",
    "        if daily_pnl < DAILY_MAX_LOSS: break \n",
    "        if consecutive_losses >= CONSECUTIVE_LOSS_LIMIT: break # 2-Strike Out\n",
    "            \n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        \n",
    "        # --- TRADE MANAGEMENT ---\n",
    "        if in_trade:\n",
    "            duration = (ts - entry_time).total_seconds()\n",
    "            exit_signal = False\n",
    "            exit_reason = \"\"\n",
    "            \n",
    "            # PnL Calc\n",
    "            if side == \"LONG\":\n",
    "                float_pnl = ltp - entry_price\n",
    "            else:\n",
    "                float_pnl = entry_price - ltp\n",
    "            \n",
    "            # Update Peak\n",
    "            if float_pnl > highest_pnl: highest_pnl = float_pnl\n",
    "            \n",
    "            # Dynamic Stop Logic\n",
    "            current_sl = STOP_LOSS_POINTS\n",
    "            if highest_pnl >= TRAIL_TRIGGER: current_sl = -TRAIL_LOCK # Lock in profit\n",
    "            elif highest_pnl >= BE_TRIGGER: current_sl = -1.0 # Breakeven\n",
    "            \n",
    "            # Exits\n",
    "            if float_pnl <= -current_sl: \n",
    "                exit_signal = True\n",
    "                exit_reason = \"TRAIL/BE\" if current_sl < 0 else \"SL\"\n",
    "            elif float_pnl >= TAKE_PROFIT_POINTS: \n",
    "                exit_signal = True; exit_reason = \"TP\"\n",
    "            elif duration >= MAX_HOLD_SECONDS:\n",
    "                exit_signal = True; exit_reason = \"TIME\"\n",
    "                \n",
    "            if exit_signal:\n",
    "                gross_pnl = float_pnl * LOT_SIZE\n",
    "                cost = FUTURES_ROUND_TRIP_COST * LOT_SIZE\n",
    "                net_pnl = gross_pnl - cost\n",
    "                \n",
    "                daily_pnl += net_pnl\n",
    "                \n",
    "                # Update Streak\n",
    "                if net_pnl < 0: consecutive_losses += 1\n",
    "                else: consecutive_losses = 0 # Reset on win\n",
    "                \n",
    "                completed_trades.append({\n",
    "                    \"Date\": ts.date(),\n",
    "                    \"Entry_Time\": entry_time,\n",
    "                    \"Side\": side,\n",
    "                    \"Net_Pts\": float_pnl - FUTURES_ROUND_TRIP_COST,\n",
    "                    \"Net_INR\": net_pnl,\n",
    "                    \"Exit_Reason\": exit_reason\n",
    "                })\n",
    "                in_trade = False\n",
    "                highest_pnl = 0.0\n",
    "                continue \n",
    "\n",
    "        # --- SIGNAL GENERATION ---\n",
    "        if not in_trade:\n",
    "            sig = brain.tick(ltp, vol)\n",
    "            if sig == 1: \n",
    "                in_trade = True; entry_time = ts; entry_price = ltp; side = \"LONG\"\n",
    "            elif sig == 2: \n",
    "                in_trade = True; entry_time = ts; entry_price = ltp; side = \"SHORT\"\n",
    "        else:\n",
    "            brain.tick(ltp, vol)\n",
    "\n",
    "    trades_df = pd.DataFrame(completed_trades)\n",
    "    return trades_df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "    \n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{day:02d}/{MONTH}/{YEAR}...\", end=\" \")\n",
    "        \n",
    "        df = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"No data\")\n",
    "            continue\n",
    "        \n",
    "        trades_df = process_day_trades(df, day_folder)\n",
    "        \n",
    "        if not trades_df.empty:\n",
    "            daily_csv = os.path.join(day_folder, \"futures_results.csv\")\n",
    "            trades_df.to_csv(daily_csv, index=False)\n",
    "            \n",
    "            pnl = trades_df['Net_INR'].sum()\n",
    "            n_trades = len(trades_df)\n",
    "            sl_hits = len(trades_df[trades_df['Exit_Reason'] == 'SL'])\n",
    "            be_hits = len(trades_df[trades_df['Exit_Reason'] == 'TRAIL/BE'])\n",
    "            streak_end = \"YES\" if pnl < DAILY_MAX_LOSS or len(trades_df) < 5 else \"NO\" # approx logic check\n",
    "            \n",
    "            # Check if stopped by streak\n",
    "            # We can infer it: if consecutive losses at end is >= 2\n",
    "            \n",
    "            print(f\"Trades: {n_trades} (SL:{sl_hits}/BE:{be_hits}) | PnL: â‚¹{pnl:,.0f}\")\n",
    "            if pnl < DAILY_MAX_LOSS: print(f\"   [RISK] Global Stop Hit!\")\n",
    "            \n",
    "            all_trades.append(trades_df)\n",
    "        else:\n",
    "            print(\"No trades\")\n",
    "    \n",
    "    if all_trades:\n",
    "        full_df = pd.concat(all_trades, ignore_index=True)\n",
    "        \n",
    "        total_pnl = full_df['Net_INR'].sum()\n",
    "        win_rate = (full_df['Net_Pts'] > 0).mean() * 100\n",
    "        \n",
    "        longs = full_df[full_df['Side'] == 'LONG']\n",
    "        shorts = full_df[full_df['Side'] == 'SHORT']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"EFFICIENCY HYBRID (GUARDED) SUMMARY: {MONTH}/{YEAR}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "        print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "        print(f\"Total Trades:       {len(full_df)}\")\n",
    "        print(f\"  - Longs:          {len(longs)} (â‚¹{longs['Net_INR'].sum():,.0f})\")\n",
    "        print(f\"  - Shorts:         {len(shorts)} (â‚¹{shorts['Net_INR'].sum():,.0f})\")\n",
    "        \n",
    "        final_csv = f\"data/nov_{YEAR}_hybrid_guarded_results.csv\"\n",
    "        full_df.to_csv(final_csv, index=False)\n",
    "        print(f\"\\nResults saved: {final_csv}\")\n",
    "    else:\n",
    "        print(\"\\nNo trades for the month.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779fdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KINETIC DIRECTIONAL FUTURES SCALPER - 11/2025\n",
      "Symbol: NIFTY, Contract: NIFTY25NOVFUT\n",
      "============================================================\n",
      "\n",
      "01/11/2025... No data\n",
      "02/11/2025... No data\n",
      "03/11/2025... No data\n",
      "04/11/2025... Trades: 2 (SL:2/TP:0) | PnL: â‚¹-4,035\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "05/11/2025... No data\n",
      "06/11/2025... Trades: 23 (SL:4/TP:3) | PnL: â‚¹16,770\n",
      "07/11/2025... Trades: 2 (SL:2/TP:0) | PnL: â‚¹-3,900\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "08/11/2025... No data\n",
      "09/11/2025... No data\n",
      "10/11/2025... No data\n",
      "11/11/2025... Trades: 2 (SL:2/TP:0) | PnL: â‚¹-4,418\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "12/11/2025... Trades: 24 (SL:5/TP:1) | PnL: â‚¹-2,798\n",
      "13/11/2025... Trades: 2 (SL:2/TP:0) | PnL: â‚¹-4,050\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "14/11/2025... No data\n",
      "15/11/2025... No data\n",
      "16/11/2025... No data\n",
      "17/11/2025... Trades: 23 (SL:2/TP:1) | PnL: â‚¹-532\n",
      "18/11/2025... Trades: 23 (SL:4/TP:1) | PnL: â‚¹-878\n",
      "19/11/2025... Trades: 24 (SL:4/TP:0) | PnL: â‚¹-263\n",
      "20/11/2025... Trades: 16 (SL:3/TP:0) | PnL: â‚¹-4,282\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "21/11/2025... Trades: 12 (SL:5/TP:1) | PnL: â‚¹-4,395\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "22/11/2025... No data\n",
      "23/11/2025... No data\n",
      "24/11/2025... Trades: 21 (SL:4/TP:0) | PnL: â‚¹-3,795\n",
      "   [RISK] Daily Stop Loss Breached!\n",
      "25/11/2025... Trades: 11 (SL:3/TP:2) | PnL: â‚¹1,200\n",
      "26/11/2025... No data\n",
      "27/11/2025... No data\n",
      "28/11/2025... No data\n",
      "29/11/2025... No data\n",
      "30/11/2025... No data\n",
      "\n",
      "============================================================\n",
      "KINETIC DIRECTIONAL SUMMARY: 11/2025\n",
      "============================================================\n",
      "Total Net PnL:      â‚¹-15,375.00\n",
      "Win Rate:           44.9%\n",
      "Total Trades:       185\n",
      "  - Longs:          93 (â‚¹-19,095)\n",
      "  - Shorts:         92 (â‚¹3,720)\n",
      "\n",
      "Results saved: data/nov_2025_kinetic_directional_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS FUTURES SCALPER: KINETIC DIRECTIONAL BRAIN\n",
    "==============================================\n",
    "Logic:\n",
    "- Detect big kinetic bursts (volume / displacement) like your core bot\n",
    "- On each burst, decide LONG / SHORT using:\n",
    "    * Signed orderflow (uptick vs downtick volume)\n",
    "    * Fast vs slow slopes (trend alignment)\n",
    "    * Position in local range (are we at extremes?)\n",
    "- Only trade when multiple signals agree (vote filter)\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # change if needed\n",
    "\n",
    "# NIFTY Futures Settings\n",
    "LOT_SIZE = 75\n",
    "\n",
    "# Kinetic Directional Brain Params\n",
    "KINETIC_THRESHOLD = 37500      # same spirit as your core bot\n",
    "PRICE_WINDOW = 60              # ticks for local range\n",
    "VOL_WINDOW = 60                # ticks for KE + signed vol\n",
    "FAST_LOOKBACK = 10             # short slope window\n",
    "SLOW_LOOKBACK = 30             # medium slope window\n",
    "MIN_VOTES = 3                  # how strict we are (3+ recommended)\n",
    "\n",
    "# Trade Management\n",
    "MAX_HOLD_SECONDS = 900         # 15 min hold cap\n",
    "STOP_LOSS_POINTS = 25.0        # per lot\n",
    "TAKE_PROFIT_POINTS = 50.0      # per lot\n",
    "\n",
    "# Costs\n",
    "FUTURES_ROUND_TRIP_COST = 1.0  # in index points (both sides combined)\n",
    "\n",
    "# Risk Management\n",
    "DAILY_MAX_LOSS = -3000.0       # INR, hard stop per day\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"KINETIC DIRECTIONAL FUTURES SCALPER - {MONTH}/{YEAR}\")\n",
    "print(f\"Symbol: {SYMBOL}, Contract: {FUT_TS}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation:\n",
    "            kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            continuation = resp.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "    return keys\n",
    "\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# KINETIC DIRECTIONAL BRAIN\n",
    "# ==========================================\n",
    "class KineticDirectionalBrain:\n",
    "    \"\"\"\n",
    "    Directional overlay on top of your Kinetic burst.\n",
    "    Uses:\n",
    "      - Kinetic score (volume / displacement)\n",
    "      - Signed orderflow (volume on upticks vs downticks)\n",
    "      - Short/medium price slope\n",
    "      - Local range position\n",
    "\n",
    "    tick(ltp, volume) -> \n",
    "        0  = no trade\n",
    "        +1 = LONG\n",
    "        -1 = SHORT\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        kinetic_threshold=37500,\n",
    "        price_window=60,\n",
    "        vol_window=60,\n",
    "        fast_lookback=10,\n",
    "        slow_lookback=30,\n",
    "        min_votes=3\n",
    "    ):\n",
    "        self.kinetic_threshold = kinetic_threshold\n",
    "        self.price_window = price_window\n",
    "        self.vol_window = vol_window\n",
    "        self.fast_lookback = fast_lookback\n",
    "        self.slow_lookback = slow_lookback\n",
    "        self.min_votes = min_votes\n",
    "\n",
    "        self.price_buf = deque(maxlen=max(price_window, vol_window))\n",
    "        self.vol_buf = deque(maxlen=vol_window)\n",
    "        self.last_ke_score = 0.0\n",
    "\n",
    "    def _lin_slope(self, arr):\n",
    "        \"\"\"Simple linear regression slope over index 0..n-1.\"\"\"\n",
    "        n = len(arr)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "        x = np.arange(n, dtype=float)\n",
    "        y = np.asarray(arr, dtype=float)\n",
    "        x_mean = x.mean()\n",
    "        y_mean = y.mean()\n",
    "        num = np.sum((x - x_mean) * (y - y_mean))\n",
    "        den = np.sum((x - x_mean) ** 2) + 1e-9\n",
    "        return num / den\n",
    "\n",
    "    def tick(self, ltp, volume):\n",
    "        \"\"\"\n",
    "        Call this for EVERY tick.\n",
    "\n",
    "        Returns:\n",
    "          0  = no signal\n",
    "          +1 = LONG\n",
    "          -1 = SHORT\n",
    "        \"\"\"\n",
    "        ltp = float(ltp)\n",
    "        volume = float(volume)\n",
    "\n",
    "        self.price_buf.append(ltp)\n",
    "        self.vol_buf.append(volume)\n",
    "\n",
    "        if len(self.vol_buf) < self.vol_window or len(self.price_buf) < self.price_window:\n",
    "            return 0\n",
    "\n",
    "        prices = np.asarray(self.price_buf, dtype=float)\n",
    "        vols = np.asarray(self.vol_buf, dtype=float)\n",
    "\n",
    "        # ---------- 1) KINETIC SCORE ----------\n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0.0)\n",
    "        if trade_vol.sum() <= 0:\n",
    "            return 0\n",
    "\n",
    "        displacement = abs(prices[-1] - prices[-self.vol_window])\n",
    "        ke_score = trade_vol.sum() / (displacement + 0.05)\n",
    "        self.last_ke_score = ke_score\n",
    "\n",
    "        if ke_score < self.kinetic_threshold:\n",
    "            return 0\n",
    "\n",
    "        # ---------- 2) SIGNED ORDERFLOW ----------\n",
    "        price_short = prices[-self.vol_window:]\n",
    "        dp = np.diff(price_short)\n",
    "        v = trade_vol[-len(dp):]\n",
    "\n",
    "        signed_vol = np.sum(np.sign(dp) * v)\n",
    "        total_trade_vol = v.sum() + 1e-9\n",
    "        signed_vol_ratio = signed_vol / total_trade_vol  # -1..+1\n",
    "\n",
    "        # ---------- 3) SHORT & MEDIUM SLOPES ----------\n",
    "        fast_len = min(self.fast_lookback, len(prices))\n",
    "        slow_len = min(self.slow_lookback, len(prices))\n",
    "\n",
    "        fast_slice = prices[-fast_len:]\n",
    "        slow_slice = prices[-slow_len:]\n",
    "\n",
    "        fast_slope = self._lin_slope(fast_slice)\n",
    "        slow_slope = self._lin_slope(slow_slice)\n",
    "\n",
    "        price_scale = np.mean(prices[-slow_len:]) + 1e-9\n",
    "        fast_slope_norm = fast_slope / price_scale\n",
    "        slow_slope_norm = slow_slope / price_scale\n",
    "\n",
    "        # ---------- 4) LOCAL RANGE POSITION ----------\n",
    "        window_slice = prices[-self.price_window:]\n",
    "        p_min = window_slice.min()\n",
    "        p_max = window_slice.max()\n",
    "        rng = (p_max - p_min) + 1e-9\n",
    "        range_pos = (window_slice[-1] - p_min) / rng  # 0 = local low, 1 = local high\n",
    "\n",
    "        # ---------- 5) VOTING ----------\n",
    "        long_votes = 0\n",
    "        short_votes = 0\n",
    "\n",
    "        # (a) Signed orderflow bias\n",
    "        if signed_vol_ratio > 0.15:\n",
    "            long_votes += 1\n",
    "        elif signed_vol_ratio < -0.15:\n",
    "            short_votes += 1\n",
    "\n",
    "        # (b) Fast slope\n",
    "        if fast_slope_norm > 0:\n",
    "            long_votes += 1\n",
    "        elif fast_slope_norm < 0:\n",
    "            short_votes += 1\n",
    "\n",
    "        # (c) Slow slope\n",
    "        if slow_slope_norm > 0:\n",
    "            long_votes += 1\n",
    "        elif slow_slope_norm < 0:\n",
    "            short_votes += 1\n",
    "\n",
    "        # (d) Range position\n",
    "        if range_pos > 0.65:\n",
    "            long_votes += 1\n",
    "        elif range_pos < 0.35:\n",
    "            short_votes += 1\n",
    "\n",
    "        # ---------- 6) FINAL DECISION ----------\n",
    "        max_votes = max(long_votes, short_votes)\n",
    "        if max_votes < self.min_votes:\n",
    "            return 0\n",
    "\n",
    "        if long_votes >= short_votes + 1:\n",
    "            return +1\n",
    "        elif short_votes >= long_votes + 1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATA LOADING\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    ok = download_parquet_to_path(key, local_path)\n",
    "    if not ok:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if \"DateTime\" not in df.columns:\n",
    "        if \"Date\" in df.columns and \"Time\" in df.columns:\n",
    "            df[\"DateTime\"] = pd.to_datetime(\n",
    "                df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str),\n",
    "                dayfirst=True,\n",
    "                errors=\"coerce\"\n",
    "            )\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df = df.dropna(subset=[\"DateTime\"])\n",
    "    df[\"LTP\"] = pd.to_numeric(df.get(\"LTP\"), errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"LTP\"])\n",
    "\n",
    "    if \"Volume\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"Volume\"] = 0.0\n",
    "\n",
    "    df = df.sort_values(\"DateTime\").reset_index(drop=True)\n",
    "\n",
    "    # Restrict to normal trading hours (optional)\n",
    "    df = df[\n",
    "        (df[\"DateTime\"].dt.time >= datetime.time(9, 15)) &\n",
    "        (df[\"DateTime\"].dt.time <= datetime.time(15, 15))\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DAY PROCESSING\n",
    "# ==========================================\n",
    "def process_day_trades(df):\n",
    "    brain = KineticDirectionalBrain(\n",
    "        kinetic_threshold=KINETIC_THRESHOLD,\n",
    "        price_window=PRICE_WINDOW,\n",
    "        vol_window=VOL_WINDOW,\n",
    "        fast_lookback=FAST_LOOKBACK,\n",
    "        slow_lookback=SLOW_LOOKBACK,\n",
    "        min_votes=MIN_VOTES\n",
    "    )\n",
    "\n",
    "    trades = []\n",
    "    in_trade = False\n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    side = None\n",
    "    daily_pnl = 0.0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "\n",
    "        # Hard daily stop in INR\n",
    "        if daily_pnl <= DAILY_MAX_LOSS:\n",
    "            break\n",
    "\n",
    "        # ----- Manage open trade -----\n",
    "        if in_trade:\n",
    "            duration = (ts - entry_time).total_seconds()\n",
    "            exit_signal = False\n",
    "            exit_reason = \"\"\n",
    "            pnl_pts = 0.0\n",
    "\n",
    "            if side == \"LONG\":\n",
    "                pnl_pts = ltp - entry_price\n",
    "                if pnl_pts <= -STOP_LOSS_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"SL\"\n",
    "                elif pnl_pts >= TAKE_PROFIT_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"TP\"\n",
    "            else:  # SHORT\n",
    "                pnl_pts = entry_price - ltp\n",
    "                if pnl_pts <= -STOP_LOSS_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"SL\"\n",
    "                elif pnl_pts >= TAKE_PROFIT_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"TP\"\n",
    "\n",
    "            if not exit_signal and duration >= MAX_HOLD_SECONDS:\n",
    "                exit_signal = True\n",
    "                exit_reason = \"TIME\"\n",
    "\n",
    "            if exit_signal:\n",
    "                gross_pnl_inr = pnl_pts * LOT_SIZE\n",
    "                cost_inr = FUTURES_ROUND_TRIP_COST * LOT_SIZE\n",
    "                net_inr = gross_pnl_inr - cost_inr\n",
    "                net_pts_after_cost = pnl_pts - FUTURES_ROUND_TRIP_COST\n",
    "                daily_pnl += net_inr\n",
    "\n",
    "                trades.append({\n",
    "                    \"Date\": ts.date(),\n",
    "                    \"Entry_Time\": entry_time,\n",
    "                    \"Exit_Time\": ts,\n",
    "                    \"Side\": side,\n",
    "                    \"Entry_Price\": entry_price,\n",
    "                    \"Exit_Price\": ltp,\n",
    "                    \"Raw_PnL_Pts\": pnl_pts,\n",
    "                    \"Net_Pts\": net_pts_after_cost,\n",
    "                    \"Net_INR\": net_inr,\n",
    "                    \"Exit_Reason\": exit_reason,\n",
    "                })\n",
    "\n",
    "                in_trade = False\n",
    "                side = None\n",
    "                entry_time = None\n",
    "                entry_price = 0.0\n",
    "                continue\n",
    "\n",
    "        # ----- Generate new signal when flat -----\n",
    "        if not in_trade:\n",
    "            sig = brain.tick(ltp, vol)\n",
    "            if sig == 1:\n",
    "                in_trade = True\n",
    "                side = \"LONG\"\n",
    "                entry_time = ts\n",
    "                entry_price = ltp\n",
    "            elif sig == -1:\n",
    "                in_trade = True\n",
    "                side = \"SHORT\"\n",
    "                entry_time = ts\n",
    "                entry_price = ltp\n",
    "        else:\n",
    "            # Still call brain to keep buffers moving\n",
    "            brain.tick(ltp, vol)\n",
    "\n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "\n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"{day:02d}/{MONTH}/{YEAR}...\", end=\" \")\n",
    "\n",
    "        df = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        if df is None or df.empty:\n",
    "            print(\"No data\")\n",
    "            continue\n",
    "\n",
    "        trades_df = process_day_trades(df)\n",
    "\n",
    "        if trades_df.empty:\n",
    "            print(\"No trades\")\n",
    "            continue\n",
    "\n",
    "        day_pnl = trades_df[\"Net_INR\"].sum()\n",
    "        n_trades = len(trades_df)\n",
    "        sl_hits = (trades_df[\"Exit_Reason\"] == \"SL\").sum()\n",
    "        tp_hits = (trades_df[\"Exit_Reason\"] == \"TP\").sum()\n",
    "\n",
    "        print(f\"Trades: {n_trades} (SL:{sl_hits}/TP:{tp_hits}) | PnL: â‚¹{day_pnl:,.0f}\")\n",
    "        if day_pnl <= DAILY_MAX_LOSS:\n",
    "            print(\"   [RISK] Daily Stop Loss Breached!\")\n",
    "\n",
    "        daily_csv = os.path.join(day_folder, \"futures_directional_results.csv\")\n",
    "        trades_df.to_csv(daily_csv, index=False)\n",
    "        all_trades.append(trades_df)\n",
    "\n",
    "    if not all_trades:\n",
    "        print(\"\\nNo trades for the month.\")\n",
    "        return\n",
    "\n",
    "    full_df = pd.concat(all_trades, ignore_index=True)\n",
    "\n",
    "    total_pnl = full_df[\"Net_INR\"].sum()\n",
    "    win_rate = (full_df[\"Net_Pts\"] > 0).mean() * 100\n",
    "    longs = full_df[full_df[\"Side\"] == \"LONG\"]\n",
    "    shorts = full_df[full_df[\"Side\"] == \"SHORT\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"KINETIC DIRECTIONAL SUMMARY: {MONTH}/{YEAR}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Net PnL:      â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "    print(f\"Total Trades:       {len(full_df)}\")\n",
    "    print(f\"  - Longs:          {len(longs)} (â‚¹{longs['Net_INR'].sum():,.0f})\")\n",
    "    print(f\"  - Shorts:         {len(shorts)} (â‚¹{shorts['Net_INR'].sum():,.0f})\")\n",
    "\n",
    "    out_csv = f\"data/nov_{YEAR}_kinetic_directional_results.csv\"\n",
    "    full_df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nResults saved: {out_csv}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f63ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ORIGINAL KINETIC from 2025-09-01 to 2025-11-26\n",
      "Threshold: 37500 | Hold: 900s | Cost: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Date         | Trades | Daily PnL (Pts) | Status\n",
      "-----------------------------------------------------------------\n",
      "2025-09-01 | 23     |      80.50 pts   | PROFIT\n",
      "2025-09-02 | 22     |    -109.80 pts   | LOSS\n",
      "2025-09-03 | 17     |      85.70 pts   | PROFIT\n",
      "2025-09-04 | 23     |    -176.80 pts   | LOSS\n",
      "2025-09-05 | 23     |     -74.20 pts   | LOSS\n",
      "2025-09-08 | 22     |     -90.50 pts   | LOSS\n",
      "2025-09-09 | 20     |     -26.30 pts   | LOSS\n",
      "2025-09-10 | 23     |      41.00 pts   | PROFIT\n",
      "2025-09-11 | 20     |      59.70 pts   | PROFIT\n",
      "2025-09-12 | 24     |      31.10 pts   | PROFIT\n",
      "2025-09-18 | 23     |      -0.50 pts   | LOSS\n",
      "2025-09-22 | 22     |     -40.40 pts   | LOSS\n",
      "2025-09-23 | 23     |     -79.00 pts   | LOSS\n",
      "2025-09-25 | 22     |    -108.70 pts   | LOSS\n",
      "2025-10-03 | 13     |      74.80 pts   | PROFIT\n",
      "2025-10-06 | 23     |     109.40 pts   | PROFIT\n",
      "2025-10-07 | 23     |      40.40 pts   | PROFIT\n",
      "2025-10-08 | 23     |    -101.00 pts   | LOSS\n",
      "2025-10-09 | 22     |      97.20 pts   | PROFIT\n",
      "2025-10-10 | 23     |     110.40 pts   | PROFIT\n",
      "2025-10-13 | 22     |     -13.50 pts   | LOSS\n",
      "2025-10-14 | 23     |     -81.20 pts   | LOSS\n",
      "2025-10-15 | 23     |     106.10 pts   | PROFIT\n",
      "2025-10-16 | 24     |     101.40 pts   | PROFIT\n",
      "2025-10-17 | 23     |     170.10 pts   | PROFIT\n",
      "2025-10-20 | 22     |    -131.50 pts   | LOSS\n",
      "2025-10-23 | 22     |     -99.20 pts   | LOSS\n",
      "2025-10-24 | 23     |    -156.60 pts   | LOSS\n",
      "2025-10-27 | 23     |      86.20 pts   | PROFIT\n",
      "2025-10-28 | 23     |     -61.30 pts   | LOSS\n",
      "2025-10-31 | 18     |     -76.80 pts   | LOSS\n",
      "2025-11-04 | 23     |    -194.10 pts   | LOSS\n",
      "2025-11-06 | 23     |    -125.50 pts   | LOSS\n",
      "2025-11-07 | 23     |      33.60 pts   | PROFIT\n",
      "2025-11-11 | 23     |      31.40 pts   | PROFIT\n",
      "2025-11-12 | 23     |       8.00 pts   | PROFIT\n",
      "2025-11-13 | 23     |     -14.70 pts   | LOSS\n",
      "2025-11-17 | 23     |      22.00 pts   | PROFIT\n",
      "2025-11-18 | 23     |     -63.50 pts   | LOSS\n",
      "2025-11-19 | 24     |     106.00 pts   | PROFIT\n",
      "2025-11-20 | 23     |      49.70 pts   | PROFIT\n",
      "2025-11-21 | 24     |     -85.00 pts   | LOSS\n",
      "2025-11-24 | 24     |    -159.40 pts   | LOSS\n",
      "2025-11-25 | 10     |    -118.30 pts   | LOSS\n",
      "-----------------------------------------------------------------\n",
      "TOTAL RESULTS:\n",
      "Gross Points: -743.10\n",
      "Total Trades: 969\n",
      "Avg Pts/Day:  -16.89\n",
      "Total INR:    â‚¹-55,732.50\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "# Expiry Dates 2025\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# Strategy Params (From your snippet)\n",
    "KINETIC_THRESHOLD = 37500\n",
    "HOLD_SECONDS = 900\n",
    "COST_PER_TRADE = 1.0     \n",
    "LOT_SIZE = 75\n",
    "\n",
    "# ==========================================\n",
    "# 1. S3 & DATA UTILITIES\n",
    "# ==========================================\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year\n",
    "    month = date_obj.month\n",
    "    day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    \n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    \n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        \n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(\n",
    "                df['Date'].astype(str) + \" \" + df['Time'].astype(str), \n",
    "                dayfirst=True, errors='coerce'\n",
    "            )\n",
    "        \n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        \n",
    "        # Handle Volume\n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "            \n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. ORIGINAL KINETIC BRAIN\n",
    "# ==========================================\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=900):\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.in_trade = False\n",
    "        self.entry_time = 0\n",
    "        self.last_score = 0\n",
    "\n",
    "    # Adapted to accept 'timestamp' argument for backtesting\n",
    "    def process_tick(self, ltp, cumulative_volume, timestamp):\n",
    "        # Convert timestamp to float seconds for calculation\n",
    "        current_time = timestamp.timestamp()\n",
    "        \n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < 50:\n",
    "            return 0\n",
    "            \n",
    "        if self.in_trade:\n",
    "            time_passed = current_time - self.entry_time\n",
    "            if time_passed >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                self.entry_time = 0\n",
    "                return -1 # exit\n",
    "            else:\n",
    "                return 0 # hold\n",
    "                \n",
    "        score = self._calculate_score()\n",
    "        self.last_score = score\n",
    "        \n",
    "        if score > self.threshold:\n",
    "            self.in_trade = True\n",
    "            self.entry_time = current_time\n",
    "            return 1 # enter\n",
    "            \n",
    "        return 0 # wait\n",
    "\n",
    "    def _calculate_score(self):\n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        # Ensure positive volume flow (filter resets)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        \n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        return score\n",
    "\n",
    "# ==========================================\n",
    "# 3. DAILY BACKTEST ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = KineticBrain(threshold=KINETIC_THRESHOLD, hold_seconds=HOLD_SECONDS)\n",
    "    \n",
    "    trades = []\n",
    "    active_trade_price = 0.0\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        sig = brain.process_tick(ltp, vol, ts)\n",
    "        \n",
    "        if sig == 1:\n",
    "            # ENTRY (Long)\n",
    "            active_trade_price = ltp\n",
    "            \n",
    "        elif sig == -1:\n",
    "            # EXIT\n",
    "            pnl = ltp - active_trade_price\n",
    "            trades.append(pnl - COST_PER_TRADE)\n",
    "            active_trade_price = 0.0\n",
    "            \n",
    "    return trades\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Running ORIGINAL KINETIC from {START_DATE} to {END_DATE}\")\n",
    "    print(f\"Threshold: {KINETIC_THRESHOLD} | Hold: {HOLD_SECONDS}s | Cost: {COST_PER_TRADE}\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Date':<12} | {'Trades':<6} | {'Daily PnL (Pts)':<15} | {'Status'}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    current_date = START_DATE\n",
    "    total_points = 0.0\n",
    "    total_trades = 0\n",
    "    date_pnl_map = []\n",
    "    \n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_trades = run_day(df)\n",
    "            daily_pts = sum(daily_trades)\n",
    "            count = len(daily_trades)\n",
    "            \n",
    "            total_points += daily_pts\n",
    "            total_trades += count\n",
    "            \n",
    "            status = \"PROFIT\" if daily_pts > 0 else \"LOSS\" if daily_pts < 0 else \"FLAT\"\n",
    "            print(f\"{current_date} | {count:<6} | {daily_pts:>10.2f} pts   | {status}\")\n",
    "            \n",
    "            date_pnl_map.append({'Date': current_date, 'PnL': daily_pts})\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    print(\"-\" * 65)\n",
    "    print(f\"TOTAL RESULTS:\")\n",
    "    print(f\"Gross Points: {total_points:.2f}\")\n",
    "    print(f\"Total Trades: {total_trades}\")\n",
    "    print(f\"Avg Pts/Day:  {total_points / len(date_pnl_map) if date_pnl_map else 0:.2f}\")\n",
    "    print(f\"Total INR:    â‚¹{total_points * LOT_SIZE:,.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f469a0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DIRECTIONAL KINETIC from 2025-09-01 to 2025-11-26\n",
      "Threshold: 37500 | Hold: 900s | Cost: 1.0\n",
      "-----------------------------------------------------------------\n",
      "Date         | Trades | Daily PnL (Pts) | Status\n",
      "-----------------------------------------------------------------\n",
      "2025-09-01 | 23     |      24.90 pts   | PROFIT\n",
      "2025-09-02 | 22     |     -46.80 pts   | LOSS\n",
      "2025-09-03 | 17     |      65.70 pts   | PROFIT\n",
      "2025-09-04 | 23     |    -162.20 pts   | LOSS\n",
      "2025-09-05 | 23     |     -79.00 pts   | LOSS\n",
      "2025-09-08 | 22     |    -108.90 pts   | LOSS\n",
      "2025-09-09 | 20     |     -54.70 pts   | LOSS\n",
      "2025-09-10 | 23     |      41.00 pts   | PROFIT\n",
      "2025-09-11 | 20     |      59.70 pts   | PROFIT\n",
      "2025-09-12 | 24     |      14.50 pts   | PROFIT\n",
      "2025-09-18 | 23     |     -11.50 pts   | LOSS\n",
      "2025-09-22 | 22     |    -114.40 pts   | LOSS\n",
      "2025-09-23 | 23     |     199.80 pts   | PROFIT\n",
      "2025-09-25 | 22     |     -21.50 pts   | LOSS\n",
      "2025-10-03 | 13     |      54.80 pts   | PROFIT\n",
      "2025-10-06 | 23     |      37.20 pts   | PROFIT\n",
      "2025-10-07 | 23     |     -28.00 pts   | LOSS\n",
      "2025-10-08 | 23     |     -46.60 pts   | LOSS\n",
      "2025-10-09 | 22     |     166.00 pts   | PROFIT\n",
      "2025-10-10 | 23     |     -77.00 pts   | LOSS\n",
      "2025-10-13 | 22     |     -91.90 pts   | LOSS\n",
      "2025-10-14 | 23     |     -84.80 pts   | LOSS\n",
      "2025-10-15 | 23     |      90.10 pts   | PROFIT\n",
      "2025-10-16 | 24     |     102.00 pts   | PROFIT\n",
      "2025-10-17 | 23     |    -176.70 pts   | LOSS\n",
      "2025-10-20 | 22     |      16.90 pts   | PROFIT\n",
      "2025-10-23 | 22     |    -292.60 pts   | LOSS\n",
      "2025-10-24 | 23     |    -294.20 pts   | LOSS\n",
      "2025-10-27 | 23     |    -187.60 pts   | LOSS\n",
      "2025-10-28 | 23     |       2.50 pts   | PROFIT\n",
      "2025-10-31 | 18     |     -47.20 pts   | LOSS\n",
      "2025-11-04 | 23     |    -137.30 pts   | LOSS\n",
      "2025-11-06 | 23     |     -81.50 pts   | LOSS\n",
      "2025-11-07 | 23     |     -59.20 pts   | LOSS\n",
      "2025-11-11 | 23     |      22.00 pts   | PROFIT\n",
      "2025-11-12 | 23     |      60.00 pts   | PROFIT\n",
      "2025-11-13 | 23     |     -90.30 pts   | LOSS\n",
      "2025-11-17 | 23     |     -55.20 pts   | LOSS\n",
      "2025-11-18 | 23     |     -60.10 pts   | LOSS\n",
      "2025-11-19 | 24     |      28.40 pts   | PROFIT\n",
      "2025-11-20 | 23     |     -49.30 pts   | LOSS\n",
      "2025-11-21 | 24     |    -155.40 pts   | LOSS\n",
      "2025-11-24 | 24     |    -238.40 pts   | LOSS\n",
      "2025-11-25 | 10     |    -149.90 pts   | LOSS\n",
      "-----------------------------------------------------------------\n",
      "TOTAL RESULTS:\n",
      "Gross Points: -2016.70\n",
      "Total Trades: 969\n",
      "Avg Pts/Day:  -45.83\n",
      "Total INR:    â‚¹-151,252.50\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "# Expiry Dates 2025\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# Strategy Params (Original)\n",
    "KINETIC_THRESHOLD = 37500\n",
    "HOLD_SECONDS = 900\n",
    "COST_PER_TRADE = 1.0     \n",
    "LOT_SIZE = 75\n",
    "\n",
    "# ==========================================\n",
    "# 1. S3 & DATA UTILITIES\n",
    "# ==========================================\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year\n",
    "    month = date_obj.month\n",
    "    day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    \n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    \n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        \n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(\n",
    "                df['Date'].astype(str) + \" \" + df['Time'].astype(str), \n",
    "                dayfirst=True, errors='coerce'\n",
    "            )\n",
    "        \n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        \n",
    "        # Handle Volume\n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "            \n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. DIRECTIONAL KINETIC BRAIN\n",
    "# ==========================================\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500, hold_seconds=900):\n",
    "        self.threshold = threshold\n",
    "        self.hold_seconds = hold_seconds\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.in_trade = False\n",
    "        self.entry_time = 0\n",
    "        self.last_score = 0\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume, timestamp):\n",
    "        current_time = timestamp.timestamp()\n",
    "        \n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < 50:\n",
    "            return 0\n",
    "            \n",
    "        if self.in_trade:\n",
    "            time_passed = current_time - self.entry_time\n",
    "            if time_passed >= self.hold_seconds:\n",
    "                self.in_trade = False\n",
    "                self.entry_time = 0\n",
    "                return -1 # exit signal\n",
    "            else:\n",
    "                return 0 # hold\n",
    "                \n",
    "        score = self._calculate_score()\n",
    "        self.last_score = score\n",
    "        \n",
    "        if score > self.threshold:\n",
    "            # FIX: Determine direction from price drift in buffer\n",
    "            # Even if displacement is small, the sign tells us the pressure\n",
    "            data = np.array(self.tick_buffer)\n",
    "            price_change = data[-1, 0] - data[0, 0]\n",
    "            \n",
    "            self.in_trade = True\n",
    "            self.entry_time = current_time\n",
    "            \n",
    "            if price_change >= 0:\n",
    "                return 1 # LONG\n",
    "            else:\n",
    "                return 2 # SHORT\n",
    "            \n",
    "        return 0 \n",
    "\n",
    "    def _calculate_score(self):\n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        \n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        return score\n",
    "\n",
    "# ==========================================\n",
    "# 3. DAILY BACKTEST ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = KineticBrain(threshold=KINETIC_THRESHOLD, hold_seconds=HOLD_SECONDS)\n",
    "    \n",
    "    trades = []\n",
    "    active_trade_price = 0.0\n",
    "    direction = 0 # 1 Long, -1 Short\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        sig = brain.process_tick(ltp, vol, ts)\n",
    "        \n",
    "        if sig == 1: # LONG\n",
    "            active_trade_price = ltp\n",
    "            direction = 1\n",
    "            \n",
    "        elif sig == 2: # SHORT\n",
    "            active_trade_price = ltp\n",
    "            direction = -1\n",
    "            \n",
    "        elif sig == -1: # EXIT\n",
    "            pnl = 0\n",
    "            if direction == 1:\n",
    "                pnl = ltp - active_trade_price\n",
    "            elif direction == -1:\n",
    "                pnl = active_trade_price - ltp\n",
    "                \n",
    "            trades.append(pnl - COST_PER_TRADE)\n",
    "            active_trade_price = 0.0\n",
    "            direction = 0\n",
    "            \n",
    "    return trades\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Running DIRECTIONAL KINETIC from {START_DATE} to {END_DATE}\")\n",
    "    print(f\"Threshold: {KINETIC_THRESHOLD} | Hold: {HOLD_SECONDS}s | Cost: {COST_PER_TRADE}\")\n",
    "    print(\"-\" * 65)\n",
    "    print(f\"{'Date':<12} | {'Trades':<6} | {'Daily PnL (Pts)':<15} | {'Status'}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    current_date = START_DATE\n",
    "    total_points = 0.0\n",
    "    total_trades = 0\n",
    "    date_pnl_map = []\n",
    "    \n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_trades = run_day(df)\n",
    "            daily_pts = sum(daily_trades)\n",
    "            count = len(daily_trades)\n",
    "            \n",
    "            total_points += daily_pts\n",
    "            total_trades += count\n",
    "            \n",
    "            status = \"PROFIT\" if daily_pts > 0 else \"LOSS\" if daily_pts < 0 else \"FLAT\"\n",
    "            print(f\"{current_date} | {count:<6} | {daily_pts:>10.2f} pts   | {status}\")\n",
    "            \n",
    "            date_pnl_map.append({'Date': current_date, 'PnL': daily_pts})\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    print(\"-\" * 65)\n",
    "    print(f\"TOTAL RESULTS:\")\n",
    "    print(f\"Gross Points: {total_points:.2f}\")\n",
    "    print(f\"Total Trades: {total_trades}\")\n",
    "    print(f\"Avg Pts/Day:  {total_points / len(date_pnl_map) if date_pnl_map else 0:.2f}\")\n",
    "    print(f\"Total INR:    â‚¹{total_points * LOT_SIZE:,.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b37b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KINETIC MAGNITUDE TEST from 2025-09-01 to 2025-11-26\n",
      "Threshold: 37500 | Measure Window: 900s\n",
      "-----------------------------------------------------------------\n",
      "2025-09-01 | 22 Signals | Avg Move: 17.59 pts\n",
      "2025-09-02 | 22 Signals | Avg Move: 29.28 pts\n",
      "2025-09-03 | 17 Signals | Avg Move: 27.08 pts\n",
      "2025-09-04 | 22 Signals | Avg Move: 31.04 pts\n",
      "2025-09-05 | 22 Signals | Avg Move: 36.62 pts\n",
      "2025-09-08 | 22 Signals | Avg Move: 28.82 pts\n",
      "2025-09-09 | 19 Signals | Avg Move: 18.77 pts\n",
      "2025-09-10 | 23 Signals | Avg Move: 20.67 pts\n",
      "2025-09-11 | 18 Signals | Avg Move: 16.32 pts\n",
      "2025-09-12 | 23 Signals | Avg Move: 12.48 pts\n",
      "2025-09-18 | 22 Signals | Avg Move: 17.09 pts\n",
      "2025-09-22 | 20 Signals | Avg Move: 21.57 pts\n",
      "2025-09-23 | 21 Signals | Avg Move: 26.79 pts\n",
      "2025-09-25 | 22 Signals | Avg Move: 27.22 pts\n",
      "2025-10-03 | 13 Signals | Avg Move: 22.11 pts\n",
      "2025-10-06 | 22 Signals | Avg Move: 21.42 pts\n",
      "2025-10-07 | 22 Signals | Avg Move: 25.55 pts\n",
      "2025-10-08 | 22 Signals | Avg Move: 32.19 pts\n",
      "2025-10-09 | 22 Signals | Avg Move: 29.06 pts\n",
      "2025-10-10 | 21 Signals | Avg Move: 23.63 pts\n",
      "2025-10-13 | 22 Signals | Avg Move: 23.93 pts\n",
      "2025-10-14 | 23 Signals | Avg Move: 31.99 pts\n",
      "2025-10-15 | 22 Signals | Avg Move: 22.77 pts\n",
      "2025-10-16 | 23 Signals | Avg Move: 20.66 pts\n",
      "2025-10-17 | 23 Signals | Avg Move: 37.55 pts\n",
      "2025-10-20 | 21 Signals | Avg Move: 31.53 pts\n",
      "2025-10-23 | 22 Signals | Avg Move: 29.93 pts\n",
      "2025-10-24 | 23 Signals | Avg Move: 32.69 pts\n",
      "2025-10-27 | 22 Signals | Avg Move: 25.03 pts\n",
      "2025-10-28 | 23 Signals | Avg Move: 43.68 pts\n",
      "2025-10-31 | 18 Signals | Avg Move: 23.71 pts\n",
      "2025-11-04 | 23 Signals | Avg Move: 21.18 pts\n",
      "2025-11-06 | 22 Signals | Avg Move: 29.21 pts\n",
      "2025-11-07 | 22 Signals | Avg Move: 32.30 pts\n",
      "2025-11-11 | 23 Signals | Avg Move: 32.84 pts\n",
      "2025-11-12 | 22 Signals | Avg Move: 18.69 pts\n",
      "2025-11-13 | 23 Signals | Avg Move: 28.73 pts\n",
      "2025-11-17 | 22 Signals | Avg Move: 21.72 pts\n",
      "2025-11-18 | 23 Signals | Avg Move: 27.60 pts\n",
      "2025-11-19 | 24 Signals | Avg Move: 24.37 pts\n",
      "2025-11-20 | 23 Signals | Avg Move: 22.72 pts\n",
      "2025-11-21 | 23 Signals | Avg Move: 30.26 pts\n",
      "2025-11-24 | 22 Signals | Avg Move: 23.92 pts\n",
      "2025-11-25 | 10 Signals | Avg Move: 33.03 pts\n",
      "\n",
      "========================================\n",
      "MAGNITUDE DISTRIBUTION (N=941)\n",
      "========================================\n",
      "Moves >= 10  pts: 896   (95.2%)\n",
      "Moves >= 20  pts: 547   (58.1%)\n",
      "Moves >= 30  pts: 267   (28.4%)\n",
      "Moves >= 40  pts: 133   (14.1%)\n",
      "Moves >= 50  pts: 69    (7.3%)\n",
      "Moves >= 75  pts: 16    (1.7%)\n",
      "Moves >= 100 pts: 3     (0.3%)\n",
      "----------------------------------------\n",
      "Average Move: 26.31 pts\n",
      "Median Move:  22.00 pts\n",
      "Max Move:     140.00 pts\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# Strategy Params\n",
    "KINETIC_THRESHOLD = 37500\n",
    "MEASURE_DURATION = 900   # 15 Minutes to measure the \"Bang\"\n",
    "\n",
    "# ==========================================\n",
    "# 1. S3 & DATA UTILITIES\n",
    "# ==========================================\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year\n",
    "    month = date_obj.month\n",
    "    day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    \n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    \n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        \n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(\n",
    "                df['Date'].astype(str) + \" \" + df['Time'].astype(str), \n",
    "                dayfirst=True, errors='coerce'\n",
    "            )\n",
    "        \n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        \n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "            \n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. KINETIC BRAIN (MAGNITUDE ONLY)\n",
    "# ==========================================\n",
    "class KineticBrain:\n",
    "    def __init__(self, threshold=37500):\n",
    "        self.threshold = threshold\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.last_score = 0\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < 50:\n",
    "            return False # Not ready\n",
    "            \n",
    "        score = self._calculate_score()\n",
    "        self.last_score = score\n",
    "        \n",
    "        if score > self.threshold:\n",
    "            return True # SIGNAL FIRED (High Energy)\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def _calculate_score(self):\n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        \n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        return score\n",
    "\n",
    "# ==========================================\n",
    "# 3. MAGNITUDE TEST ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = KineticBrain(threshold=KINETIC_THRESHOLD)\n",
    "    \n",
    "    events = []\n",
    "    \n",
    "    # State\n",
    "    monitoring = False\n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    max_dev = 0.0 # Tracks max absolute move\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        # 1. Update Monitor if active\n",
    "        if monitoring:\n",
    "            elapsed = (ts - entry_time).total_seconds()\n",
    "            current_dev = abs(ltp - entry_price)\n",
    "            \n",
    "            if current_dev > max_dev:\n",
    "                max_dev = current_dev\n",
    "                \n",
    "            if elapsed >= MEASURE_DURATION:\n",
    "                # Event Finished\n",
    "                events.append(max_dev)\n",
    "                monitoring = False\n",
    "                brain.tick_buffer.clear() # Reset brain to find fresh energy\n",
    "            continue # Skip detection while monitoring an event\n",
    "            \n",
    "        # 2. Check Signal\n",
    "        fired = brain.process_tick(ltp, vol)\n",
    "        \n",
    "        if fired:\n",
    "            monitoring = True\n",
    "            entry_time = ts\n",
    "            entry_price = ltp\n",
    "            max_dev = 0.0 # Reset tracker\n",
    "            \n",
    "    return events\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Running KINETIC MAGNITUDE TEST from {START_DATE} to {END_DATE}\")\n",
    "    print(f\"Threshold: {KINETIC_THRESHOLD} | Measure Window: {MEASURE_DURATION}s\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    all_moves = []\n",
    "    \n",
    "    current_date = START_DATE\n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_moves = run_day(df)\n",
    "            all_moves.extend(daily_moves)\n",
    "            \n",
    "            # Optional: Print daily avg just to show progress\n",
    "            avg = sum(daily_moves)/len(daily_moves) if daily_moves else 0\n",
    "            print(f\"{current_date} | {len(daily_moves)} Signals | Avg Move: {avg:.2f} pts\")\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    # --- FINAL STATS ---\n",
    "    total = len(all_moves)\n",
    "    if total == 0:\n",
    "        print(\"No signals found.\")\n",
    "        return\n",
    "\n",
    "    moves = np.array(all_moves)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"MAGNITUDE DISTRIBUTION (N={total})\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    thresholds = [10, 20, 30, 40, 50, 75, 100]\n",
    "    \n",
    "    for t in thresholds:\n",
    "        count = np.sum(moves >= t)\n",
    "        pct = (count / total) * 100\n",
    "        print(f\"Moves >= {t:<3} pts: {count:<5} ({pct:.1f}%)\")\n",
    "        \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Average Move: {np.mean(moves):.2f} pts\")\n",
    "    print(f\"Median Move:  {np.median(moves):.2f} pts\")\n",
    "    print(f\"Max Move:     {np.max(moves):.2f} pts\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44eaf1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Trading_Symbol</th>\n",
       "      <th>Instrument_Token</th>\n",
       "      <th>LTP</th>\n",
       "      <th>LTQ</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_Interest</th>\n",
       "      <th>BestBid</th>\n",
       "      <th>BestAsk</th>\n",
       "      <th>BidSize</th>\n",
       "      <th>AskSize</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>08:46:42.278</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:10:01.994</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:01.722</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24590.0</td>\n",
       "      <td>300</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.471</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24602.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.975</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>75</td>\n",
       "      <td>5700</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>24605.5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213543</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:33.077</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213544</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:34.659</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.5</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213545</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.142</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213546</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.834</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213547</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:36.267</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213548 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date          Time Trading_Symbol  Instrument_Token      LTP  \\\n",
       "0        01/09/2025  08:46:42.278  NIFTY25SEPFUT          13568258  24568.5   \n",
       "1        01/09/2025  09:10:01.994  NIFTY25SEPFUT          13568258  24568.5   \n",
       "2        01/09/2025  09:15:01.722  NIFTY25SEPFUT          13568258  24590.0   \n",
       "3        01/09/2025  09:15:02.471  NIFTY25SEPFUT          13568258  24602.8   \n",
       "4        01/09/2025  09:15:02.975  NIFTY25SEPFUT          13568258  24595.7   \n",
       "...             ...           ...            ...               ...      ...   \n",
       "1213543  13/11/2025  15:29:33.077  NIFTY25NOVFUT           9485826  25957.3   \n",
       "1213544  13/11/2025  15:29:34.659  NIFTY25NOVFUT           9485826  25957.5   \n",
       "1213545  13/11/2025  15:29:35.142  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213546  13/11/2025  15:29:35.834  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213547  13/11/2025  15:29:36.267  NIFTY25NOVFUT           9485826  25950.0   \n",
       "\n",
       "         LTQ   Volume  Open_Interest  BestBid  BestAsk  BidSize  AskSize  \\\n",
       "0         75        0       16610100      0.0      0.0        0        0   \n",
       "1         75        0       16610100      0.0      0.0        0        0   \n",
       "2        300     1050       16610100  24586.6  24597.3      300      300   \n",
       "3         75     1050       16610100  24586.6  24597.3      300      300   \n",
       "4         75     5700       16610100  24595.7  24605.5      300      300   \n",
       "...      ...      ...            ...      ...      ...      ...      ...   \n",
       "1213543   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213544   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213545   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213546   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213547   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "\n",
       "                Ticker  \n",
       "0        NIFTY25SEPFUT  \n",
       "1        NIFTY25SEPFUT  \n",
       "2        NIFTY25SEPFUT  \n",
       "3        NIFTY25SEPFUT  \n",
       "4        NIFTY25SEPFUT  \n",
       "...                ...  \n",
       "1213543  NIFTY25NOVFUT  \n",
       "1213544  NIFTY25NOVFUT  \n",
       "1213545  NIFTY25NOVFUT  \n",
       "1213546  NIFTY25NOVFUT  \n",
       "1213547  NIFTY25NOVFUT  \n",
       "\n",
       "[1213548 rows x 13 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('master_fut_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5efe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING LIVE SIMULATION ON master_fut_df.csv ---\n",
      "Loading CSV (This may take a moment for large files)...\n",
      "Parsing DateTime from 'Date' and 'Time' columns...\n",
      "Loaded 1213548 valid ticks. Starting feed...\n",
      "--- SIMULATION ENDED. Total Trades: 853 ---\n",
      "\n",
      "=== RESULTS SUMMARY ===\n",
      "Total PnL (Points): 622.60\n",
      "Total PnL (INR):    â‚¹46,695.00\n",
      "Win Rate:           51.70%\n",
      "Avg PnL per Trade:  0.73\n",
      "\n",
      "=== FIRST 5 TRADES ===\n",
      "               Entry_Time  Entry_Price               Exit_Time  Exit_Price  \\\n",
      "0 2025-09-01 09:16:04.406      24637.3 2025-09-01 09:31:04.506     24665.1   \n",
      "1 2025-09-01 09:31:36.229      24673.4 2025-09-01 09:46:36.292     24677.3   \n",
      "2 2025-09-01 09:46:37.146      24680.0 2025-09-01 10:01:38.278     24680.0   \n",
      "3 2025-09-01 10:01:44.319      24680.0 2025-09-01 10:16:44.536     24659.5   \n",
      "4 2025-09-01 10:16:54.795      24660.0 2025-09-01 10:31:55.034     24652.0   \n",
      "\n",
      "      Score  PnL_Points      Reason  \n",
      "0   45300.0        27.8  TIME_LIMIT  \n",
      "1  184500.0         3.9  TIME_LIMIT  \n",
      "2  204000.0         0.0  TIME_LIMIT  \n",
      "3  121500.0       -20.5  TIME_LIMIT  \n",
      "4   46500.0        -8.0  TIME_LIMIT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "KINETIC_THRESHOLD = \n",
    "HOLD_SECONDS = 900  # 15 Minutes hold logic\n",
    "\n",
    "# Trading Hours\n",
    "MARKET_START = datetime.time(9, 15)\n",
    "MARKET_END = datetime.time(15, 30)\n",
    "\n",
    "# ==========================================\n",
    "# 1. THE PRODUCTION CLASS (Copy this to your live bot)\n",
    "# ==========================================\n",
    "class LiveKineticBrain:\n",
    "    def __init__(self, threshold=37500):\n",
    "        \"\"\"\n",
    "        Initialize the Kinetic Brain.\n",
    "        :param threshold: The energy score required to trigger a signal.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        # Buffer stores [price, cumulative_volume]\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.last_score = 0.0\n",
    "        self.is_ready = False\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        \"\"\"\n",
    "        Feed a single tick into the brain.\n",
    "        :param ltp: Last Traded Price (float)\n",
    "        :param cumulative_volume: Total Volume / LTQ Sum / Open Interest (float)\n",
    "        :return: True if Signal Fired, False otherwise\n",
    "        \"\"\"\n",
    "        # 1. Store Tick\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        # 2. Warmup Check\n",
    "        if len(self.tick_buffer) < 50:\n",
    "            self.is_ready = False\n",
    "            return False \n",
    "            \n",
    "        self.is_ready = True\n",
    "\n",
    "        # 3. Calculate Score\n",
    "        score = self._calculate_score()\n",
    "        self.last_score = score\n",
    "        \n",
    "        # 4. Check Trigger\n",
    "        if score > self.threshold:\n",
    "            return True # SIGNAL FIRED!\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def _calculate_score(self):\n",
    "        \"\"\"Internal calculation logic (Vectorized for speed)\"\"\"\n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        # Calculate Flow (Positive volume deltas only)\n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        # Calculate Displacement (Price change over 50 ticks)\n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        \n",
    "        # Calculate Energy Score\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        \n",
    "        return score\n",
    "\n",
    "# ==========================================\n",
    "# 2. LIVE SIMULATION (MOCK WEBSOCKET)\n",
    "# ==========================================\n",
    "def simulate_live_market(csv_file_path):\n",
    "    print(f\"--- STARTING LIVE SIMULATION ON {csv_file_path} ---\")\n",
    "    \n",
    "    # Load Data\n",
    "    try:\n",
    "        print(\"Loading CSV (This may take a moment for large files)...\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # --- ROBUST DATE PARSING ---\n",
    "        # Combine Date and Time if they are separate\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            # Format: 01/09/2025 + 08:46:42.278\n",
    "            print(\"Parsing DateTime from 'Date' and 'Time' columns...\")\n",
    "            df['DateTime'] = pd.to_datetime(\n",
    "                df['Date'].astype(str) + ' ' + df['Time'].astype(str), \n",
    "                format='%d/%m/%Y %H:%M:%S.%f', \n",
    "                errors='coerce'\n",
    "            )\n",
    "            # Fallback for rows without millis or different formats if coerce fails\n",
    "            mask_nan = df['DateTime'].isna()\n",
    "            if mask_nan.any():\n",
    "                 df.loc[mask_nan, 'DateTime'] = pd.to_datetime(\n",
    "                    df.loc[mask_nan, 'Date'].astype(str) + ' ' + df.loc[mask_nan, 'Time'].astype(str), \n",
    "                    errors='coerce' # Just drop them if still failing\n",
    "                )\n",
    "        elif 'DateTime' in df.columns:\n",
    "             df['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True)\n",
    "        \n",
    "        # Drop bad rows\n",
    "        df = df.dropna(subset=['DateTime']).sort_values('DateTime').reset_index(drop=True)\n",
    "        print(f\"Loaded {len(df)} valid ticks. Starting feed...\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: File not found.\")\n",
    "        return None\n",
    "\n",
    "    # Initialize the Brain\n",
    "    brain = LiveKineticBrain(threshold=KINETIC_THRESHOLD)\n",
    "    \n",
    "    trades = []\n",
    "    in_trade = False\n",
    "    entry_data = {} \n",
    "    \n",
    "    # --- THE EVENT LOOP ---\n",
    "    for i, row in df.iterrows():\n",
    "        # Extract fields (Handle aliases)\n",
    "        ltp = row.get('LTP') or row.get('LastTradedPrice') or row.get('Close')\n",
    "        vol = row.get('Volume') or row.get('LTQ') or row.get('OpenInterest')\n",
    "        ts = row['DateTime']\n",
    "        \n",
    "        if pd.isna(ltp) or pd.isna(vol): continue\n",
    "            \n",
    "        curr_time = ts.time()\n",
    "        \n",
    "        # 1. FEED THE BRAIN (Always feed to keep buffer current)\n",
    "        signal_fired = brain.process_tick(ltp, vol)\n",
    "        \n",
    "        # 2. TRADE MANAGEMENT\n",
    "        if in_trade:\n",
    "            time_in_trade = (ts - entry_data['Entry_Time']).total_seconds()\n",
    "            should_exit = False\n",
    "            exit_reason = \"\"\n",
    "            \n",
    "            # Condition A: Time Limit\n",
    "            if time_in_trade >= HOLD_SECONDS:\n",
    "                should_exit = True\n",
    "                exit_reason = \"TIME_LIMIT\"\n",
    "            \n",
    "            # Condition B: Market Close Force Exit (15:30)\n",
    "            if curr_time >= MARKET_END:\n",
    "                should_exit = True\n",
    "                exit_reason = \"MARKET_CLOSE\"\n",
    "            \n",
    "            if should_exit:\n",
    "                exit_price = ltp\n",
    "                pnl = exit_price - entry_data['Entry_Price'] # Long Logic\n",
    "                \n",
    "                trades.append({\n",
    "                    'Entry_Time': entry_data['Entry_Time'],\n",
    "                    'Entry_Price': entry_data['Entry_Price'],\n",
    "                    'Exit_Time': ts,\n",
    "                    'Exit_Price': exit_price,\n",
    "                    'Score': entry_data['Score'],\n",
    "                    'PnL_Points': pnl,\n",
    "                    'Reason': exit_reason\n",
    "                })\n",
    "                \n",
    "                # print(f\"ðŸ”´ CLOSED ({exit_reason}) at {ts.time()} | PnL: {pnl:.2f}\")\n",
    "                in_trade = False\n",
    "                entry_data = {}\n",
    "\n",
    "        # 3. ENTRY LOGIC\n",
    "        else:\n",
    "            # Only enter if within Market Hours (09:15 - 15:30)\n",
    "            if curr_time >= MARKET_START and curr_time < MARKET_END:\n",
    "                if signal_fired:\n",
    "                    in_trade = True\n",
    "                    entry_data = {\n",
    "                        'Entry_Time': ts,\n",
    "                        'Entry_Price': ltp,\n",
    "                        'Score': brain.last_score\n",
    "                    }\n",
    "                    # print(f\"ðŸŸ¢ OPEN LONG at {ts.time()} | Price: {ltp} | Score: {brain.last_score:.0f}\")\n",
    "    \n",
    "    # Force close if still open at end of file\n",
    "    if in_trade:\n",
    "         trades.append({\n",
    "            'Entry_Time': entry_data['Entry_Time'],\n",
    "            'Entry_Price': entry_data['Entry_Price'],\n",
    "            'Exit_Time': df.iloc[-1]['DateTime'],\n",
    "            'Exit_Price': df.iloc[-1]['LTP'], # Close at last tick\n",
    "            'Score': entry_data['Score'],\n",
    "            'PnL_Points': df.iloc[-1]['LTP'] - entry_data['Entry_Price'],\n",
    "            'Reason': \"END_OF_DATA\"\n",
    "        })\n",
    "\n",
    "    print(f\"--- SIMULATION ENDED. Total Trades: {len(trades)} ---\")\n",
    "    \n",
    "    # Results\n",
    "    if trades:\n",
    "        trade_df = pd.DataFrame(trades)\n",
    "        \n",
    "        total_pnl = trade_df['PnL_Points'].sum()\n",
    "        win_rate = (trade_df['PnL_Points'] > 0).mean() * 100\n",
    "        \n",
    "        print(\"\\n=== RESULTS SUMMARY ===\")\n",
    "        print(f\"Total PnL (Points): {total_pnl:.2f}\")\n",
    "        print(f\"Total PnL (INR):    â‚¹{total_pnl * 75:,.2f}\")\n",
    "        print(f\"Win Rate:           {win_rate:.2f}%\")\n",
    "        print(f\"Avg PnL per Trade:  {trade_df['PnL_Points'].mean():.2f}\")\n",
    "        \n",
    "        print(\"\\n=== FIRST 5 TRADES ===\")\n",
    "        print(trade_df.head())\n",
    "        return trade_df\n",
    "    else:\n",
    "        print(\"No trades generated.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use 'master_fut_df.csv' if available, otherwise generate dummy\n",
    "    FILENAME = \"master_fut_df.csv\"\n",
    "    \n",
    "    if not os.path.exists(FILENAME):\n",
    "        print(f\"'{FILENAME}' not found. Creating dummy data for demo...\")\n",
    "        dummy_data = {\n",
    "            'Date': ['01/09/2025'] * 3000,\n",
    "            'Time': [pd.Timestamp(f'2025-09-01 09:15:00') + pd.Timedelta(seconds=i) for i in range(3000)],\n",
    "        }\n",
    "        # Convert timestamps back to string format to match user requirement\n",
    "        dummy_data['Time'] = [t.strftime('%H:%M:%S.%f')[:-3] for t in dummy_data['Time']]\n",
    "        \n",
    "        dummy_df = pd.DataFrame(dummy_data)\n",
    "        dummy_df['LTP'] = np.random.normal(24000, 5, 3000)\n",
    "        dummy_df['Volume'] = np.cumsum(np.random.randint(100, 5000, 3000))\n",
    "        \n",
    "        # Spike\n",
    "        dummy_df.loc[100:110, 'Volume'] += 200000\n",
    "        \n",
    "        dummy_df.to_csv(FILENAME, index=False)\n",
    "\n",
    "    df_results = simulate_live_market(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "febcee93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trade_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrade_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trade_df' is not defined"
     ]
    }
   ],
   "source": [
    "trade_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c430e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry_Time</th>\n",
       "      <th>Entry_Price</th>\n",
       "      <th>Exit_Time</th>\n",
       "      <th>Exit_Price</th>\n",
       "      <th>Score</th>\n",
       "      <th>PnL_Points</th>\n",
       "      <th>Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-09-01 09:16:04.406</td>\n",
       "      <td>24637.3</td>\n",
       "      <td>2025-09-01 09:31:04.506</td>\n",
       "      <td>24665.1</td>\n",
       "      <td>45300.000000</td>\n",
       "      <td>27.8</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-09-01 09:31:36.229</td>\n",
       "      <td>24673.4</td>\n",
       "      <td>2025-09-01 09:46:36.292</td>\n",
       "      <td>24677.3</td>\n",
       "      <td>184500.000000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-09-01 09:46:37.146</td>\n",
       "      <td>24680.0</td>\n",
       "      <td>2025-09-01 10:01:38.278</td>\n",
       "      <td>24680.0</td>\n",
       "      <td>204000.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-09-01 10:01:44.319</td>\n",
       "      <td>24680.0</td>\n",
       "      <td>2025-09-01 10:16:44.536</td>\n",
       "      <td>24659.5</td>\n",
       "      <td>121500.000000</td>\n",
       "      <td>-20.5</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-09-01 10:16:54.795</td>\n",
       "      <td>24660.0</td>\n",
       "      <td>2025-09-01 10:31:55.034</td>\n",
       "      <td>24652.0</td>\n",
       "      <td>46500.000000</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>2025-11-13 14:19:43.656</td>\n",
       "      <td>25986.0</td>\n",
       "      <td>2025-11-13 14:34:45.960</td>\n",
       "      <td>25986.8</td>\n",
       "      <td>130500.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>2025-11-13 14:36:57.217</td>\n",
       "      <td>25979.0</td>\n",
       "      <td>2025-11-13 14:51:57.613</td>\n",
       "      <td>25975.0</td>\n",
       "      <td>117000.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>2025-11-13 14:52:39.178</td>\n",
       "      <td>25970.0</td>\n",
       "      <td>2025-11-13 15:07:39.839</td>\n",
       "      <td>25953.0</td>\n",
       "      <td>69000.000000</td>\n",
       "      <td>-17.0</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>2025-11-13 15:07:46.298</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>2025-11-13 15:22:48.527</td>\n",
       "      <td>25958.8</td>\n",
       "      <td>71500.000001</td>\n",
       "      <td>8.8</td>\n",
       "      <td>TIME_LIMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>2025-11-13 15:23:36.935</td>\n",
       "      <td>25959.8</td>\n",
       "      <td>2025-11-13 15:29:36.267</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>45900.000000</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>END_OF_DATA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Entry_Time  Entry_Price               Exit_Time  Exit_Price  \\\n",
       "0   2025-09-01 09:16:04.406      24637.3 2025-09-01 09:31:04.506     24665.1   \n",
       "1   2025-09-01 09:31:36.229      24673.4 2025-09-01 09:46:36.292     24677.3   \n",
       "2   2025-09-01 09:46:37.146      24680.0 2025-09-01 10:01:38.278     24680.0   \n",
       "3   2025-09-01 10:01:44.319      24680.0 2025-09-01 10:16:44.536     24659.5   \n",
       "4   2025-09-01 10:16:54.795      24660.0 2025-09-01 10:31:55.034     24652.0   \n",
       "..                      ...          ...                     ...         ...   \n",
       "848 2025-11-13 14:19:43.656      25986.0 2025-11-13 14:34:45.960     25986.8   \n",
       "849 2025-11-13 14:36:57.217      25979.0 2025-11-13 14:51:57.613     25975.0   \n",
       "850 2025-11-13 14:52:39.178      25970.0 2025-11-13 15:07:39.839     25953.0   \n",
       "851 2025-11-13 15:07:46.298      25950.0 2025-11-13 15:22:48.527     25958.8   \n",
       "852 2025-11-13 15:23:36.935      25959.8 2025-11-13 15:29:36.267     25950.0   \n",
       "\n",
       "             Score  PnL_Points       Reason  \n",
       "0     45300.000000        27.8   TIME_LIMIT  \n",
       "1    184500.000000         3.9   TIME_LIMIT  \n",
       "2    204000.000000         0.0   TIME_LIMIT  \n",
       "3    121500.000000       -20.5   TIME_LIMIT  \n",
       "4     46500.000000        -8.0   TIME_LIMIT  \n",
       "..             ...         ...          ...  \n",
       "848  130500.000000         0.8   TIME_LIMIT  \n",
       "849  117000.000000        -4.0   TIME_LIMIT  \n",
       "850   69000.000000       -17.0   TIME_LIMIT  \n",
       "851   71500.000001         8.8   TIME_LIMIT  \n",
       "852   45900.000000        -9.8  END_OF_DATA  \n",
       "\n",
       "[853 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "633a1ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "622.599999999984"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results['PnL_Points'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02162270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING LIVE SIMULATION ON master_fut_df.csv ---\n",
      "Loading CSV (This may take a moment)...\n",
      "Parsing timestamps...\n",
      "Loaded 1213548 valid ticks (Dropped 0 bad rows).\n",
      "Range: 2025-09-01 08:46:42.278000 to 2025-11-13 15:29:36.267000\n",
      "\n",
      "Processing Tick Stream...\n",
      "Progress: 98.9%\n",
      "\n",
      "--- SIMULATION ENDED. Total Trades: 819 ---\n",
      "\n",
      "=== MAGNITUDE RESULTS SUMMARY ===\n",
      "Total Magnitude Captured (Points): 13613.70\n",
      "Total Magnitude Value (INR):       â‚¹1,021,027.50\n",
      "Non-Zero Moves:                    99.15%\n",
      "Avg Move per Signal:               16.62 pts\n",
      "\n",
      "=== FIRST 5 SIGNALS ===\n",
      "               Entry_Time  Entry_Price               Exit_Time  Exit_Price  \\\n",
      "0 2025-09-01 09:16:04.406      24637.3 2025-09-01 09:31:04.506     24665.1   \n",
      "1 2025-09-01 09:31:36.229      24673.4 2025-09-01 09:46:36.292     24677.3   \n",
      "2 2025-09-01 09:46:37.146      24680.0 2025-09-01 10:01:38.278     24680.0   \n",
      "3 2025-09-01 10:01:44.319      24680.0 2025-09-01 10:16:44.536     24659.5   \n",
      "4 2025-09-01 10:16:54.795      24660.0 2025-09-01 10:31:55.034     24652.0   \n",
      "\n",
      "      Score  PnL_Points      Reason  \n",
      "0   45300.0        27.8  TIME_LIMIT  \n",
      "1  184500.0         3.9  TIME_LIMIT  \n",
      "2  204000.0         0.0  TIME_LIMIT  \n",
      "3  121500.0        20.5  TIME_LIMIT  \n",
      "4   46500.0         8.0  TIME_LIMIT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "KINETIC_THRESHOLD = 37500\n",
    "HOLD_SECONDS = 900  # 15 Minutes hold logic\n",
    "\n",
    "# Trading Hours\n",
    "MARKET_START = datetime.time(9, 15)\n",
    "MARKET_END = datetime.time(15, 30)\n",
    "\n",
    "# ==========================================\n",
    "# 1. THE PRODUCTION CLASS (Copy this to your live bot)\n",
    "# ==========================================\n",
    "class LiveKineticBrain:\n",
    "    def __init__(self, threshold=37500):\n",
    "        \"\"\"\n",
    "        Initialize the Kinetic Brain.\n",
    "        :param threshold: The energy score required to trigger a signal.\n",
    "        \"\"\"\n",
    "        self.threshold = threshold\n",
    "        # Buffer stores [price, cumulative_volume]\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.last_score = 0.0\n",
    "        self.is_ready = False\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        \"\"\"\n",
    "        Feed a single tick into the brain.\n",
    "        :param ltp: Last Traded Price (float)\n",
    "        :param cumulative_volume: Total Volume / LTQ Sum / Open Interest (float)\n",
    "        :return: True if Signal Fired, False otherwise\n",
    "        \"\"\"\n",
    "        # 1. Store Tick\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        # 2. Warmup Check\n",
    "        if len(self.tick_buffer) < 50:\n",
    "            self.is_ready = False\n",
    "            return False \n",
    "            \n",
    "        self.is_ready = True\n",
    "\n",
    "        # 3. Calculate Score\n",
    "        score = self._calculate_score()\n",
    "        self.last_score = score\n",
    "        \n",
    "        # 4. Check Trigger\n",
    "        if score > self.threshold:\n",
    "            return True # SIGNAL FIRED!\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def _calculate_score(self):\n",
    "        \"\"\"Internal calculation logic (Vectorized for speed)\"\"\"\n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        # Calculate Flow (Positive volume deltas only)\n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        # Calculate Displacement (Price change over 50 ticks)\n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        \n",
    "        # Calculate Energy Score\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        \n",
    "        return score\n",
    "\n",
    "# ==========================================\n",
    "# 2. LIVE SIMULATION (MOCK WEBSOCKET)\n",
    "# ==========================================\n",
    "def simulate_live_market(csv_file_path):\n",
    "    print(f\"--- STARTING LIVE SIMULATION ON {csv_file_path} ---\")\n",
    "    \n",
    "    if not os.path.exists(csv_file_path):\n",
    "        print(f\"âŒ ERROR: File '{csv_file_path}' not found.\")\n",
    "        print(\"Please upload 'master_fut_df.csv' to the current directory.\")\n",
    "        return None\n",
    "\n",
    "    # Load Data\n",
    "    try:\n",
    "        print(\"Loading CSV (This may take a moment)...\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # --- ROBUST DATE PARSING ---\n",
    "        print(\"Parsing timestamps...\")\n",
    "        \n",
    "        # Case A: Separate Date and Time columns\n",
    "        if 'Date' in df.columns and 'Time' in df.columns:\n",
    "            # Try fast parsing first\n",
    "            try:\n",
    "                df['DateTime'] = pd.to_datetime(\n",
    "                    df['Date'] + ' ' + df['Time'], \n",
    "                    format='%d/%m/%Y %H:%M:%S.%f', # Matches your data: 01/09/2025 08:46:42.278\n",
    "                    errors='coerce'\n",
    "                )\n",
    "            except:\n",
    "                # Fallback to flexible parsing\n",
    "                 df['DateTime'] = pd.to_datetime(\n",
    "                    df['Date'] + ' ' + df['Time'], \n",
    "                    dayfirst=True,\n",
    "                    errors='coerce'\n",
    "                )\n",
    "                \n",
    "        # Case B: Single DateTime column\n",
    "        elif 'DateTime' in df.columns:\n",
    "             df['DateTime'] = pd.to_datetime(df['DateTime'], dayfirst=True, errors='coerce')\n",
    "        \n",
    "        # Drop invalid rows\n",
    "        initial_len = len(df)\n",
    "        df = df.dropna(subset=['DateTime']).sort_values('DateTime').reset_index(drop=True)\n",
    "        print(f\"Loaded {len(df)} valid ticks (Dropped {initial_len - len(df)} bad rows).\")\n",
    "        print(f\"Range: {df['DateTime'].min()} to {df['DateTime'].max()}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize the Brain\n",
    "    brain = LiveKineticBrain(threshold=KINETIC_THRESHOLD)\n",
    "    \n",
    "    trades = []\n",
    "    in_trade = False\n",
    "    entry_data = {} \n",
    "    \n",
    "    total_ticks = len(df)\n",
    "    print(\"\\nProcessing Tick Stream...\")\n",
    "    \n",
    "    # --- THE EVENT LOOP ---\n",
    "    for i, row in df.iterrows():\n",
    "        if i % 100000 == 0:\n",
    "            sys.stdout.write(f\"\\rProgress: {i/total_ticks*100:.1f}%\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        # Extract fields (Handle aliases)\n",
    "        ltp = row.get('LTP') or row.get('LastTradedPrice') or row.get('Close')\n",
    "        vol = row.get('Volume') or row.get('LTQ') or row.get('OpenInterest')\n",
    "        ts = row['DateTime']\n",
    "        \n",
    "        if pd.isna(ltp) or pd.isna(vol): continue\n",
    "            \n",
    "        curr_time = ts.time()\n",
    "        \n",
    "        # 1. FEED THE BRAIN (Always feed to keep buffer current)\n",
    "        signal_fired = brain.process_tick(ltp, vol)\n",
    "        \n",
    "        # 2. TRADE MANAGEMENT\n",
    "        if in_trade:\n",
    "            time_in_trade = (ts - entry_data['Entry_Time']).total_seconds()\n",
    "            should_exit = False\n",
    "            exit_reason = \"\"\n",
    "            \n",
    "            # Condition A: Time Limit\n",
    "            if time_in_trade >= HOLD_SECONDS:\n",
    "                should_exit = True\n",
    "                exit_reason = \"TIME_LIMIT\"\n",
    "            \n",
    "            # Condition B: Market Close Force Exit (15:30)\n",
    "            if curr_time >= MARKET_END:\n",
    "                should_exit = True\n",
    "                exit_reason = \"MARKET_CLOSE\"\n",
    "            \n",
    "            if should_exit:\n",
    "                exit_price = ltp\n",
    "                # FIX: Use Absolute Difference to measure Magnitude (Pure Volatility)\n",
    "                # This assumes we correctly guessed direction (Perfect Trend Following or Straddle)\n",
    "                pnl = abs(exit_price - entry_data['Entry_Price'])\n",
    "                \n",
    "                trades.append({\n",
    "                    'Entry_Time': entry_data['Entry_Time'],\n",
    "                    'Entry_Price': entry_data['Entry_Price'],\n",
    "                    'Exit_Time': ts,\n",
    "                    'Exit_Price': exit_price,\n",
    "                    'Score': entry_data['Score'],\n",
    "                    'PnL_Points': pnl,\n",
    "                    'Reason': exit_reason\n",
    "                })\n",
    "                \n",
    "                in_trade = False\n",
    "                entry_data = {}\n",
    "\n",
    "        # 3. ENTRY LOGIC\n",
    "        else:\n",
    "            # Only enter if within Market Hours (09:15 - 15:15)\n",
    "            # Also ensure we are not entering right before close\n",
    "            if curr_time >= MARKET_START and curr_time < datetime.time(15, 15):\n",
    "                if signal_fired:\n",
    "                    in_trade = True\n",
    "                    entry_data = {\n",
    "                        'Entry_Time': ts,\n",
    "                        'Entry_Price': ltp,\n",
    "                        'Score': brain.last_score\n",
    "                    }\n",
    "    \n",
    "    # Force close if still open at end of file\n",
    "    if in_trade:\n",
    "         trades.append({\n",
    "            'Entry_Time': entry_data['Entry_Time'],\n",
    "            'Entry_Price': entry_data['Entry_Price'],\n",
    "            'Exit_Time': df.iloc[-1]['DateTime'],\n",
    "            'Exit_Price': df.iloc[-1]['LTP'], \n",
    "            'Score': entry_data['Score'],\n",
    "            'PnL_Points': abs(df.iloc[-1]['LTP'] - entry_data['Entry_Price']),\n",
    "            'Reason': \"END_OF_DATA\"\n",
    "        })\n",
    "\n",
    "    print(f\"\\n\\n--- SIMULATION ENDED. Total Trades: {len(trades)} ---\")\n",
    "    \n",
    "    # Results\n",
    "    if trades:\n",
    "        trade_df = pd.DataFrame(trades)\n",
    "        \n",
    "        total_pnl = trade_df['PnL_Points'].sum()\n",
    "        # Win Rate is redundant here as magnitude is always >= 0, but we can check > 0\n",
    "        win_rate = (trade_df['PnL_Points'] > 0).mean() * 100\n",
    "        \n",
    "        print(\"\\n=== MAGNITUDE RESULTS SUMMARY ===\")\n",
    "        print(f\"Total Magnitude Captured (Points): {total_pnl:.2f}\")\n",
    "        print(f\"Total Magnitude Value (INR):       â‚¹{total_pnl * 75:,.2f}\")\n",
    "        print(f\"Non-Zero Moves:                    {win_rate:.2f}%\")\n",
    "        print(f\"Avg Move per Signal:               {trade_df['PnL_Points'].mean():.2f} pts\")\n",
    "        \n",
    "        print(\"\\n=== FIRST 5 SIGNALS ===\")\n",
    "        print(trade_df.head())\n",
    "        return trade_df\n",
    "    else:\n",
    "        print(\"No trades generated.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FILENAME = \"master_fut_df.csv\"\n",
    "    df_results = simulate_live_market(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1f97edc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('trades_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66231a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running SMART KINETIC HUNTER\n",
      "Range: 2025-09-01 to 2025-11-26\n",
      "Filter: 75.0k < Score < 500k\n",
      "Targets: <100k->20.0pts | >100k->40.0pts\n",
      "---------------------------------------------------------------------------\n",
      "Date         | Trades | Pts Captured | Avg/Trade  | Status\n",
      "---------------------------------------------------------------------------\n",
      "2025-09-01 | 12     |     73.60 pts  |      6.13  | PROFIT\n",
      "2025-09-02 | 12     |    192.80 pts  |     16.07  | PROFIT\n",
      "2025-09-03 | 9      |    105.80 pts  |     11.76  | PROFIT\n",
      "2025-09-04 | 12     |    212.90 pts  |     17.74  | PROFIT\n",
      "2025-09-05 | 13     |    133.40 pts  |     10.26  | PROFIT\n",
      "2025-09-08 | 11     |    151.00 pts  |     13.73  | PROFIT\n",
      "2025-09-09 | 9      |     76.70 pts  |      8.52  | PROFIT\n",
      "2025-09-10 | 12     |    130.80 pts  |     10.90  | PROFIT\n",
      "2025-09-11 | 9      |     53.70 pts  |      5.97  | PROFIT\n",
      "2025-09-12 | 12     |     71.40 pts  |      5.95  | PROFIT\n",
      "2025-09-18 | 11     |    125.80 pts  |     11.44  | PROFIT\n",
      "2025-09-22 | 11     |    163.30 pts  |     14.85  | PROFIT\n",
      "2025-09-23 | 12     |    205.40 pts  |     17.12  | PROFIT\n",
      "2025-09-25 | 12     |    165.60 pts  |     13.80  | PROFIT\n",
      "2025-10-03 | 6      |     60.70 pts  |     10.12  | PROFIT\n",
      "2025-10-06 | 12     |    163.80 pts  |     13.65  | PROFIT\n",
      "2025-10-07 | 14     |    192.70 pts  |     13.76  | PROFIT\n",
      "2025-10-08 | 12     |    294.30 pts  |     24.52  | PROFIT\n",
      "2025-10-09 | 13     |    243.40 pts  |     18.72  | PROFIT\n",
      "2025-10-10 | 13     |    177.00 pts  |     13.62  | PROFIT\n",
      "2025-10-13 | 11     |    141.80 pts  |     12.89  | PROFIT\n",
      "2025-10-14 | 12     |    247.60 pts  |     20.63  | PROFIT\n",
      "2025-10-15 | 12     |    164.90 pts  |     13.74  | PROFIT\n",
      "2025-10-16 | 12     |    169.20 pts  |     14.10  | PROFIT\n",
      "2025-10-17 | 15     |    332.70 pts  |     22.18  | PROFIT\n",
      "2025-10-20 | 12     |    213.40 pts  |     17.78  | PROFIT\n",
      "2025-10-23 | 13     |    248.20 pts  |     19.09  | PROFIT\n",
      "2025-10-24 | 13     |    267.40 pts  |     20.57  | PROFIT\n",
      "2025-10-27 | 13     |    253.70 pts  |     19.52  | PROFIT\n",
      "2025-10-28 | 15     |    308.20 pts  |     20.55  | PROFIT\n",
      "2025-10-31 | 10     |    134.80 pts  |     13.48  | PROFIT\n",
      "2025-11-04 | 13     |    220.30 pts  |     16.95  | PROFIT\n",
      "2025-11-06 | 12     |    218.10 pts  |     18.18  | PROFIT\n",
      "2025-11-07 | 14     |    262.70 pts  |     18.76  | PROFIT\n",
      "2025-11-11 | 14     |    237.00 pts  |     16.93  | PROFIT\n",
      "2025-11-12 | 11     |     87.00 pts  |      7.91  | PROFIT\n",
      "2025-11-13 | 13     |    192.90 pts  |     14.84  | PROFIT\n",
      "2025-11-17 | 12     |    107.40 pts  |      8.95  | PROFIT\n",
      "2025-11-18 | 12     |    216.10 pts  |     18.01  | PROFIT\n",
      "2025-11-19 | 13     |    202.90 pts  |     15.61  | PROFIT\n",
      "2025-11-20 | 13     |    211.50 pts  |     16.27  | PROFIT\n",
      "2025-11-21 | 12     |    184.50 pts  |     15.38  | PROFIT\n",
      "2025-11-24 | 12     |    200.30 pts  |     16.69  | PROFIT\n",
      "2025-11-25 | 7      |    150.60 pts  |     21.51  | PROFIT\n",
      "\n",
      "==================================================\n",
      "SMART MAGNITUDE SUMMARY (N=523)\n",
      "==================================================\n",
      "Total Points Captured: 7967.30\n",
      "Total Value (INR):     â‚¹597,547.50\n",
      "Average Pts/Trade:     15.23\n",
      "Target Hit Rate:       33.3%\n",
      "--------------------------------------------------\n",
      "                     Trades  Avg Pts  Total Pts  Target Hit %\n",
      "Tier                                                         \n",
      "High Energy (>100k)     329    16.02     5269.8         18.54\n",
      "Med Energy (<100k)      194    13.90     2697.5         58.25\n",
      "\n",
      "Detailed logs saved to: smart_kinetic_results.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "# Contract Expiries\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# --- SMART STRATEGY PARAMS ---\n",
    "KINETIC_FLOOR = 75000      # Eliminate Noise (<75k)\n",
    "KINETIC_CEILING = 500000   # Eliminate Exhaustion (>500k)\n",
    "\n",
    "# Tiered Targets\n",
    "HIGH_ENERGY_THRESH = 100000\n",
    "TARGET_LOW_ENERGY = 20.0   # Target for 75k-100k scores\n",
    "TARGET_HIGH_ENERGY = 40.0  # Target for 100k-500k scores\n",
    "\n",
    "MAX_HOLD_SECONDS = 900     # 15 Mins max hold\n",
    "COOLDOWN_SECONDS = 900     # 15 Mins cooldown after trade\n",
    "COST_PER_TRADE = 1.0       # Points slippage/comm\n",
    "LOT_SIZE = 75\n",
    "\n",
    "# ==========================================\n",
    "# 1. S3 & DATA UTILITIES\n",
    "# ==========================================\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year\n",
    "    month = date_obj.month\n",
    "    day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    \n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    \n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        \n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(\n",
    "                df['Date'].astype(str) + \" \" + df['Time'].astype(str), \n",
    "                dayfirst=True, errors='coerce'\n",
    "            )\n",
    "        \n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        \n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "            \n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# 2. KINETIC BRAIN (FILTERED)\n",
    "# ==========================================\n",
    "class KineticBrain:\n",
    "    def __init__(self):\n",
    "        self.tick_buffer = deque(maxlen=50) \n",
    "        self.last_score = 0\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < 50:\n",
    "            return 0 \n",
    "        \n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        \n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        total_vol = np.sum(trade_vol)\n",
    "        \n",
    "        score = total_vol / (displacement + 0.05)\n",
    "        self.last_score = score\n",
    "        \n",
    "        # --- SMART FILTER ---\n",
    "        if score >= KINETIC_FLOOR and score <= KINETIC_CEILING:\n",
    "            return score # Valid Signal\n",
    "            \n",
    "        return 0 # Noise or Exhaustion\n",
    "\n",
    "# ==========================================\n",
    "# 3. SMART MAGNITUDE ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = KineticBrain()\n",
    "    \n",
    "    # State\n",
    "    state = 'SEARCHING' # SEARCHING, MONITORING, COOLDOWN\n",
    "    \n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    active_target = 0.0\n",
    "    active_score = 0.0\n",
    "    \n",
    "    cooldown_start = None\n",
    "    trades = []\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        # --- STATE: COOLDOWN ---\n",
    "        if state == 'COOLDOWN':\n",
    "            if (ts - cooldown_start).total_seconds() > COOLDOWN_SECONDS:\n",
    "                state = 'SEARCHING'\n",
    "                brain.tick_buffer.clear() # Reset brain\n",
    "            continue\n",
    "\n",
    "        # --- STATE: SEARCHING ---\n",
    "        if state == 'SEARCHING':\n",
    "            score = brain.process_tick(ltp, vol)\n",
    "            \n",
    "            if score > 0:\n",
    "                # SIGNAL FIRED\n",
    "                state = 'MONITORING'\n",
    "                entry_time = ts\n",
    "                entry_price = ltp\n",
    "                active_score = score\n",
    "                \n",
    "                # Set Smart Target\n",
    "                if score >= HIGH_ENERGY_THRESH:\n",
    "                    active_target = TARGET_HIGH_ENERGY\n",
    "                else:\n",
    "                    active_target = TARGET_LOW_ENERGY\n",
    "                    \n",
    "        # --- STATE: MONITORING (IN TRADE) ---\n",
    "        elif state == 'MONITORING':\n",
    "            elapsed = (ts - entry_time).total_seconds()\n",
    "            current_move = abs(ltp - entry_price)\n",
    "            \n",
    "            # Check Target Hit (Magnitude Captured)\n",
    "            if current_move >= active_target:\n",
    "                # Success! We captured the full target move\n",
    "                trades.append({\n",
    "                    'Entry_Time': entry_time,\n",
    "                    'Score': active_score,\n",
    "                    'Target': active_target,\n",
    "                    'Captured_Pts': active_target - COST_PER_TRADE, # Net PnL\n",
    "                    'Outcome': 'TARGET_HIT'\n",
    "                })\n",
    "                state = 'COOLDOWN'\n",
    "                cooldown_start = ts\n",
    "                continue\n",
    "                \n",
    "            # Check Time Limit\n",
    "            if elapsed >= MAX_HOLD_SECONDS:\n",
    "                # Time's up! Capture whatever move exists now\n",
    "                final_move = current_move\n",
    "                trades.append({\n",
    "                    'Entry_Time': entry_time,\n",
    "                    'Score': active_score,\n",
    "                    'Target': active_target,\n",
    "                    'Captured_Pts': final_move - COST_PER_TRADE,\n",
    "                    'Outcome': 'TIME_EXIT'\n",
    "                })\n",
    "                state = 'COOLDOWN'\n",
    "                cooldown_start = ts\n",
    "                \n",
    "    return trades\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN LOOP & REPORTING\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(f\"Running SMART KINETIC HUNTER\")\n",
    "    print(f\"Range: {START_DATE} to {END_DATE}\")\n",
    "    print(f\"Filter: {KINETIC_FLOOR/1000:.1f}k < Score < {KINETIC_CEILING/1000:.0f}k\")\n",
    "    print(f\"Targets: <100k->{TARGET_LOW_ENERGY}pts | >100k->{TARGET_HIGH_ENERGY}pts\")\n",
    "    print(\"-\" * 75)\n",
    "    print(f\"{'Date':<12} | {'Trades':<6} | {'Pts Captured':<12} | {'Avg/Trade':<10} | {'Status'}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    all_trades = []\n",
    "    current_date = START_DATE\n",
    "    \n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_trades = run_day(df)\n",
    "            \n",
    "            if daily_trades:\n",
    "                # Convert to DF for easier summation if needed, or just sum dicts\n",
    "                pts = sum(t['Captured_Pts'] for t in daily_trades)\n",
    "                count = len(daily_trades)\n",
    "                avg = pts / count\n",
    "                \n",
    "                status = \"PROFIT\" if pts > 0 else \"LOSS\"\n",
    "                print(f\"{current_date} | {count:<6} | {pts:>9.2f} pts  | {avg:>9.2f}  | {status}\")\n",
    "                \n",
    "                all_trades.extend(daily_trades)\n",
    "            else:\n",
    "                 pass\n",
    "                 # print(f\"{current_date} | 0      |      0.00 pts  |      0.00  | NO SIGNALS\")\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    # --- FINAL REPORT ---\n",
    "    if not all_trades:\n",
    "        print(\"No trades found.\")\n",
    "        return\n",
    "\n",
    "    df_res = pd.DataFrame(all_trades)\n",
    "    \n",
    "    total_pts = df_res['Captured_Pts'].sum()\n",
    "    avg_trade = df_res['Captured_Pts'].mean()\n",
    "    hit_rate = (df_res['Outcome'] == 'TARGET_HIT').mean() * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"SMART MAGNITUDE SUMMARY (N={len(df_res)})\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Points Captured: {total_pts:.2f}\")\n",
    "    print(f\"Total Value (INR):     â‚¹{total_pts * LOT_SIZE:,.2f}\")\n",
    "    print(f\"Average Pts/Trade:     {avg_trade:.2f}\")\n",
    "    print(f\"Target Hit Rate:       {hit_rate:.1f}%\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    # Breakdown by Score Tier\n",
    "    df_res['Tier'] = np.where(df_res['Score'] >= HIGH_ENERGY_THRESH, 'High Energy (>100k)', 'Med Energy (<100k)')\n",
    "    breakdown = df_res.groupby('Tier').agg({\n",
    "        'Captured_Pts': ['count', 'mean', 'sum'],\n",
    "        'Outcome': lambda x: (x == 'TARGET_HIT').mean() * 100\n",
    "    })\n",
    "    breakdown.columns = ['Trades', 'Avg Pts', 'Total Pts', 'Target Hit %']\n",
    "    print(breakdown.round(2))\n",
    "    \n",
    "    # Save for analysis\n",
    "    df_res.to_csv(\"smart_kinetic_results.csv\", index=False)\n",
    "    print(f\"\\nDetailed logs saved to: smart_kinetic_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a04a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KINETIC GRAPH TOPOLOGY STRATEGY\n",
      "Logic: Kinetic > 37500 AND HVG Degree < 3.5\n",
      "Hypothesis: Low Graph Degree = Structural Breakout (Trend)\n",
      "--------------------------------------------------------------------------------\n",
      "2025-09-01 | 13     | 15.4 % | â‚¹  -60,390.00\n",
      "2025-09-02 | 15     | 40.0 % | â‚¹   15,345.00\n",
      "2025-09-03 | 11     | 27.3 % | â‚¹  -17,775.00\n",
      "2025-09-04 | 11     | 72.7 % | â‚¹   67,995.00\n",
      "2025-09-05 | 18     | 16.7 % | â‚¹ -108,495.00\n",
      "2025-09-08 | 14     | 35.7 % | â‚¹   -9,000.00\n",
      "2025-09-09 | 11     | 18.2 % | â‚¹  -40,365.00\n",
      "2025-09-10 | 12     | 66.7 % | â‚¹   31,950.00\n",
      "2025-09-11 | 11     | 54.5 % | â‚¹  -23,985.00\n",
      "2025-09-12 | 12     | 41.7 % | â‚¹  -19,755.00\n",
      "2025-09-18 | 11     | 63.6 % | â‚¹   14,310.00\n",
      "2025-09-22 | 12     | 25.0 % | â‚¹  -50,175.00\n",
      "2025-09-23 | 13     | 30.8 % | â‚¹  -27,000.00\n",
      "2025-09-25 | 13     | 61.5 % | â‚¹   80,415.00\n",
      "2025-10-03 | 6      | 16.7 % | â‚¹  -22,320.00\n",
      "2025-10-06 | 11     | 27.3 % | â‚¹  -45,630.00\n",
      "2025-10-07 | 13     | 53.8 % | â‚¹   47,160.00\n",
      "2025-10-08 | 14     | 42.9 % | â‚¹   22,005.00\n",
      "2025-10-09 | 17     | 23.5 % | â‚¹  -97,245.00\n",
      "2025-10-10 | 13     | 46.2 % | â‚¹   -7,740.00\n",
      "2025-10-13 | 15     | 40.0 % | â‚¹  -41,400.00\n",
      "2025-10-14 | 15     | 40.0 % | â‚¹    5,535.00\n",
      "2025-10-15 | 12     | 25.0 % | â‚¹  -50,040.00\n",
      "2025-10-16 | 13     | 23.1 % | â‚¹  -46,395.00\n",
      "2025-10-17 | 16     | 37.5 % | â‚¹   35,955.00\n",
      "2025-10-20 | 13     | 15.4 % | â‚¹  -64,125.00\n",
      "2025-10-23 | 12     | 41.7 % | â‚¹   36,270.00\n",
      "2025-10-24 | 13     | 38.5 % | â‚¹    9,405.00\n",
      "2025-10-27 | 14     | 28.6 % | â‚¹  -45,000.00\n",
      "2025-10-28 | 17     | 35.3 % | â‚¹   13,725.00\n",
      "2025-10-31 | 8      | 62.5 % | â‚¹   44,775.00\n",
      "2025-11-04 | 12     | 50.0 % | â‚¹   10,350.00\n",
      "2025-11-06 | 13     | 38.5 % | â‚¹    9,990.00\n",
      "2025-11-07 | 18     | 22.2 % | â‚¹  -76,230.00\n",
      "2025-11-11 | 15     | 46.7 % | â‚¹   50,085.00\n",
      "2025-11-12 | 13     | 15.4 % | â‚¹  -58,275.00\n",
      "2025-11-13 | 15     | 26.7 % | â‚¹  -39,375.00\n",
      "2025-11-17 | 13     | 30.8 % | â‚¹  -51,120.00\n",
      "2025-11-18 | 13     | 30.8 % | â‚¹  -13,455.00\n",
      "2025-11-19 | 14     | 42.9 % | â‚¹  -32,715.00\n",
      "2025-11-20 | 14     | 35.7 % | â‚¹  -48,330.00\n",
      "2025-11-21 | 15     | 33.3 % | â‚¹   -1,800.00\n",
      "2025-11-24 | 13     | 38.5 % | â‚¹   -5,175.00\n",
      "2025-11-25 | 7      | 42.9 % | â‚¹    2,610.00\n",
      "\n",
      "==================================================\n",
      "FINAL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "Total Net Profit:      â‚¹-605,430.00\n",
      "Return on Capital:     -60.54%\n",
      "Total Trades:          574\n",
      "Win Rate:              36.24%\n",
      "Avg Profit per Trade:  â‚¹-1,054.76\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "from numba import njit\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# --- STRATEGY: VISIBILITY GRAPH KINETIC ---\n",
    "KINETIC_THRESHOLD = 37500     \n",
    "HVG_WINDOW = 50               # Lookback for Graph Construction\n",
    "\n",
    "# GRAPH FILTER\n",
    "# If Mean Degree is HIGH, price is tangled (Chop) -> AVOID\n",
    "# If Mean Degree is LOW, price is free (Trend) -> ATTACK\n",
    "DEGREE_THRESHOLD = 3.5        # Empirical cutoff for HVG Density\n",
    "\n",
    "# Trade Management (Standard Trend Following)\n",
    "STOP_LOSS_POINTS = 20.0       \n",
    "TAKE_PROFIT_POINTS = 60.0     # 1:3 Risk Reward\n",
    "MAX_HOLD_SECONDS = 1800       \n",
    "COOLDOWN_SECONDS = 300        # 5 Mins (Let the graph reset)\n",
    "COST_PER_TRADE = 1.0          \n",
    "\n",
    "# Capital\n",
    "CAPITAL = 1000000             \n",
    "MARGIN_PER_LOT = 150000       \n",
    "LOT_SIZE = 75\n",
    "NUM_LOTS = int(CAPITAL / MARGIN_PER_LOT) \n",
    "QTY = NUM_LOTS * LOT_SIZE     \n",
    "\n",
    "# ==========================================\n",
    "# 1. NUMBA GRAPH ENGINE (HVG)\n",
    "# ==========================================\n",
    "@njit\n",
    "def calculate_hvg_mean_degree(prices):\n",
    "    \"\"\"\n",
    "    Calculates the Mean Degree of a Horizontal Visibility Graph.\n",
    "    O(N^2) worst case, but fast on small windows (50).\n",
    "    \"\"\"\n",
    "    n = len(prices)\n",
    "    if n < 2: return 0.0\n",
    "    \n",
    "    total_degree = 0\n",
    "    \n",
    "    # Check visibility for every node i\n",
    "    for i in range(n):\n",
    "        current_degree = 0\n",
    "        \n",
    "        # Look backwards\n",
    "        if i > 0:\n",
    "            max_h = -99999999.0\n",
    "            for j in range(i - 1, -1, -1):\n",
    "                # Visibility condition: prices[k] < min(prices[i], prices[j])\n",
    "                # For HVG: Two nodes i and j see each other if all intermediate nodes are smaller\n",
    "                if j == i - 1: # Immediate neighbor always visible\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                elif prices[j] > max_h:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                \n",
    "                # Optimization: If we hit a wall bigger than current node, we can't see past it?\n",
    "                # For HVG specifically: node i sees node j if prices[k] < prices[i] AND prices[k] < prices[j]\n",
    "                # Actually simple HVG: i and j see each other if y_k < min(y_i, y_j) for all k in between.\n",
    "                # My optimized logic above approximates \"looking back\" line of sight.\n",
    "                if prices[j] >= prices[i]: break\n",
    "                \n",
    "        # Look forwards\n",
    "        if i < n - 1:\n",
    "            max_h = -99999999.0\n",
    "            for j in range(i + 1, n):\n",
    "                if j == i + 1:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                elif prices[j] > max_h:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                \n",
    "                if prices[j] >= prices[i]: break\n",
    "        \n",
    "        total_degree += current_degree\n",
    "\n",
    "    return total_degree / n\n",
    "\n",
    "# ==========================================\n",
    "# 2. KINETIC GRAPH BRAIN\n",
    "# ==========================================\n",
    "class KineticGraphBrain:\n",
    "    def __init__(self):\n",
    "        self.tick_buffer = deque(maxlen=HVG_WINDOW) \n",
    "        self.last_score = 0\n",
    "        self.last_degree = 0.0\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < HVG_WINDOW: return 0 \n",
    "        \n",
    "        data = np.array(self.tick_buffer)\n",
    "        prices = data[:, 0]\n",
    "        vols = data[:, 1]\n",
    "        \n",
    "        # 1. Calculate Kinetic (Energy)\n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0)\n",
    "        displacement = abs(prices[-1] - prices[0])\n",
    "        kinetic_score = np.sum(trade_vol) / (displacement + 0.05)\n",
    "        self.last_score = kinetic_score\n",
    "        \n",
    "        # 2. Check Energy Threshold\n",
    "        if kinetic_score > KINETIC_THRESHOLD:\n",
    "            \n",
    "            # 3. Calculate Graph Topology (Structure)\n",
    "            # We pass contiguous numpy array of prices to Numba\n",
    "            mean_degree = calculate_hvg_mean_degree(prices)\n",
    "            self.last_degree = mean_degree\n",
    "            \n",
    "            # 4. The \"Structural Break\" Signal\n",
    "            # Low Degree = Low Connectivity = Unstable/Trend\n",
    "            # High Degree = High Connectivity = Mean Reversion/Chop\n",
    "            \n",
    "            if mean_degree < DEGREE_THRESHOLD:\n",
    "                # Structure is broken -> Follow Momentum\n",
    "                direction = 1 if prices[-1] > prices[0] else -1\n",
    "                return direction\n",
    "                \n",
    "        return 0\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = KineticGraphBrain()\n",
    "    \n",
    "    state = 'SEARCHING'\n",
    "    \n",
    "    entry_price = 0.0\n",
    "    entry_time = None\n",
    "    direction = 0 \n",
    "    \n",
    "    cooldown_start = None\n",
    "    trades = []\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        if state == 'COOLDOWN':\n",
    "            if (ts - cooldown_start).total_seconds() > COOLDOWN_SECONDS:\n",
    "                state = 'SEARCHING'\n",
    "                brain.tick_buffer.clear()\n",
    "            continue\n",
    "\n",
    "        if state == 'SEARCHING':\n",
    "            # Returns 1 (Long), -1 (Short), or 0\n",
    "            sig = brain.process_tick(ltp, vol)\n",
    "            \n",
    "            if sig != 0:\n",
    "                state = 'IN_TRADE'\n",
    "                direction = sig\n",
    "                entry_price = ltp\n",
    "                entry_time = ts\n",
    "                \n",
    "        elif state == 'IN_TRADE':\n",
    "            elapsed = (ts - entry_time).total_seconds()\n",
    "            pnl = 0\n",
    "            exit_reason = None\n",
    "            \n",
    "            # Calc PnL\n",
    "            if direction == 1: pnl = ltp - entry_price\n",
    "            else: pnl = entry_price - ltp\n",
    "            \n",
    "            # Exits\n",
    "            if pnl <= -STOP_LOSS_POINTS: exit_reason = \"SL\"\n",
    "            elif pnl >= TAKE_PROFIT_POINTS: exit_reason = \"TP\"\n",
    "            elif elapsed >= MAX_HOLD_SECONDS: exit_reason = \"TIME\"\n",
    "            \n",
    "            if exit_reason:\n",
    "                net_pts = pnl - COST_PER_TRADE\n",
    "                trades.append({\n",
    "                    'Entry_Time': entry_time,\n",
    "                    'Type': 'LONG' if direction == 1 else 'SHORT',\n",
    "                    'Net_Pts': net_pts,\n",
    "                    'PnL_INR': net_pts * QTY,\n",
    "                    'Reason': exit_reason,\n",
    "                    'Degree': brain.last_degree\n",
    "                })\n",
    "                state = 'COOLDOWN'\n",
    "                cooldown_start = ts\n",
    "                \n",
    "    return trades\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN LOOP\n",
    "# ==========================================\n",
    "# S3 Get Data Function (Reused)\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year; month = date_obj.month; day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + \" \" + df['Time'].astype(str), dayfirst=True, errors='coerce')\n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except: return None\n",
    "\n",
    "def main():\n",
    "    print(f\"Running KINETIC GRAPH TOPOLOGY STRATEGY\")\n",
    "    print(f\"Logic: Kinetic > {KINETIC_THRESHOLD} AND HVG Degree < {DEGREE_THRESHOLD}\")\n",
    "    print(f\"Hypothesis: Low Graph Degree = Structural Breakout (Trend)\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_trades = []\n",
    "    current_date = START_DATE\n",
    "    \n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_trades = run_day(df)\n",
    "            \n",
    "            if daily_trades:\n",
    "                daily_df = pd.DataFrame(daily_trades)\n",
    "                pnl = daily_df['PnL_INR'].sum()\n",
    "                wins = len(daily_df[daily_df['Net_Pts'] > 0])\n",
    "                win_rate = (wins / len(daily_df)) * 100\n",
    "                print(f\"{current_date} | {len(daily_trades):<6} | {win_rate:<5.1f}% | â‚¹{pnl:>12,.2f}\")\n",
    "                all_trades.extend(daily_trades)\n",
    "            else:\n",
    "                print(f\"{current_date} | 0      | -     | â‚¹0.00\")\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    if not all_trades:\n",
    "        print(\"No trades found.\")\n",
    "        return\n",
    "\n",
    "    df_res = pd.DataFrame(all_trades)\n",
    "    \n",
    "    total_pnl = df_res['PnL_INR'].sum()\n",
    "    roi = (total_pnl / CAPITAL) * 100\n",
    "    win_rate = (len(df_res[df_res['Net_Pts'] > 0]) / len(df_res)) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"FINAL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Net Profit:      â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Return on Capital:     {roi:.2f}%\")\n",
    "    print(f\"Total Trades:          {len(df_res)}\")\n",
    "    print(f\"Win Rate:              {win_rate:.2f}%\")\n",
    "    print(f\"Avg Profit per Trade:  â‚¹{df_res['PnL_INR'].mean():,.2f}\")\n",
    "    \n",
    "    df_res.to_csv(\"kinetic_graph_results.csv\", index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3568d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ ðŸ”„ INVERSE LIQUIDITY GRAB STRATEGY\n",
      "Logic: Fade high-volume, low-displacement moves\n",
      "  - Kinetic Threshold: 100000\n",
      "  - Graph Degree < 3.5\n",
      "  - Divergence > 0.4 = TRAP\n",
      "  - Inverse Mode: True\n",
      "--------------------------------------------------------------------------------\n",
      "2025-09-01 | 0      | -     | â‚¹0.00\n",
      "2025-09-02 | 3      | 66.7 % | â‚¹   28,800.00\n",
      "2025-09-03 | 0      | -     | â‚¹0.00\n",
      "2025-09-04 | 2      | 0.0  % | â‚¹  -18,945.00\n",
      "2025-09-05 | 1      | 100.0% | â‚¹    4,500.00\n",
      "2025-09-08 | 0      | -     | â‚¹0.00\n",
      "2025-09-09 | 0      | -     | â‚¹0.00\n",
      "2025-09-10 | 0      | -     | â‚¹0.00\n",
      "2025-09-11 | 0      | -     | â‚¹0.00\n",
      "2025-09-12 | 1      | 100.0% | â‚¹      495.00\n",
      "2025-09-18 | 0      | -     | â‚¹0.00\n",
      "2025-09-22 | 1      | 100.0% | â‚¹    7,695.00\n",
      "2025-09-23 | 3      | 33.3 % | â‚¹    6,435.00\n",
      "2025-09-25 | 2      | 100.0% | â‚¹   30,150.00\n",
      "2025-10-03 | 1      | 0.0  % | â‚¹   -9,540.00\n",
      "2025-10-06 | 5      | 100.0% | â‚¹   36,045.00\n",
      "2025-10-07 | 2      | 100.0% | â‚¹   46,485.00\n",
      "2025-10-08 | 1      | 0.0  % | â‚¹   -9,450.00\n",
      "2025-10-09 | 4      | 25.0 % | â‚¹   -1,935.00\n",
      "2025-10-10 | 0      | -     | â‚¹0.00\n",
      "2025-10-13 | 2      | 50.0 % | â‚¹   -7,650.00\n",
      "2025-10-14 | 2      | 50.0 % | â‚¹    6,930.00\n",
      "2025-10-15 | 2      | 0.0  % | â‚¹  -20,430.00\n",
      "2025-10-16 | 3      | 33.3 % | â‚¹  -17,100.00\n",
      "2025-10-17 | 2      | 50.0 % | â‚¹   15,930.00\n",
      "2025-10-20 | 1      | 0.0  % | â‚¹   -9,450.00\n",
      "2025-10-23 | 3      | 66.7 % | â‚¹   23,085.00\n",
      "2025-10-24 | 1      | 100.0% | â‚¹   15,345.00\n",
      "2025-10-27 | 2      | 50.0 % | â‚¹   14,940.00\n",
      "2025-10-28 | 5      | 0.0  % | â‚¹  -44,505.00\n",
      "2025-10-31 | 2      | 50.0 % | â‚¹    2,835.00\n",
      "2025-11-04 | 1      | 0.0  % | â‚¹   -9,450.00\n",
      "2025-11-06 | 2      | 0.0  % | â‚¹  -19,845.00\n",
      "2025-11-07 | 2      | 50.0 % | â‚¹   -4,410.00\n",
      "2025-11-11 | 1      | 0.0  % | â‚¹   -9,450.00\n",
      "2025-11-12 | 1      | 100.0% | â‚¹   19,980.00\n",
      "2025-11-13 | 2      | 50.0 % | â‚¹   -5,175.00\n",
      "2025-11-17 | 4      | 25.0 % | â‚¹  -26,370.00\n",
      "2025-11-18 | 3      | 33.3 % | â‚¹   -7,515.00\n",
      "2025-11-19 | 4      | 100.0% | â‚¹   26,370.00\n",
      "2025-11-20 | 4      | 25.0 % | â‚¹   -8,100.00\n",
      "2025-11-21 | 4      | 50.0 % | â‚¹   -9,405.00\n",
      "2025-11-24 | 3      | 33.3 % | â‚¹   -5,175.00\n",
      "2025-11-25 | 2      | 0.0  % | â‚¹  -20,430.00\n",
      "\n",
      "==================================================\n",
      "ðŸ’° FINAL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "Total Net Profit:      â‚¹21,690.00\n",
      "Return on Capital:     2.17%\n",
      "Total Trades:          84\n",
      "Win Rate:              45.24%\n",
      "Avg Profit per Trade:  â‚¹258.21\n",
      "\n",
      "ðŸ“Š LIQUIDITY TRAP METRICS:\n",
      "Avg Divergence Score:  0.023\n",
      "DIRECT TRADES: 84 | 45.2% WR | â‚¹21,690.00\n",
      "\n",
      "ðŸŽ¯ DIRECTIONAL BREAKDOWN:\n",
      "LONGS:  48 trades | 50.0% WR | â‚¹68,175.00\n",
      "SHORTS: 36 trades | 38.9% WR | â‚¹-46,485.00\n",
      "\n",
      "âœ… Results saved to: inverse_liquidity_results.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "from io import BytesIO\n",
    "from numba import njit\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "START_DATE = datetime.date(2025, 9, 1)\n",
    "END_DATE = datetime.date(2025, 11, 26)\n",
    "\n",
    "EXPIRY_SEP = datetime.date(2025, 9, 25)\n",
    "EXPIRY_OCT = datetime.date(2025, 10, 30)\n",
    "EXPIRY_NOV = datetime.date(2025, 11, 27)\n",
    "\n",
    "# --- STRATEGY: INVERSE LIQUIDITY GRAB ---\n",
    "KINETIC_THRESHOLD = 100000   \n",
    "HVG_WINDOW = 50               \n",
    "DEGREE_THRESHOLD = 3.5        \n",
    "\n",
    "# PHASE SPACE PARAMETERS\n",
    "EMBEDDING_DIM = 3             \n",
    "EMBEDDING_DELAY = 5           \n",
    "LYAPUNOV_THRESHOLD = 0.15     \n",
    "MOMENTUM_ASYMMETRY_MIN = 0.6  \n",
    "\n",
    "# NEW: LIQUIDITY DETECTION\n",
    "VOLUME_PRICE_DIVERGENCE_MIN = 0.4  # High vol, low price move = trap\n",
    "INVERSE_MODE = True                 # TRADE OPPOSITE OF SIGNAL\n",
    "\n",
    "# Trade Management\n",
    "STOP_LOSS_POINTS = 20.0       \n",
    "TAKE_PROFIT_POINTS = 60.0     \n",
    "MAX_HOLD_SECONDS = 1800       \n",
    "COOLDOWN_SECONDS = 300        \n",
    "COST_PER_TRADE = 1.0          \n",
    "\n",
    "# Capital\n",
    "CAPITAL = 1000000             \n",
    "MARGIN_PER_LOT = 150000       \n",
    "LOT_SIZE = 75\n",
    "NUM_LOTS = int(CAPITAL / MARGIN_PER_LOT) \n",
    "QTY = NUM_LOTS * LOT_SIZE     \n",
    "\n",
    "# ==========================================\n",
    "# 1. NUMBA GRAPH ENGINE (HVG)\n",
    "# ==========================================\n",
    "@njit\n",
    "def calculate_hvg_mean_degree(prices):\n",
    "    n = len(prices)\n",
    "    if n < 2: return 0.0\n",
    "    \n",
    "    total_degree = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        current_degree = 0\n",
    "        \n",
    "        if i > 0:\n",
    "            max_h = -99999999.0\n",
    "            for j in range(i - 1, -1, -1):\n",
    "                if j == i - 1:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                elif prices[j] > max_h:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                \n",
    "                if prices[j] >= prices[i]: break\n",
    "                \n",
    "        if i < n - 1:\n",
    "            max_h = -99999999.0\n",
    "            for j in range(i + 1, n):\n",
    "                if j == i + 1:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                elif prices[j] > max_h:\n",
    "                    current_degree += 1\n",
    "                    max_h = prices[j]\n",
    "                \n",
    "                if prices[j] >= prices[i]: break\n",
    "        \n",
    "        total_degree += current_degree\n",
    "\n",
    "    return total_degree / n\n",
    "\n",
    "# ==========================================\n",
    "# 2. PHASE SPACE TOOLKIT\n",
    "# ==========================================\n",
    "@njit\n",
    "def calculate_lyapunov_local(prices, delay=5, steps=10):\n",
    "    n = len(prices)\n",
    "    if n < delay + steps + 5:\n",
    "        return 0.0\n",
    "    \n",
    "    ref_idx = n - delay - steps - 1\n",
    "    ref_point = prices[ref_idx]\n",
    "    \n",
    "    min_dist = 99999999.0\n",
    "    nearest_idx = -1\n",
    "    \n",
    "    for i in range(10, n - delay - steps - 10):\n",
    "        if abs(i - ref_idx) < 5:\n",
    "            continue\n",
    "        dist = abs(prices[i] - ref_point)\n",
    "        if dist < min_dist and dist > 0.01:\n",
    "            min_dist = dist\n",
    "            nearest_idx = i\n",
    "    \n",
    "    if nearest_idx == -1:\n",
    "        return 0.0\n",
    "    \n",
    "    initial_dist = abs(prices[ref_idx] - prices[nearest_idx])\n",
    "    final_dist = abs(prices[ref_idx + steps] - prices[nearest_idx + steps])\n",
    "    \n",
    "    if initial_dist < 0.01 or final_dist < 0.01:\n",
    "        return 0.0\n",
    "    \n",
    "    lyap = np.log(final_dist / initial_dist) / steps\n",
    "    return lyap\n",
    "\n",
    "@njit\n",
    "def volume_momentum_asymmetry(prices, volumes, window=20):\n",
    "    n = len(prices)\n",
    "    if n < window + 1:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    up_momentum = 0.0\n",
    "    down_momentum = 0.0\n",
    "    \n",
    "    start_idx = n - window\n",
    "    \n",
    "    for i in range(start_idx, n - 1):\n",
    "        price_change = prices[i + 1] - prices[i]\n",
    "        vol_weight = volumes[i + 1]\n",
    "        \n",
    "        if price_change > 0:\n",
    "            up_momentum += price_change * vol_weight\n",
    "        elif price_change < 0:\n",
    "            down_momentum += abs(price_change) * vol_weight\n",
    "    \n",
    "    total_momentum = up_momentum + down_momentum\n",
    "    if total_momentum < 0.01:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    direction = (up_momentum - down_momentum) / total_momentum\n",
    "    confidence = max(up_momentum, down_momentum) / total_momentum\n",
    "    \n",
    "    return direction, confidence\n",
    "\n",
    "@njit\n",
    "def calculate_order_flow_pressure(volumes, prices, window=15):\n",
    "    n = len(volumes)\n",
    "    if n < window + 1:\n",
    "        return 0.0\n",
    "    \n",
    "    buy_volume = 0.0\n",
    "    sell_volume = 0.0\n",
    "    \n",
    "    start_idx = n - window\n",
    "    \n",
    "    for i in range(start_idx + 1, n):\n",
    "        vol_delta = volumes[i] - volumes[i - 1]\n",
    "        if vol_delta <= 0:\n",
    "            continue\n",
    "            \n",
    "        price_change = prices[i] - prices[i - 1]\n",
    "        \n",
    "        if price_change > 0:\n",
    "            buy_volume += vol_delta\n",
    "        elif price_change < 0:\n",
    "            sell_volume += vol_delta\n",
    "        else:\n",
    "            buy_volume += vol_delta * 0.5\n",
    "            sell_volume += vol_delta * 0.5\n",
    "    \n",
    "    total_volume = buy_volume + sell_volume\n",
    "    if total_volume < 1:\n",
    "        return 0.0\n",
    "    \n",
    "    return (buy_volume - sell_volume) / total_volume\n",
    "\n",
    "@njit\n",
    "def calculate_kinetic_energy(volumes, prices):\n",
    "    n = len(volumes)\n",
    "    if n < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    trade_vol_sum = 0.0\n",
    "    for i in range(1, n):\n",
    "        vol_diff = volumes[i] - volumes[i - 1]\n",
    "        if vol_diff > 0:\n",
    "            trade_vol_sum += vol_diff\n",
    "    \n",
    "    displacement = abs(prices[-1] - prices[0])\n",
    "    kinetic = trade_vol_sum / (displacement + 0.05)\n",
    "    \n",
    "    return kinetic\n",
    "\n",
    "@njit\n",
    "def detect_volume_price_divergence(volumes, prices, window=20):\n",
    "    \"\"\"\n",
    "    NEW: Detects when volume is high but price movement is low.\n",
    "    This indicates accumulation/distribution (liquidity grab).\n",
    "    Returns divergence_score: 0 (aligned) to 1 (maximum divergence)\n",
    "    \"\"\"\n",
    "    n = len(volumes)\n",
    "    if n < window + 1:\n",
    "        return 0.0\n",
    "    \n",
    "    start_idx = n - window\n",
    "    \n",
    "    # Calculate volume intensity\n",
    "    total_volume = 0.0\n",
    "    for i in range(start_idx, n):\n",
    "        vol_delta = volumes[i] - volumes[i - 1] if i > 0 else volumes[i]\n",
    "        if vol_delta > 0:\n",
    "            total_volume += vol_delta\n",
    "    \n",
    "    # Calculate price movement\n",
    "    price_range = 0.0\n",
    "    for i in range(start_idx + 1, n):\n",
    "        price_range += abs(prices[i] - prices[i - 1])\n",
    "    \n",
    "    if price_range < 0.01 or total_volume < 1:\n",
    "        return 0.0\n",
    "    \n",
    "    # Normalized metrics\n",
    "    avg_vol = total_volume / window\n",
    "    avg_price_move = price_range / window\n",
    "    \n",
    "    # High volume, low price move = HIGH divergence (liquidity trap)\n",
    "    # We want: high avg_vol relative to avg_price_move\n",
    "    vol_price_ratio = avg_vol / (avg_price_move + 0.01)\n",
    "    \n",
    "    # Normalize to 0-1 range (empirically tuned)\n",
    "    divergence = min(1.0, vol_price_ratio / 50000.0)\n",
    "    \n",
    "    return divergence\n",
    "\n",
    "# ==========================================\n",
    "# 3. INVERSE LIQUIDITY BRAIN\n",
    "# ==========================================\n",
    "class InverseLiquidityBrain:\n",
    "    def __init__(self):\n",
    "        self.tick_buffer = deque(maxlen=HVG_WINDOW) \n",
    "        self.last_score = 0\n",
    "        self.last_degree = 0.0\n",
    "        self.last_lyapunov = 0.0\n",
    "        self.last_direction_score = 0.0\n",
    "        self.last_confidence = 0.0\n",
    "        self.last_order_flow = 0.0\n",
    "        self.last_divergence = 0.0\n",
    "\n",
    "    def process_tick(self, ltp, cumulative_volume):\n",
    "        self.tick_buffer.append([ltp, cumulative_volume])\n",
    "        \n",
    "        if len(self.tick_buffer) < HVG_WINDOW: \n",
    "            return 0, {}\n",
    "        \n",
    "        data = np.array(self.tick_buffer, dtype=np.float64)\n",
    "        prices = np.ascontiguousarray(data[:, 0])\n",
    "        vols = np.ascontiguousarray(data[:, 1])\n",
    "        \n",
    "        # 1. Calculate Kinetic (Energy)\n",
    "        kinetic_score = calculate_kinetic_energy(vols, prices)\n",
    "        self.last_score = kinetic_score\n",
    "        \n",
    "        if kinetic_score <= KINETIC_THRESHOLD:\n",
    "            return 0, {}\n",
    "            \n",
    "        # 2. Calculate Graph Topology\n",
    "        mean_degree = calculate_hvg_mean_degree(prices)\n",
    "        self.last_degree = mean_degree\n",
    "        \n",
    "        if mean_degree >= DEGREE_THRESHOLD:\n",
    "            return 0, {}\n",
    "        \n",
    "        # 3. Lyapunov Exponent\n",
    "        lyap = calculate_lyapunov_local(prices, delay=EMBEDDING_DELAY, steps=10)\n",
    "        self.last_lyapunov = lyap\n",
    "        \n",
    "        # 4. Volume-Weighted Momentum\n",
    "        dir_score, confidence = volume_momentum_asymmetry(prices, vols, window=30)\n",
    "        self.last_direction_score = dir_score\n",
    "        self.last_confidence = confidence\n",
    "        \n",
    "        # 5. Order Flow Pressure\n",
    "        order_flow = calculate_order_flow_pressure(vols, prices, window=20)\n",
    "        self.last_order_flow = order_flow\n",
    "        \n",
    "        # 6. NEW: Volume-Price Divergence Detection\n",
    "        divergence = detect_volume_price_divergence(vols, prices, window=30)\n",
    "        self.last_divergence = divergence\n",
    "        \n",
    "        # ============================================\n",
    "        # LIQUIDITY GRAB LOGIC\n",
    "        # ============================================\n",
    "        \n",
    "        # Require high confidence\n",
    "        if confidence < MOMENTUM_ASYMMETRY_MIN:\n",
    "            return 0, {}\n",
    "        \n",
    "        # Lyapunov filter\n",
    "        if lyap < 0.05 or lyap > 0.3:\n",
    "            return 0, {}\n",
    "        \n",
    "        # NEW: Check for volume-price divergence\n",
    "        # High divergence = liquidity trap = INVERSE THE SIGNAL\n",
    "        is_liquidity_trap = divergence > VOLUME_PRICE_DIVERGENCE_MIN\n",
    "        \n",
    "        # Calculate apparent direction\n",
    "        combined_signal = (0.6 * dir_score) + (0.4 * order_flow)\n",
    "        \n",
    "        if abs(combined_signal) < 0.5:\n",
    "            return 0, {}\n",
    "        \n",
    "        apparent_direction = 1 if combined_signal > 0 else -1\n",
    "        \n",
    "        # THE EDGE: If liquidity trap detected, fade the move\n",
    "        if INVERSE_MODE and is_liquidity_trap:\n",
    "            actual_direction = -1 * apparent_direction\n",
    "            trade_logic = \"INVERSE\"\n",
    "        else:\n",
    "            actual_direction = apparent_direction\n",
    "            trade_logic = \"DIRECT\"\n",
    "        \n",
    "        metrics = {\n",
    "            'kinetic': kinetic_score,\n",
    "            'degree': mean_degree,\n",
    "            'lyapunov': lyap,\n",
    "            'momentum_dir': dir_score,\n",
    "            'confidence': confidence,\n",
    "            'order_flow': order_flow,\n",
    "            'combined_signal': combined_signal,\n",
    "            'divergence': divergence,\n",
    "            'is_trap': is_liquidity_trap,\n",
    "            'trade_logic': trade_logic\n",
    "        }\n",
    "        \n",
    "        return actual_direction, metrics\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXECUTION ENGINE\n",
    "# ==========================================\n",
    "def run_day(df):\n",
    "    brain = InverseLiquidityBrain()\n",
    "    \n",
    "    state = 'SEARCHING'\n",
    "    \n",
    "    entry_price = 0.0\n",
    "    entry_time = None\n",
    "    direction = 0 \n",
    "    entry_metrics = {}\n",
    "    \n",
    "    cooldown_start = None\n",
    "    trades = []\n",
    "    \n",
    "    for row in df.itertuples():\n",
    "        ts = row.DateTime\n",
    "        ltp = row.LTP\n",
    "        vol = row.Volume\n",
    "        \n",
    "        if state == 'COOLDOWN':\n",
    "            if (ts - cooldown_start).total_seconds() > COOLDOWN_SECONDS:\n",
    "                state = 'SEARCHING'\n",
    "                brain.tick_buffer.clear()\n",
    "            continue\n",
    "\n",
    "        if state == 'SEARCHING':\n",
    "            sig, metrics = brain.process_tick(ltp, vol)\n",
    "            \n",
    "            if sig != 0:\n",
    "                state = 'IN_TRADE'\n",
    "                direction = sig\n",
    "                entry_price = ltp\n",
    "                entry_time = ts\n",
    "                entry_metrics = metrics\n",
    "                \n",
    "        elif state == 'IN_TRADE':\n",
    "            elapsed = (ts - entry_time).total_seconds()\n",
    "            pnl = 0\n",
    "            exit_reason = None\n",
    "            \n",
    "            if direction == 1: \n",
    "                pnl = ltp - entry_price\n",
    "            else: \n",
    "                pnl = entry_price - ltp\n",
    "            \n",
    "            if pnl <= -STOP_LOSS_POINTS: \n",
    "                exit_reason = \"SL\"\n",
    "            elif pnl >= TAKE_PROFIT_POINTS: \n",
    "                exit_reason = \"TP\"\n",
    "            elif elapsed >= MAX_HOLD_SECONDS: \n",
    "                exit_reason = \"TIME\"\n",
    "            \n",
    "            if exit_reason:\n",
    "                net_pts = pnl - COST_PER_TRADE\n",
    "                \n",
    "                trade_record = {\n",
    "                    'Entry_Time': entry_time,\n",
    "                    'Type': 'LONG' if direction == 1 else 'SHORT',\n",
    "                    'Net_Pts': net_pts,\n",
    "                    'PnL_INR': net_pts * QTY,\n",
    "                    'Reason': exit_reason,\n",
    "                    'Degree': entry_metrics.get('degree', 0),\n",
    "                    'Lyapunov': entry_metrics.get('lyapunov', 0),\n",
    "                    'Momentum': entry_metrics.get('momentum_dir', 0),\n",
    "                    'Confidence': entry_metrics.get('confidence', 0),\n",
    "                    'OrderFlow': entry_metrics.get('order_flow', 0),\n",
    "                    'Signal': entry_metrics.get('combined_signal', 0),\n",
    "                    'Divergence': entry_metrics.get('divergence', 0),\n",
    "                    'IsTrap': entry_metrics.get('is_trap', False),\n",
    "                    'Logic': entry_metrics.get('trade_logic', 'UNKNOWN')\n",
    "                }\n",
    "                trades.append(trade_record)\n",
    "                \n",
    "                state = 'COOLDOWN'\n",
    "                cooldown_start = ts\n",
    "                \n",
    "    return trades\n",
    "\n",
    "# ==========================================\n",
    "# 5. MAIN LOOP\n",
    "# ==========================================\n",
    "def get_trading_symbol(current_date):\n",
    "    if current_date <= EXPIRY_SEP: return \"NIFTY25SEPFUT\"\n",
    "    elif current_date <= EXPIRY_OCT: return \"NIFTY25OCTFUT\"\n",
    "    else: return \"NIFTY25NOVFUT\"\n",
    "\n",
    "def get_data_for_date(date_obj):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    year = date_obj.year; month = date_obj.month; day = date_obj.day\n",
    "    ts = get_trading_symbol(date_obj)\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{SYMBOL}/{ts}.parquet\"\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        df = pd.read_parquet(BytesIO(obj[\"Body\"].read()))\n",
    "        if 'DateTime' not in df.columns:\n",
    "            df['DateTime'] = pd.to_datetime(df['Date'].astype(str) + \" \" + df['Time'].astype(str), dayfirst=True, errors='coerce')\n",
    "        col_map = {'LastTradedPrice': 'LTP', 'Close': 'LTP'}\n",
    "        df.rename(columns=col_map, inplace=True)\n",
    "        if 'Volume' not in df.columns:\n",
    "            if 'OpenInterest' in df.columns: df['Volume'] = df['OpenInterest']\n",
    "            elif 'LTQ' in df.columns: df['Volume'] = df['LTQ'] \n",
    "            else: df['Volume'] = 0\n",
    "        df = df.dropna(subset=['DateTime', 'LTP']).sort_values('DateTime').reset_index(drop=True)\n",
    "        return df\n",
    "    except: \n",
    "        return None\n",
    "\n",
    "def main():\n",
    "    mode_str = \"ðŸ”„ INVERSE LIQUIDITY GRAB\" if INVERSE_MODE else \"âž¡ï¸ DIRECT MOMENTUM\"\n",
    "    print(f\"ðŸš€ {mode_str} STRATEGY\")\n",
    "    print(f\"Logic: Fade high-volume, low-displacement moves\")\n",
    "    print(f\"  - Kinetic Threshold: {KINETIC_THRESHOLD}\")\n",
    "    print(f\"  - Graph Degree < {DEGREE_THRESHOLD}\")\n",
    "    print(f\"  - Divergence > {VOLUME_PRICE_DIVERGENCE_MIN} = TRAP\")\n",
    "    print(f\"  - Inverse Mode: {INVERSE_MODE}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    all_trades = []\n",
    "    current_date = START_DATE\n",
    "    \n",
    "    while current_date <= END_DATE:\n",
    "        if current_date.weekday() >= 5:\n",
    "            current_date += datetime.timedelta(days=1)\n",
    "            continue\n",
    "            \n",
    "        df = get_data_for_date(current_date)\n",
    "        \n",
    "        if df is not None and not df.empty:\n",
    "            daily_trades = run_day(df)\n",
    "            \n",
    "            if daily_trades:\n",
    "                daily_df = pd.DataFrame(daily_trades)\n",
    "                pnl = daily_df['PnL_INR'].sum()\n",
    "                wins = len(daily_df[daily_df['Net_Pts'] > 0])\n",
    "                win_rate = (wins / len(daily_df)) * 100\n",
    "                print(f\"{current_date} | {len(daily_trades):<6} | {win_rate:<5.1f}% | â‚¹{pnl:>12,.2f}\")\n",
    "                all_trades.extend(daily_trades)\n",
    "            else:\n",
    "                print(f\"{current_date} | 0      | -     | â‚¹0.00\")\n",
    "        \n",
    "        current_date += datetime.timedelta(days=1)\n",
    "        \n",
    "    if not all_trades:\n",
    "        print(\"\\nâŒ No trades found.\")\n",
    "        return\n",
    "\n",
    "    df_res = pd.DataFrame(all_trades)\n",
    "    \n",
    "    total_pnl = df_res['PnL_INR'].sum()\n",
    "    roi = (total_pnl / CAPITAL) * 100\n",
    "    win_rate = (len(df_res[df_res['Net_Pts'] > 0]) / len(df_res)) * 100\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ðŸ’° FINAL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Net Profit:      â‚¹{total_pnl:,.2f}\")\n",
    "    print(f\"Return on Capital:     {roi:.2f}%\")\n",
    "    print(f\"Total Trades:          {len(df_res)}\")\n",
    "    print(f\"Win Rate:              {win_rate:.2f}%\")\n",
    "    print(f\"Avg Profit per Trade:  â‚¹{df_res['PnL_INR'].mean():,.2f}\")\n",
    "    \n",
    "    # Divergence analytics\n",
    "    print(f\"\\nðŸ“Š LIQUIDITY TRAP METRICS:\")\n",
    "    print(f\"Avg Divergence Score:  {df_res['Divergence'].mean():.3f}\")\n",
    "    trap_trades = df_res[df_res['IsTrap'] == True]\n",
    "    direct_trades = df_res[df_res['IsTrap'] == False]\n",
    "    \n",
    "    if len(trap_trades) > 0:\n",
    "        trap_wr = (len(trap_trades[trap_trades['Net_Pts'] > 0]) / len(trap_trades)) * 100\n",
    "        print(f\"TRAP TRADES: {len(trap_trades)} | {trap_wr:.1f}% WR | â‚¹{trap_trades['PnL_INR'].sum():,.2f}\")\n",
    "    \n",
    "    if len(direct_trades) > 0:\n",
    "        direct_wr = (len(direct_trades[direct_trades['Net_Pts'] > 0]) / len(direct_trades)) * 100\n",
    "        print(f\"DIRECT TRADES: {len(direct_trades)} | {direct_wr:.1f}% WR | â‚¹{direct_trades['PnL_INR'].sum():,.2f}\")\n",
    "    \n",
    "    # Directional breakdown\n",
    "    longs = df_res[df_res['Type'] == 'LONG']\n",
    "    shorts = df_res[df_res['Type'] == 'SHORT']\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ DIRECTIONAL BREAKDOWN:\")\n",
    "    if len(longs) > 0:\n",
    "        long_wr = (len(longs[longs['Net_Pts'] > 0]) / len(longs)) * 100\n",
    "        print(f\"LONGS:  {len(longs)} trades | {long_wr:.1f}% WR | â‚¹{longs['PnL_INR'].sum():,.2f}\")\n",
    "    if len(shorts) > 0:\n",
    "        short_wr = (len(shorts[shorts['Net_Pts'] > 0]) / len(shorts)) * 100\n",
    "        print(f\"SHORTS: {len(shorts)} trades | {short_wr:.1f}% WR | â‚¹{shorts['PnL_INR'].sum():,.2f}\")\n",
    "    \n",
    "    df_res.to_csv(\"inverse_liquidity_results.csv\", index=False)\n",
    "    print(f\"\\nâœ… Results saved to: inverse_liquidity_results.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "089bcdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Trading_Symbol</th>\n",
       "      <th>Instrument_Token</th>\n",
       "      <th>LTP</th>\n",
       "      <th>LTQ</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_Interest</th>\n",
       "      <th>BestBid</th>\n",
       "      <th>BestAsk</th>\n",
       "      <th>BidSize</th>\n",
       "      <th>AskSize</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>08:46:42.278</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:10:01.994</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:01.722</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24590.0</td>\n",
       "      <td>300</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.471</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24602.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.975</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>75</td>\n",
       "      <td>5700</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>24605.5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213543</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:33.077</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213544</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:34.659</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.5</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213545</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.142</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213546</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.834</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213547</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:36.267</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213548 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date          Time Trading_Symbol  Instrument_Token      LTP  \\\n",
       "0        01/09/2025  08:46:42.278  NIFTY25SEPFUT          13568258  24568.5   \n",
       "1        01/09/2025  09:10:01.994  NIFTY25SEPFUT          13568258  24568.5   \n",
       "2        01/09/2025  09:15:01.722  NIFTY25SEPFUT          13568258  24590.0   \n",
       "3        01/09/2025  09:15:02.471  NIFTY25SEPFUT          13568258  24602.8   \n",
       "4        01/09/2025  09:15:02.975  NIFTY25SEPFUT          13568258  24595.7   \n",
       "...             ...           ...            ...               ...      ...   \n",
       "1213543  13/11/2025  15:29:33.077  NIFTY25NOVFUT           9485826  25957.3   \n",
       "1213544  13/11/2025  15:29:34.659  NIFTY25NOVFUT           9485826  25957.5   \n",
       "1213545  13/11/2025  15:29:35.142  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213546  13/11/2025  15:29:35.834  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213547  13/11/2025  15:29:36.267  NIFTY25NOVFUT           9485826  25950.0   \n",
       "\n",
       "         LTQ   Volume  Open_Interest  BestBid  BestAsk  BidSize  AskSize  \\\n",
       "0         75        0       16610100      0.0      0.0        0        0   \n",
       "1         75        0       16610100      0.0      0.0        0        0   \n",
       "2        300     1050       16610100  24586.6  24597.3      300      300   \n",
       "3         75     1050       16610100  24586.6  24597.3      300      300   \n",
       "4         75     5700       16610100  24595.7  24605.5      300      300   \n",
       "...      ...      ...            ...      ...      ...      ...      ...   \n",
       "1213543   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213544   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213545   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213546   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213547   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "\n",
       "                Ticker  \n",
       "0        NIFTY25SEPFUT  \n",
       "1        NIFTY25SEPFUT  \n",
       "2        NIFTY25SEPFUT  \n",
       "3        NIFTY25SEPFUT  \n",
       "4        NIFTY25SEPFUT  \n",
       "...                ...  \n",
       "1213543  NIFTY25NOVFUT  \n",
       "1213544  NIFTY25NOVFUT  \n",
       "1213545  NIFTY25NOVFUT  \n",
       "1213546  NIFTY25NOVFUT  \n",
       "1213547  NIFTY25NOVFUT  \n",
       "\n",
       "[1213548 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"master_fut_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d0a7a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Trading_Symbol</th>\n",
       "      <th>Instrument_Token</th>\n",
       "      <th>LTP</th>\n",
       "      <th>LTQ</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_Interest</th>\n",
       "      <th>BestBid</th>\n",
       "      <th>BestAsk</th>\n",
       "      <th>BidSize</th>\n",
       "      <th>AskSize</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>08:46:42.278</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:10:01.994</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:01.722</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24590.0</td>\n",
       "      <td>300</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.471</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24602.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.975</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>75</td>\n",
       "      <td>5700</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>24605.5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213543</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:33.077</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213544</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:34.659</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.5</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213545</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.142</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213546</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.834</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213547</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:36.267</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213548 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date          Time Trading_Symbol  Instrument_Token      LTP  \\\n",
       "0        01/09/2025  08:46:42.278  NIFTY25SEPFUT          13568258  24568.5   \n",
       "1        01/09/2025  09:10:01.994  NIFTY25SEPFUT          13568258  24568.5   \n",
       "2        01/09/2025  09:15:01.722  NIFTY25SEPFUT          13568258  24590.0   \n",
       "3        01/09/2025  09:15:02.471  NIFTY25SEPFUT          13568258  24602.8   \n",
       "4        01/09/2025  09:15:02.975  NIFTY25SEPFUT          13568258  24595.7   \n",
       "...             ...           ...            ...               ...      ...   \n",
       "1213543  13/11/2025  15:29:33.077  NIFTY25NOVFUT           9485826  25957.3   \n",
       "1213544  13/11/2025  15:29:34.659  NIFTY25NOVFUT           9485826  25957.5   \n",
       "1213545  13/11/2025  15:29:35.142  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213546  13/11/2025  15:29:35.834  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213547  13/11/2025  15:29:36.267  NIFTY25NOVFUT           9485826  25950.0   \n",
       "\n",
       "         LTQ   Volume  Open_Interest  BestBid  BestAsk  BidSize  AskSize  \\\n",
       "0         75        0       16610100      0.0      0.0        0        0   \n",
       "1         75        0       16610100      0.0      0.0        0        0   \n",
       "2        300     1050       16610100  24586.6  24597.3      300      300   \n",
       "3         75     1050       16610100  24586.6  24597.3      300      300   \n",
       "4         75     5700       16610100  24595.7  24605.5      300      300   \n",
       "...      ...      ...            ...      ...      ...      ...      ...   \n",
       "1213543   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213544   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213545   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213546   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213547   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "\n",
       "                Ticker  \n",
       "0        NIFTY25SEPFUT  \n",
       "1        NIFTY25SEPFUT  \n",
       "2        NIFTY25SEPFUT  \n",
       "3        NIFTY25SEPFUT  \n",
       "4        NIFTY25SEPFUT  \n",
       "...                ...  \n",
       "1213543  NIFTY25NOVFUT  \n",
       "1213544  NIFTY25NOVFUT  \n",
       "1213545  NIFTY25NOVFUT  \n",
       "1213546  NIFTY25NOVFUT  \n",
       "1213547  NIFTY25NOVFUT  \n",
       "\n",
       "[1213548 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('master_fut_df.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5531f7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Trading_Symbol</th>\n",
       "      <th>Instrument_Token</th>\n",
       "      <th>LTP</th>\n",
       "      <th>LTQ</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open_Interest</th>\n",
       "      <th>BestBid</th>\n",
       "      <th>BestAsk</th>\n",
       "      <th>BidSize</th>\n",
       "      <th>AskSize</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>08:46:42.278</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:10:01.994</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24568.5</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16610100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:01.722</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24590.0</td>\n",
       "      <td>300</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.471</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24602.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1050</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24586.6</td>\n",
       "      <td>24597.3</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/09/2025</td>\n",
       "      <td>09:15:02.975</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "      <td>13568258</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>75</td>\n",
       "      <td>5700</td>\n",
       "      <td>16610100</td>\n",
       "      <td>24595.7</td>\n",
       "      <td>24605.5</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>NIFTY25SEPFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213543</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:33.077</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213544</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:34.659</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25957.5</td>\n",
       "      <td>75</td>\n",
       "      <td>5163450</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25951.3</td>\n",
       "      <td>25957.3</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213545</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.142</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213546</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:35.834</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213547</th>\n",
       "      <td>13/11/2025</td>\n",
       "      <td>15:29:36.267</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "      <td>9485826</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>75</td>\n",
       "      <td>5164350</td>\n",
       "      <td>17647575</td>\n",
       "      <td>25950.0</td>\n",
       "      <td>25951.0</td>\n",
       "      <td>1725</td>\n",
       "      <td>825</td>\n",
       "      <td>NIFTY25NOVFUT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1213548 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date          Time Trading_Symbol  Instrument_Token      LTP  \\\n",
       "0        01/09/2025  08:46:42.278  NIFTY25SEPFUT          13568258  24568.5   \n",
       "1        01/09/2025  09:10:01.994  NIFTY25SEPFUT          13568258  24568.5   \n",
       "2        01/09/2025  09:15:01.722  NIFTY25SEPFUT          13568258  24590.0   \n",
       "3        01/09/2025  09:15:02.471  NIFTY25SEPFUT          13568258  24602.8   \n",
       "4        01/09/2025  09:15:02.975  NIFTY25SEPFUT          13568258  24595.7   \n",
       "...             ...           ...            ...               ...      ...   \n",
       "1213543  13/11/2025  15:29:33.077  NIFTY25NOVFUT           9485826  25957.3   \n",
       "1213544  13/11/2025  15:29:34.659  NIFTY25NOVFUT           9485826  25957.5   \n",
       "1213545  13/11/2025  15:29:35.142  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213546  13/11/2025  15:29:35.834  NIFTY25NOVFUT           9485826  25950.0   \n",
       "1213547  13/11/2025  15:29:36.267  NIFTY25NOVFUT           9485826  25950.0   \n",
       "\n",
       "         LTQ   Volume  Open_Interest  BestBid  BestAsk  BidSize  AskSize  \\\n",
       "0         75        0       16610100      0.0      0.0        0        0   \n",
       "1         75        0       16610100      0.0      0.0        0        0   \n",
       "2        300     1050       16610100  24586.6  24597.3      300      300   \n",
       "3         75     1050       16610100  24586.6  24597.3      300      300   \n",
       "4         75     5700       16610100  24595.7  24605.5      300      300   \n",
       "...      ...      ...            ...      ...      ...      ...      ...   \n",
       "1213543   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213544   75  5163450       17647575  25951.3  25957.3       75      150   \n",
       "1213545   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213546   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "1213547   75  5164350       17647575  25950.0  25951.0     1725      825   \n",
       "\n",
       "                Ticker  \n",
       "0        NIFTY25SEPFUT  \n",
       "1        NIFTY25SEPFUT  \n",
       "2        NIFTY25SEPFUT  \n",
       "3        NIFTY25SEPFUT  \n",
       "4        NIFTY25SEPFUT  \n",
       "...                ...  \n",
       "1213543  NIFTY25NOVFUT  \n",
       "1213544  NIFTY25NOVFUT  \n",
       "1213545  NIFTY25NOVFUT  \n",
       "1213546  NIFTY25NOVFUT  \n",
       "1213547  NIFTY25NOVFUT  \n",
       "\n",
       "[1213548 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"master_fut_df.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf8caac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"master_fut_df.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebbab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
