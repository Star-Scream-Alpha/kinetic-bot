{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc524eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      "DELTA-HEDGED GAMMA SCALPING\n",
      "==============================\n",
      "\n",
      "Loading futures data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NIFTY20NOV.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 89\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# LOAD FUTURES DATA (NIFTY20NOV.csv)\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading futures data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m fut_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFUT_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Expecting columns: 'Date', 'Time', 'LTP'\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Adjust if your columns have different names\u001b[39;00m\n\u001b[1;32m     93\u001b[0m fut_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\n\u001b[1;32m     94\u001b[0m     fut_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fut_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.\u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     96\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     97\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NIFTY20NOV.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "FUT_FILE = \"NIFTY20NOV.csv\"                 # futures tick file\n",
    "TRADES_FILE = \"kinetic_full_backtest_trades.csv\" # kinetic backtest output with Entry/Exit\n",
    "OPTION_PREFIX = \"NIFTY25NOV\"                # prefix for options files\n",
    "STRIKES = [26100, 26150, 26200, 26250, 26300]  # strikes you have\n",
    "LOT_SIZE = 75                               # NIFTY lot\n",
    "HEDGE_STEP_THRESHOLD = 0.02                 # min delta change to rebalance (in futures)\n",
    "HEDGE_COST_PER_CONTRACT = 0.2               # points per futures contract per hedge (slippage+fees)\n",
    "EXPIRY_DATE = pd.Timestamp(\"2025-11-27\")    # <-- SET CORRECT EXPIRY HERE\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"DELTA-HEDGED GAMMA SCALPING\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: NORMAL PDF & CDF\n",
    "# ==========================================\n",
    "def norm_pdf(x):\n",
    "    return 1.0 / math.sqrt(2 * math.pi) * math.exp(-0.5 * x * x)\n",
    "\n",
    "def norm_cdf(x):\n",
    "    # Using error function approximation\n",
    "    return 0.5 * (1 + math.erf(x / math.sqrt(2)))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# BLACK-SCHOLES: CALL PRICE & DELTA\n",
    "# ==========================================\n",
    "def bs_call_price(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return max(S - K, 0.0)\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    d2 = d1 - sigma * sqrtT\n",
    "    return S * norm_cdf(d1) - K * math.exp(-r * T) * norm_cdf(d2)\n",
    "\n",
    "def bs_call_delta(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return 1.0 if S > K else 0.0\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    return norm_cdf(d1)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# IMPLIED VOL (BISECTION)\n",
    "# ==========================================\n",
    "def implied_vol_call_bisect(market_price, S, K, T, r=0.0, \n",
    "                            sigma_low=0.0001, sigma_high=3.0, \n",
    "                            tol=1e-4, max_iter=50):\n",
    "    \"\"\"Simple bisection implied vol for call. Returns sigma or None.\"\"\"\n",
    "    if T <= 0:\n",
    "        return None\n",
    "\n",
    "    # Check bounds\n",
    "    price_low = bs_call_price(S, K, T, sigma_low, r)\n",
    "    price_high = bs_call_price(S, K, T, sigma_high, r)\n",
    "    if price_low > market_price or price_high < market_price:\n",
    "        # Outside theoretical range, fallback\n",
    "        return None\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        sigma_mid = 0.5 * (sigma_low + sigma_high)\n",
    "        price_mid = bs_call_price(S, K, T, sigma_mid, r)\n",
    "\n",
    "        if abs(price_mid - market_price) < tol:\n",
    "            return sigma_mid\n",
    "\n",
    "        if price_mid > market_price:\n",
    "            sigma_high = sigma_mid\n",
    "        else:\n",
    "            sigma_low = sigma_mid\n",
    "\n",
    "    return sigma_mid\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD FUTURES DATA (NIFTY20NOV.csv)\n",
    "# ==========================================\n",
    "print(\"Loading futures data...\")\n",
    "fut_df = pd.read_csv(FUT_FILE)\n",
    "\n",
    "# Expecting columns: 'Date', 'Time', 'LTP'\n",
    "# Adjust if your columns have different names\n",
    "fut_df['DateTime'] = pd.to_datetime(\n",
    "    fut_df['Date'] + ' ' + fut_df['Time'],\n",
    "    format='%d/%m/%Y %H:%M:%S.%f',\n",
    "    errors='coerce'\n",
    ")\n",
    "fut_df = fut_df.dropna(subset=['DateTime'])\n",
    "fut_df['LTP'] = pd.to_numeric(fut_df['LTP'], errors='coerce')\n",
    "fut_df = fut_df.dropna(subset=['LTP'])\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Futures ticks: {len(fut_df):,}\")\n",
    "print(f\"From {fut_df['DateTime'].min()} to {fut_df['DateTime'].max()}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD KINETIC TRADES (ENTRY/EXIT WINDOWS)\n",
    "# ==========================================\n",
    "print(\"Loading kinetic trade windows...\")\n",
    "trades_raw = pd.read_csv(TRADES_FILE)\n",
    "\n",
    "# Expecting 'Entry_Time' and 'Exit_Time'\n",
    "trades_raw['Entry_Time'] = pd.to_datetime(trades_raw['Entry_Time'])\n",
    "trades_raw['Exit_Time']  = pd.to_datetime(trades_raw['Exit_Time'])\n",
    "\n",
    "# Filter only trades for this specific day (20 Nov) if needed:\n",
    "# trades_raw = trades_raw[trades_raw['Entry_Time'].dt.date == datetime.date(2025, 11, 20)]\n",
    "\n",
    "trades_raw = trades_raw.sort_values('Entry_Time').reset_index(drop=True)\n",
    "print(f\"Number of kinetic trades in file: {len(trades_raw)}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD OPTION FILES INTO A SINGLE DATAFRAME\n",
    "# ==========================================\n",
    "print(\"Loading option data (CE + PE for strikes)...\")\n",
    "opt_frames = []\n",
    "\n",
    "for K in STRIKES:\n",
    "    for opt_type in ['CE', 'PE']:\n",
    "        fname = f\"{OPTION_PREFIX}{K}{opt_type}.parquet\"\n",
    "        if not os.path.exists(fname):\n",
    "            print(f\"WARNING: Missing file {fname}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        df_opt = pd.read_parquet(fname)\n",
    "        # Expecting 'Date', 'Time', 'LTP' similarly\n",
    "        df_opt['DateTime'] = pd.to_datetime(\n",
    "            df_opt['Date'] + ' ' + df_opt['Time'],\n",
    "            format='%d/%m/%Y %H:%M:%S.%f',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        df_opt = df_opt.dropna(subset=['DateTime'])\n",
    "        df_opt['LTP'] = pd.to_numeric(df_opt['LTP'], errors='coerce')\n",
    "        df_opt = df_opt.dropna(subset=['LTP'])\n",
    "\n",
    "        df_opt['Strike'] = float(K)\n",
    "        df_opt['Option_Type'] = opt_type  # 'CE' or 'PE'\n",
    "        opt_frames.append(df_opt[['DateTime', 'LTP', 'Strike', 'Option_Type']])\n",
    "\n",
    "opt_df = pd.concat(opt_frames, ignore_index=True).sort_values('DateTime')\n",
    "print(f\"Total option ticks: {len(opt_df):,}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: GET SPOT AT TIME (ASOF)\n",
    "# ==========================================\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "fut_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "opt_df = opt_df.sort_values('DateTime').reset_index(drop=True)\n",
    "opt_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "def get_spot_at(ts):\n",
    "    \"\"\"Get futures LTP at or just before ts.\"\"\"\n",
    "    if ts < fut_df.index[0]:\n",
    "        return None\n",
    "    loc = fut_df.index.searchsorted(ts, side='right') - 1\n",
    "    if loc < 0:\n",
    "        return None\n",
    "    return fut_df.iloc[loc]['LTP']\n",
    "\n",
    "\n",
    "def slice_ts(df, start_ts, end_ts):\n",
    "    \"\"\"Slice df between start_ts and end_ts inclusive.\"\"\"\n",
    "    return df.loc[(df.index >= start_ts) & (df.index <= end_ts)].copy()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# GAMMA SCALPING SIM FOR ONE TRADE WINDOW\n",
    "# ==========================================\n",
    "def gamma_scalp_for_trade(row):\n",
    "    entry_ts = row['Entry_Time']\n",
    "    exit_ts  = row['Exit_Time']\n",
    "\n",
    "    # 1) Get spot at entry\n",
    "    S0 = get_spot_at(entry_ts)\n",
    "    if S0 is None:\n",
    "        return None\n",
    "\n",
    "    # 2) Pick ATM strike from list (closest to S0)\n",
    "    atm_strike = min(STRIKES, key=lambda K: abs(K - S0))\n",
    "\n",
    "    # 3) Extract CE & PE series for that strike in [entry, exit]\n",
    "    ce_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'CE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "    pe_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'PE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "\n",
    "    # Require some data\n",
    "    if ce_series.empty or pe_series.empty:\n",
    "        return None\n",
    "\n",
    "    # 4) Build 1-second grid\n",
    "    time_index = pd.date_range(start=entry_ts, end=exit_ts, freq='1S')\n",
    "\n",
    "    # Reindex futures & options to this grid\n",
    "    fut_sub = slice_ts(fut_df, entry_ts, exit_ts)\n",
    "    if fut_sub.empty:\n",
    "        return None\n",
    "\n",
    "    S_t = fut_sub['LTP'].reindex(time_index, method='ffill')\n",
    "    CE_t = ce_series['LTP'].reindex(time_index, method='ffill')\n",
    "    PE_t = pe_series['LTP'].reindex(time_index, method='ffill')\n",
    "\n",
    "    # Drop any times where we don't have all\n",
    "    valid = S_t.notna() & CE_t.notna() & PE_t.notna()\n",
    "    S_t = S_t[valid]\n",
    "    CE_t = CE_t[valid]\n",
    "    PE_t = PE_t[valid]\n",
    "    time_index = S_t.index\n",
    "\n",
    "    if len(time_index) < 5:\n",
    "        return None\n",
    "\n",
    "    # 5) ENTRY\n",
    "    S_entry = S_t.iloc[0]\n",
    "    CE_entry = CE_t.iloc[0]\n",
    "    PE_entry = PE_t.iloc[0]\n",
    "\n",
    "    # Time to expiry at entry\n",
    "    T0 = (EXPIRY_DATE - time_index[0]).total_seconds() / (365.0 * 24 * 3600)\n",
    "    T0 = max(T0, 1e-6)\n",
    "\n",
    "    K = atm_strike\n",
    "\n",
    "    # Implied vol for CE at entry\n",
    "    sigma_ce = implied_vol_call_bisect(CE_entry, S_entry, K, T0)\n",
    "    # For PE, we can use put-call parity to infer call-equivalent price:\n",
    "    # C = P + S - K e^{-rT}, so treat that as \"call price\" for iv\n",
    "    ce_equiv_from_put = PE_entry + S_entry - K  # r≈0\n",
    "    sigma_pe = implied_vol_call_bisect(max(ce_equiv_from_put, 0.0001), S_entry, K, T0)\n",
    "\n",
    "    if sigma_ce is None or sigma_pe is None:\n",
    "        # fallback: use some rough vol (e.g. 0.15)\n",
    "        sigma_ce = sigma_ce or 0.15\n",
    "        sigma_pe = sigma_pe or 0.15\n",
    "\n",
    "    # We are long 1 CE and 1 PE\n",
    "    option_cost = CE_entry + PE_entry\n",
    "\n",
    "    # 6) Start delta hedge\n",
    "    hedge_pos = 0.0      # futures contracts\n",
    "    hedge_cash_pnl = 0.0 # cash from futures trades\n",
    "    hedge_trades = 0\n",
    "\n",
    "    # 7) Time loop\n",
    "    for t in time_index:\n",
    "        S = S_t.loc[t]\n",
    "        CE = CE_t.loc[t]\n",
    "        PE = PE_t.loc[t]\n",
    "\n",
    "        # Time to expiry at time t\n",
    "        T_t = (EXPIRY_DATE - t).total_seconds() / (365.0 * 24 * 3600)\n",
    "        T_t = max(T_t, 1e-6)\n",
    "\n",
    "        # Call delta using CE's implied vol (gamma mostly from CE for ATM)\n",
    "        delta_call = bs_call_delta(S, K, T_t, sigma_ce)\n",
    "        # Put delta from call delta via parity: Δ_put = Δ_call - 1\n",
    "        delta_put = delta_call - 1.0\n",
    "\n",
    "        opt_delta = delta_call + delta_put  # total delta of straddle\n",
    "\n",
    "        # Desired futures position to be net delta ~ 0\n",
    "        desired_hedge_pos = -opt_delta  # 1 future = 1 delta per point\n",
    "\n",
    "        # Adjust only if significant change\n",
    "        delta_change = desired_hedge_pos - hedge_pos\n",
    "        if abs(delta_change) > HEDGE_STEP_THRESHOLD:\n",
    "            # Trade this much futures at price S\n",
    "            # Negative delta_change => we buy futures (spend cash)\n",
    "            hedge_cash_pnl -= delta_change * S\n",
    "            hedge_pos = desired_hedge_pos\n",
    "            hedge_trades += abs(delta_change)\n",
    "\n",
    "    # 8) At EXIT: mark to market\n",
    "    S_exit = S_t.iloc[-1]\n",
    "    CE_exit = CE_t.iloc[-1]\n",
    "    PE_exit = PE_t.iloc[-1]\n",
    "\n",
    "    option_pnl = (CE_exit + PE_exit) - option_cost\n",
    "    futures_pnl = hedge_pos * S_exit + hedge_cash_pnl\n",
    "\n",
    "    gross_pnl_points = option_pnl + futures_pnl\n",
    "\n",
    "    # Hedge costs: per-contract per trade in points\n",
    "    # Treat hedge_trades as \"futures contracts traded\" approx\n",
    "    hedge_cost_points = hedge_trades * HEDGE_COST_PER_CONTRACT\n",
    "\n",
    "    net_pnl_points = gross_pnl_points - hedge_cost_points\n",
    "    net_pnl_rupees = net_pnl_points * LOT_SIZE\n",
    "\n",
    "    return {\n",
    "        \"Date\": entry_ts.date(),\n",
    "        \"Entry_Time\": entry_ts,\n",
    "        \"Exit_Time\": exit_ts,\n",
    "        \"ATM_Strike\": atm_strike,\n",
    "        \"S_Entry\": S_entry,\n",
    "        \"S_Exit\": S_exit,\n",
    "        \"CE_Entry\": CE_entry,\n",
    "        \"CE_Exit\": CE_exit,\n",
    "        \"PE_Entry\": PE_entry,\n",
    "        \"PE_Exit\": PE_exit,\n",
    "        \"Sigma_CE\": sigma_ce,\n",
    "        \"Sigma_PE\": sigma_pe,\n",
    "        \"Option_PnL_pts\": option_pnl,\n",
    "        \"Futures_PnL_pts\": futures_pnl,\n",
    "        \"Gross_PnL_pts\": gross_pnl_points,\n",
    "        \"Hedge_Trades\": hedge_trades,\n",
    "        \"Hedge_Cost_pts\": hedge_cost_points,\n",
    "        \"Net_PnL_pts\": net_pnl_points,\n",
    "        \"Net_PnL_rupees\": net_pnl_rupees\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RUN OVER ALL TRADES\n",
    "# ==========================================\n",
    "results = []\n",
    "for i, row in trades_raw.iterrows():\n",
    "    res = gamma_scalp_for_trade(row)\n",
    "    if res is not None:\n",
    "        results.append(res)\n",
    "    else:\n",
    "        print(f\"Skipped trade {i} (insufficient data or mismatch).\")\n",
    "\n",
    "if not results:\n",
    "    print(\"\\nNo valid gamma-scalping simulations completed.\")\n",
    "else:\n",
    "    res_df = pd.DataFrame(results)\n",
    "    print(\"\\n========= GAMMA SCALPING SUMMARY =========\")\n",
    "    print(res_df[['Date', 'Entry_Time', 'Exit_Time', 'ATM_Strike',\n",
    "                  'Net_PnL_pts', 'Net_PnL_rupees']].head())\n",
    "\n",
    "    total_pts = res_df['Net_PnL_pts'].sum()\n",
    "    total_rs  = res_df['Net_PnL_rupees'].sum()\n",
    "    print(\"\\nTOTAL Net Gamma PnL:\")\n",
    "    print(f\"  {total_pts:.2f} points\")\n",
    "    print(f\"  ₹{total_rs:,.2f}\")\n",
    "\n",
    "    print(\"\\nPer-trade stats:\")\n",
    "    print(f\"  Trades: {len(res_df)}\")\n",
    "    print(f\"  Avg per trade: {res_df['Net_PnL_pts'].mean():.2f} pts \"\n",
    "          f\"(₹{res_df['Net_PnL_rupees'].mean():.2f})\")\n",
    "    print(f\"  Win rate: \"\n",
    "          f\"{(res_df['Net_PnL_pts'] > 0).mean() * 100:.1f}%\")\n",
    "\n",
    "    # Save to CSV\n",
    "    out_file = \"gamma_scalping_results.csv\"\n",
    "    res_df.to_csv(out_file, index=False)\n",
    "    print(f\"\\nDetailed gamma scalping results saved to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "FUT_FILE = \"NIFTY20NOV.csv\"                 # futures tick file\n",
    "TRADES_FILE = \"kinetic_full_backtest_trades.csv\" # kinetic backtest output with Entry/Exit\n",
    "OPTION_PREFIX = \"NIFTY25NOV\"                # prefix for options files\n",
    "STRIKES = [26100, 26150, 26200, 26250, 26300]  # strikes you have\n",
    "LOT_SIZE = 75                               # NIFTY lot\n",
    "HEDGE_STEP_THRESHOLD = 0.02                 # min delta change to rebalance (in futures)\n",
    "HEDGE_COST_PER_CONTRACT = 0.2               # points per futures contract per hedge (slippage+fees)\n",
    "EXPIRY_DATE = pd.Timestamp(\"2025-11-27\")    # <-- SET CORRECT EXPIRY HERE\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"DELTA-HEDGED GAMMA SCALPING\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: NORMAL PDF & CDF\n",
    "# ==========================================\n",
    "def norm_pdf(x):\n",
    "    return 1.0 / math.sqrt(2 * math.pi) * math.exp(-0.5 * x * x)\n",
    "\n",
    "def norm_cdf(x):\n",
    "    # Using error function approximation\n",
    "    return 0.5 * (1 + math.erf(x / math.sqrt(2)))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# BLACK-SCHOLES: CALL PRICE & DELTA\n",
    "# ==========================================\n",
    "def bs_call_price(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return max(S - K, 0.0)\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    d2 = d1 - sigma * sqrtT\n",
    "    return S * norm_cdf(d1) - K * math.exp(-r * T) * norm_cdf(d2)\n",
    "\n",
    "def bs_call_delta(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return 1.0 if S > K else 0.0\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    return norm_cdf(d1)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# IMPLIED VOL (BISECTION)\n",
    "# ==========================================\n",
    "def implied_vol_call_bisect(market_price, S, K, T, r=0.0, \n",
    "                            sigma_low=0.0001, sigma_high=3.0, \n",
    "                            tol=1e-4, max_iter=50):\n",
    "    \"\"\"Simple bisection implied vol for call. Returns sigma or None.\"\"\"\n",
    "    if T <= 0:\n",
    "        return None\n",
    "\n",
    "    # Check bounds\n",
    "    price_low = bs_call_price(S, K, T, sigma_low, r)\n",
    "    price_high = bs_call_price(S, K, T, sigma_high, r)\n",
    "    if price_low > market_price or price_high < market_price:\n",
    "        # Outside theoretical range, fallback\n",
    "        return None\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        sigma_mid = 0.5 * (sigma_low + sigma_high)\n",
    "        price_mid = bs_call_price(S, K, T, sigma_mid, r)\n",
    "\n",
    "        if abs(price_mid - market_price) < tol:\n",
    "            return sigma_mid\n",
    "\n",
    "        if price_mid > market_price:\n",
    "            sigma_high = sigma_mid\n",
    "        else:\n",
    "            sigma_low = sigma_mid\n",
    "\n",
    "    return sigma_mid\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD FUTURES DATA (NIFTY20NOV.csv)\n",
    "# ==========================================\n",
    "print(\"Loading futures data...\")\n",
    "fut_df = pd.read_csv(FUT_FILE)\n",
    "\n",
    "# Expecting columns: 'Date', 'Time', 'LTP'\n",
    "# Adjust if your columns have different names\n",
    "fut_df['DateTime'] = pd.to_datetime(\n",
    "    fut_df['Date'] + ' ' + fut_df['Time'],\n",
    "    format='%d/%m/%Y %H:%M:%S.%f',\n",
    "    errors='coerce'\n",
    ")\n",
    "fut_df = fut_df.dropna(subset=['DateTime'])\n",
    "fut_df['LTP'] = pd.to_numeric(fut_df['LTP'], errors='coerce')\n",
    "fut_df = fut_df.dropna(subset=['LTP'])\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Futures ticks: {len(fut_df):,}\")\n",
    "print(f\"From {fut_df['DateTime'].min()} to {fut_df['DateTime'].max()}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD KINETIC TRADES (ENTRY/EXIT WINDOWS)\n",
    "# ==========================================\n",
    "print(\"Loading kinetic trade windows...\")\n",
    "trades_raw = pd.read_csv(TRADES_FILE)\n",
    "\n",
    "# Expecting 'Entry_Time' and 'Exit_Time'\n",
    "trades_raw['Entry_Time'] = pd.to_datetime(trades_raw['Entry_Time'])\n",
    "trades_raw['Exit_Time']  = pd.to_datetime(trades_raw['Exit_Time'])\n",
    "\n",
    "# Filter only trades for this specific day (20 Nov) if needed:\n",
    "# trades_raw = trades_raw[trades_raw['Entry_Time'].dt.date == datetime.date(2025, 11, 20)]\n",
    "\n",
    "trades_raw = trades_raw.sort_values('Entry_Time').reset_index(drop=True)\n",
    "print(f\"Number of kinetic trades in file: {len(trades_raw)}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD OPTION FILES INTO A SINGLE DATAFRAME\n",
    "# ==========================================\n",
    "print(\"Loading option data (CE + PE for strikes)...\")\n",
    "opt_frames = []\n",
    "\n",
    "for K in STRIKES:\n",
    "    for opt_type in ['CE', 'PE']:\n",
    "        fname = f\"{OPTION_PREFIX}{K}{opt_type}.parquet\"\n",
    "        if not os.path.exists(fname):\n",
    "            print(f\"WARNING: Missing file {fname}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        df_opt = pd.read_parquet(fname)\n",
    "        # Expecting 'Date', 'Time', 'LTP' similarly\n",
    "        df_opt['DateTime'] = pd.to_datetime(\n",
    "            df_opt['Date'] + ' ' + df_opt['Time'],\n",
    "            format='%d/%m/%Y %H:%M:%S.%f',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        df_opt = df_opt.dropna(subset=['DateTime'])\n",
    "        df_opt['LTP'] = pd.to_numeric(df_opt['LTP'], errors='coerce')\n",
    "        df_opt = df_opt.dropna(subset=['LTP'])\n",
    "\n",
    "        df_opt['Strike'] = float(K)\n",
    "        df_opt['Option_Type'] = opt_type  # 'CE' or 'PE'\n",
    "        opt_frames.append(df_opt[['DateTime', 'LTP', 'Strike', 'Option_Type']])\n",
    "\n",
    "opt_df = pd.concat(opt_frames, ignore_index=True).sort_values('DateTime')\n",
    "print(f\"Total option ticks: {len(opt_df):,}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: GET SPOT AT TIME (ASOF)\n",
    "# ==========================================\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "fut_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "opt_df = opt_df.sort_values('DateTime').reset_index(drop=True)\n",
    "opt_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "def get_spot_at(ts):\n",
    "    \"\"\"Get futures LTP at or just before ts.\"\"\"\n",
    "    if ts < fut_df.index[0]:\n",
    "        return None\n",
    "    loc = fut_df.index.searchsorted(ts, side='right') - 1\n",
    "    if loc < 0:\n",
    "        return None\n",
    "    return fut_df.iloc[loc]['LTP']\n",
    "\n",
    "\n",
    "def slice_ts(df, start_ts, end_ts):\n",
    "    \"\"\"Slice df between start_ts and end_ts inclusive.\"\"\"\n",
    "    return df.loc[(df.index >= start_ts) & (df.index <= end_ts)].copy()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# GAMMA SCALPING SIM FOR ONE TRADE WINDOW\n",
    "# ==========================================\n",
    "def gamma_scalp_for_trade(row):\n",
    "    entry_ts = row['Entry_Time']\n",
    "    exit_ts  = row['Exit_Time']\n",
    "\n",
    "    # 1) Get spot at entry\n",
    "    S0 = get_spot_at(entry_ts)\n",
    "    if S0 is None:\n",
    "        return None\n",
    "\n",
    "    # 2) Pick ATM strike from list (closest to S0)\n",
    "    atm_strike = min(STRIKES, key=lambda K: abs(K - S0))\n",
    "\n",
    "    # 3) Extract CE & PE series for that strike in [entry, exit]\n",
    "    ce_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'CE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "    pe_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'PE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "\n",
    "    # Require some data\n",
    "    if ce_series.empty or pe_series.empty:\n",
    "        return None\n",
    "\n",
    "    # 4) Build 1-second grid\n",
    "    time_index = pd.date_range(start=entry_ts, end=exit_ts, freq='1S')\n",
    "\n",
    "    # Reindex futures & options to this grid\n",
    "    fut_sub = slice_ts(fut_df, entry_ts, exit_ts)\n",
    "    if fut_sub.empty:\n",
    "        return None\n",
    "\n",
    "    S_t = fut_sub['LTP'].reindex(time_index, method='ffill')\n",
    "    CE_t = ce_series['LTP'].reindex(time_index, method='ffill')\n",
    "    PE_t = pe_series['LTP'].reindex(time_index, method='ffill')\n",
    "\n",
    "    # Drop any times where we don't have all\n",
    "    valid = S_t.notna() & CE_t.notna() & PE_t.notna()\n",
    "    S_t = S_t[valid]\n",
    "    CE_t = CE_t[valid]\n",
    "    PE_t = PE_t[valid]\n",
    "    time_index = S_t.index\n",
    "\n",
    "    if len(time_index) < 5:\n",
    "        return None\n",
    "\n",
    "    # 5) ENTRY\n",
    "    S_entry = S_t.iloc[0]\n",
    "    CE_entry = CE_t.iloc[0]\n",
    "    PE_entry = PE_t.iloc[0]\n",
    "\n",
    "    # Time to expiry at entry\n",
    "    T0 = (EXPIRY_DATE - time_index[0]).total_seconds() / (365.0 * 24 * 3600)\n",
    "    T0 = max(T0, 1e-6)\n",
    "\n",
    "    K = atm_strike\n",
    "\n",
    "    # Implied vol for CE at entry\n",
    "    sigma_ce = implied_vol_call_bisect(CE_entry, S_entry, K, T0)\n",
    "    # For PE, we can use put-call parity to infer call-equivalent price:\n",
    "    # C = P + S - K e^{-rT}, so treat that as \"call price\" for iv\n",
    "    ce_equiv_from_put = PE_entry + S_entry - K  # r≈0\n",
    "    sigma_pe = implied_vol_call_bisect(max(ce_equiv_from_put, 0.0001), S_entry, K, T0)\n",
    "\n",
    "    if sigma_ce is None or sigma_pe is None:\n",
    "        # fallback: use some rough vol (e.g. 0.15)\n",
    "        sigma_ce = sigma_ce or 0.15\n",
    "        sigma_pe = sigma_pe or 0.15\n",
    "\n",
    "    # We are long 1 CE and 1 PE\n",
    "    option_cost = CE_entry + PE_entry\n",
    "\n",
    "    # 6) Start delta hedge\n",
    "    hedge_pos = 0.0      # futures contracts\n",
    "    hedge_cash_pnl = 0.0 # cash from futures trades\n",
    "    hedge_trades = 0\n",
    "\n",
    "    # 7) Time loop\n",
    "    for t in time_index:\n",
    "        S = S_t.loc[t]\n",
    "        CE = CE_t.loc[t]\n",
    "        PE = PE_t.loc[t]\n",
    "\n",
    "        # Time to expiry at time t\n",
    "        T_t = (EXPIRY_DATE - t).total_seconds() / (365.0 * 24 * 3600)\n",
    "        T_t = max(T_t, 1e-6)\n",
    "\n",
    "        # Call delta using CE's implied vol (gamma mostly from CE for ATM)\n",
    "        delta_call = bs_call_delta(S, K, T_t, sigma_ce)\n",
    "        # Put delta from call delta via parity: Δ_put = Δ_call - 1\n",
    "        delta_put = delta_call - 1.0\n",
    "\n",
    "        opt_delta = delta_call + delta_put  # total delta of straddle\n",
    "\n",
    "        # Desired futures position to be net delta ~ 0\n",
    "        desired_hedge_pos = -opt_delta  # 1 future = 1 delta per point\n",
    "\n",
    "        # Adjust only if significant change\n",
    "        delta_change = desired_hedge_pos - hedge_pos\n",
    "        if abs(delta_change) > HEDGE_STEP_THRESHOLD:\n",
    "            # Trade this much futures at price S\n",
    "            # Negative delta_change => we buy futures (spend cash)\n",
    "            hedge_cash_pnl -= delta_change * S\n",
    "            hedge_pos = desired_hedge_pos\n",
    "            hedge_trades += abs(delta_change)\n",
    "\n",
    "    # 8) At EXIT: mark to market\n",
    "    S_exit = S_t.iloc[-1]\n",
    "    CE_exit = CE_t.iloc[-1]\n",
    "    PE_exit = PE_t.iloc[-1]\n",
    "\n",
    "    option_pnl = (CE_exit + PE_exit) - option_cost\n",
    "    futures_pnl = hedge_pos * S_exit + hedge_cash_pnl\n",
    "\n",
    "    gross_pnl_points = option_pnl + futures_pnl\n",
    "\n",
    "    # Hedge costs: per-contract per trade in points\n",
    "    # Treat hedge_trades as \"futures contracts traded\" approx\n",
    "    hedge_cost_points = hedge_trades * HEDGE_COST_PER_CONTRACT\n",
    "\n",
    "    net_pnl_points = gross_pnl_points - hedge_cost_points\n",
    "    net_pnl_rupees = net_pnl_points * LOT_SIZE\n",
    "\n",
    "    return {\n",
    "        \"Date\": entry_ts.date(),\n",
    "        \"Entry_Time\": entry_ts,\n",
    "        \"Exit_Time\": exit_ts,\n",
    "        \"ATM_Strike\": atm_strike,\n",
    "        \"S_Entry\": S_entry,\n",
    "        \"S_Exit\": S_exit,\n",
    "        \"CE_Entry\": CE_entry,\n",
    "        \"CE_Exit\": CE_exit,\n",
    "        \"PE_Entry\": PE_entry,\n",
    "        \"PE_Exit\": PE_exit,\n",
    "        \"Sigma_CE\": sigma_ce,\n",
    "        \"Sigma_PE\": sigma_pe,\n",
    "        \"Option_PnL_pts\": option_pnl,\n",
    "        \"Futures_PnL_pts\": futures_pnl,\n",
    "        \"Gross_PnL_pts\": gross_pnl_points,\n",
    "        \"Hedge_Trades\": hedge_trades,\n",
    "        \"Hedge_Cost_pts\": hedge_cost_points,\n",
    "        \"Net_PnL_pts\": net_pnl_points,\n",
    "        \"Net_PnL_rupees\": net_pnl_rupees\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RUN OVER ALL TRADES\n",
    "# ==========================================\n",
    "results = []\n",
    "for i, row in trades_raw.iterrows():\n",
    "    res = gamma_scalp_for_trade(row)\n",
    "    if res is not None:\n",
    "        results.append(res)\n",
    "    else:\n",
    "        print(f\"Skipped trade {i} (insufficient data or mismatch).\")\n",
    "\n",
    "if not results:\n",
    "    print(\"\\nNo valid gamma-scalping simulations completed.\")\n",
    "else:\n",
    "    res_df = pd.DataFrame(results)\n",
    "    print(\"\\n========= GAMMA SCALPING SUMMARY =========\")\n",
    "    print(res_df[['Date', 'Entry_Time', 'Exit_Time', 'ATM_Strike',\n",
    "                  'Net_PnL_pts', 'Net_PnL_rupees']].head())\n",
    "\n",
    "    total_pts = res_df['Net_PnL_pts'].sum()\n",
    "    total_rs  = res_df['Net_PnL_rupees'].sum()\n",
    "    print(\"\\nTOTAL Net Gamma PnL:\")\n",
    "    print(f\"  {total_pts:.2f} points\")\n",
    "    print(f\"  ₹{total_rs:,.2f}\")\n",
    "\n",
    "    print(\"\\nPer-trade stats:\")\n",
    "    print(f\"  Trades: {len(res_df)}\")\n",
    "    print(f\"  Avg per trade: {res_df['Net_PnL_pts'].mean():.2f} pts \"\n",
    "          f\"(₹{res_df['Net_PnL_rupees'].mean():.2f})\")\n",
    "    print(f\"  Win rate: \"\n",
    "          f\"{(res_df['Net_PnL_pts'] > 0).mean() * 100:.1f}%\")\n",
    "\n",
    "    # Save to CSV\n",
    "    out_file = \"gamma_scalping_results.csv\"\n",
    "    res_df.to_csv(out_file, index=False)\n",
    "    print(f\"\\nDetailed gamma scalping results saved to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b9641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- year=2025/month=11/day=04/Futures/NIFTY/NIFTY25NOVFUT.parquet ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "DAY = 4\n",
    "SYMBOL = \"NIFTY\"\n",
    "\n",
    "def get_fut_from_s3(prefix):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    resp = s3.list_objects_v2(Bucket=BUCKET, Prefix=prefix)\n",
    "\n",
    "    for obj in resp.get(\"Contents\", []):\n",
    "        key = obj[\"Key\"]\n",
    "        if key.endswith(\".parquet\"):\n",
    "            data = s3.get_object(Bucket=BUCKET, Key=key)[\"Body\"].read()\n",
    "            df = pd.read_parquet(BytesIO(data))\n",
    "            print(f\"\\n--- {key} ---\\n\")\n",
    "            return df\n",
    "\n",
    "df = get_fut_from_s3(f\"year={YEAR}/month={MONTH:02d}/day={DAY:02d}/Futures/{SYMBOL}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4165ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- year=2025/month=11/day=04/Futures/NIFTY/NIFTY25NOVFUT.parquet ---\n",
      "\n",
      "\n",
      "==============================\n",
      "DELTA-HEDGED GAMMA SCALPING\n",
      "==============================\n",
      "\n",
      "Loading futures data...\n",
      "Futures ticks: 34,540\n",
      "From 2025-11-04 08:46:29.948000 to 2025-11-04 15:28:32.829000\n",
      "\n",
      "Loading kinetic trade windows...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'kinetic_full_backtest_trades.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 111\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# LOAD KINETIC TRADES (ENTRY/EXIT WINDOWS)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading kinetic trade windows...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m trades_raw \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTRADES_FILE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Expecting 'Entry_Time' and 'Exit_Time'\u001b[39;00m\n\u001b[1;32m    114\u001b[0m trades_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntry_Time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(trades_raw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntry_Time\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'kinetic_full_backtest_trades.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "FUT_FILE = get_fut_from_s3(f\"year={YEAR}/month={MONTH:02d}/day={DAY:02d}/Futures/{SYMBOL}/\")                 # futures tick file\n",
    "TRADES_FILE = \"kinetic_full_backtest_trades.csv\" # kinetic backtest output with Entry/Exit\n",
    "OPTION_PREFIX = \"NIFTY25NOV\"                # prefix for options files\n",
    "STRIKES = [26100, 26150, 26200, 26250, 26300]  # strikes you have\n",
    "LOT_SIZE = 75                               # NIFTY lot\n",
    "HEDGE_STEP_THRESHOLD = 0.02                 # min delta change to rebalance (in futures)\n",
    "HEDGE_COST_PER_CONTRACT = 0.2               # points per futures contract per hedge (slippage+fees)\n",
    "EXPIRY_DATE = pd.Timestamp(\"2025-11-27\")    # <-- SET CORRECT EXPIRY HERE\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\"DELTA-HEDGED GAMMA SCALPING\")\n",
    "print(\"==============================\\n\")\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: NORMAL PDF & CDF\n",
    "# ==========================================\n",
    "def norm_pdf(x):\n",
    "    return 1.0 / math.sqrt(2 * math.pi) * math.exp(-0.5 * x * x)\n",
    "\n",
    "def norm_cdf(x):\n",
    "    # Using error function approximation\n",
    "    return 0.5 * (1 + math.erf(x / math.sqrt(2)))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# BLACK-SCHOLES: CALL PRICE & DELTA\n",
    "# ==========================================\n",
    "def bs_call_price(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return max(S - K, 0.0)\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    d2 = d1 - sigma * sqrtT\n",
    "    return S * norm_cdf(d1) - K * math.exp(-r * T) * norm_cdf(d2)\n",
    "\n",
    "def bs_call_delta(S, K, T, sigma, r=0.0):\n",
    "    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:\n",
    "        return 1.0 if S > K else 0.0\n",
    "    sqrtT = math.sqrt(T)\n",
    "    d1 = (math.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrtT)\n",
    "    return norm_cdf(d1)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# IMPLIED VOL (BISECTION)\n",
    "# ==========================================\n",
    "def implied_vol_call_bisect(market_price, S, K, T, r=0.0, \n",
    "                            sigma_low=0.0001, sigma_high=3.0, \n",
    "                            tol=1e-4, max_iter=50):\n",
    "    \"\"\"Simple bisection implied vol for call. Returns sigma or None.\"\"\"\n",
    "    if T <= 0:\n",
    "        return None\n",
    "\n",
    "    # Check bounds\n",
    "    price_low = bs_call_price(S, K, T, sigma_low, r)\n",
    "    price_high = bs_call_price(S, K, T, sigma_high, r)\n",
    "    if price_low > market_price or price_high < market_price:\n",
    "        # Outside theoretical range, fallback\n",
    "        return None\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        sigma_mid = 0.5 * (sigma_low + sigma_high)\n",
    "        price_mid = bs_call_price(S, K, T, sigma_mid, r)\n",
    "\n",
    "        if abs(price_mid - market_price) < tol:\n",
    "            return sigma_mid\n",
    "\n",
    "        if price_mid > market_price:\n",
    "            sigma_high = sigma_mid\n",
    "        else:\n",
    "            sigma_low = sigma_mid\n",
    "\n",
    "    return sigma_mid\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD FUTURES DATA (NIFTY20NOV.csv)\n",
    "# ==========================================\n",
    "print(\"Loading futures data...\")\n",
    "fut_df = FUT_FILE\n",
    "\n",
    "# Expecting columns: 'Date', 'Time', 'LTP'\n",
    "# Adjust if your columns have different names\n",
    "fut_df['DateTime'] = pd.to_datetime(\n",
    "    fut_df['Date'] + ' ' + fut_df['Time'],\n",
    "    format='%d/%m/%Y %H:%M:%S.%f',\n",
    "    errors='coerce'\n",
    ")\n",
    "fut_df = fut_df.dropna(subset=['DateTime'])\n",
    "fut_df['LTP'] = pd.to_numeric(fut_df['LTP'], errors='coerce')\n",
    "fut_df = fut_df.dropna(subset=['LTP'])\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "\n",
    "print(f\"Futures ticks: {len(fut_df):,}\")\n",
    "print(f\"From {fut_df['DateTime'].min()} to {fut_df['DateTime'].max()}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD KINETIC TRADES (ENTRY/EXIT WINDOWS)\n",
    "# ==========================================\n",
    "print(\"Loading kinetic trade windows...\")\n",
    "trades_raw = pd.read_csv(TRADES_FILE)\n",
    "\n",
    "# Expecting 'Entry_Time' and 'Exit_Time'\n",
    "trades_raw['Entry_Time'] = pd.to_datetime(trades_raw['Entry_Time'])\n",
    "trades_raw['Exit_Time']  = pd.to_datetime(trades_raw['Exit_Time'])\n",
    "\n",
    "# Filter only trades for this specific day (20 Nov) if needed:\n",
    "# trades_raw = trades_raw[trades_raw['Entry_Time'].dt.date == datetime.date(2025, 11, 20)]\n",
    "\n",
    "trades_raw = trades_raw.sort_values('Entry_Time').reset_index(drop=True)\n",
    "print(f\"Number of kinetic trades in file: {len(trades_raw)}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LOAD OPTION FILES INTO A SINGLE DATAFRAME\n",
    "# ==========================================\n",
    "print(\"Loading option data (CE + PE for strikes)...\")\n",
    "opt_frames = []\n",
    "\n",
    "for K in STRIKES:\n",
    "    for opt_type in ['CE', 'PE']:\n",
    "        fname = f\"{OPTION_PREFIX}{K}{opt_type}.parquet\"\n",
    "        if not os.path.exists(fname):\n",
    "            print(f\"WARNING: Missing file {fname}, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        df_opt = pd.read_parquet(fname)\n",
    "        # Expecting 'Date', 'Time', 'LTP' similarly\n",
    "        df_opt['DateTime'] = pd.to_datetime(\n",
    "            df_opt['Date'] + ' ' + df_opt['Time'],\n",
    "            format='%d/%m/%Y %H:%M:%S.%f',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        df_opt = df_opt.dropna(subset=['DateTime'])\n",
    "        df_opt['LTP'] = pd.to_numeric(df_opt['LTP'], errors='coerce')\n",
    "        df_opt = df_opt.dropna(subset=['LTP'])\n",
    "\n",
    "        df_opt['Strike'] = float(K)\n",
    "        df_opt['Option_Type'] = opt_type  # 'CE' or 'PE'\n",
    "        opt_frames.append(df_opt[['DateTime', 'LTP', 'Strike', 'Option_Type']])\n",
    "\n",
    "opt_df = pd.concat(opt_frames, ignore_index=True).sort_values('DateTime')\n",
    "print(f\"Total option ticks: {len(opt_df):,}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# HELPER: GET SPOT AT TIME (ASOF)\n",
    "# ==========================================\n",
    "fut_df = fut_df.sort_values('DateTime').reset_index(drop=True)\n",
    "fut_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "opt_df = opt_df.sort_values('DateTime').reset_index(drop=True)\n",
    "opt_df.set_index('DateTime', inplace=True)\n",
    "\n",
    "\n",
    "def get_spot_at(ts):\n",
    "    \"\"\"Get futures LTP at or just before ts.\"\"\"\n",
    "    if ts < fut_df.index[0]:\n",
    "        return None\n",
    "    loc = fut_df.index.searchsorted(ts, side='right') - 1\n",
    "    if loc < 0:\n",
    "        return None\n",
    "    return fut_df.iloc[loc]['LTP']\n",
    "\n",
    "\n",
    "def slice_ts(df, start_ts, end_ts):\n",
    "    \"\"\"Slice df between start_ts and end_ts inclusive.\"\"\"\n",
    "    return df.loc[(df.index >= start_ts) & (df.index <= end_ts)].copy()\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# GAMMA SCALPING SIM FOR ONE TRADE WINDOW\n",
    "# ==========================================\n",
    "def gamma_scalp_for_trade(row):\n",
    "    entry_ts = row['Entry_Time']\n",
    "    exit_ts  = row['Exit_Time']\n",
    "\n",
    "    # 1) Get spot at entry\n",
    "    S0 = get_spot_at(entry_ts)\n",
    "    if S0 is None:\n",
    "        return None\n",
    "\n",
    "    # 2) Pick ATM strike from list (closest to S0)\n",
    "    atm_strike = min(STRIKES, key=lambda K: abs(K - S0))\n",
    "\n",
    "    # 3) Extract CE & PE series for that strike in [entry, exit]\n",
    "    ce_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'CE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "    pe_series = slice_ts(\n",
    "        opt_df[(opt_df['Strike'] == atm_strike) & (opt_df['Option_Type'] == 'PE')],\n",
    "        entry_ts, exit_ts\n",
    "    )\n",
    "\n",
    "    # Require some data\n",
    "    if ce_series.empty or pe_series.empty:\n",
    "        return None\n",
    "\n",
    "    # 4) Build 1-second grid\n",
    "    time_index = pd.date_range(start=entry_ts, end=exit_ts, freq='1S')\n",
    "\n",
    "    # Reindex futures & options to this grid\n",
    "    fut_sub = slice_ts(fut_df, entry_ts, exit_ts)\n",
    "    if fut_sub.empty:\n",
    "        return None\n",
    "\n",
    "    S_t = fut_sub['LTP'].reindex(time_index, method='ffill')\n",
    "    CE_t = ce_series['LTP'].reindex(time_index, method='ffill')\n",
    "    PE_t = pe_series['LTP'].reindex(time_index, method='ffill')\n",
    "\n",
    "    # Drop any times where we don't have all\n",
    "    valid = S_t.notna() & CE_t.notna() & PE_t.notna()\n",
    "    S_t = S_t[valid]\n",
    "    CE_t = CE_t[valid]\n",
    "    PE_t = PE_t[valid]\n",
    "    time_index = S_t.index\n",
    "\n",
    "    if len(time_index) < 5:\n",
    "        return None\n",
    "\n",
    "    # 5) ENTRY\n",
    "    S_entry = S_t.iloc[0]\n",
    "    CE_entry = CE_t.iloc[0]\n",
    "    PE_entry = PE_t.iloc[0]\n",
    "\n",
    "    # Time to expiry at entry\n",
    "    T0 = (EXPIRY_DATE - time_index[0]).total_seconds() / (365.0 * 24 * 3600)\n",
    "    T0 = max(T0, 1e-6)\n",
    "\n",
    "    K = atm_strike\n",
    "\n",
    "    # Implied vol for CE at entry\n",
    "    sigma_ce = implied_vol_call_bisect(CE_entry, S_entry, K, T0)\n",
    "    # For PE, we can use put-call parity to infer call-equivalent price:\n",
    "    # C = P + S - K e^{-rT}, so treat that as \"call price\" for iv\n",
    "    ce_equiv_from_put = PE_entry + S_entry - K  # r≈0\n",
    "    sigma_pe = implied_vol_call_bisect(max(ce_equiv_from_put, 0.0001), S_entry, K, T0)\n",
    "\n",
    "    if sigma_ce is None or sigma_pe is None:\n",
    "        # fallback: use some rough vol (e.g. 0.15)\n",
    "        sigma_ce = sigma_ce or 0.15\n",
    "        sigma_pe = sigma_pe or 0.15\n",
    "\n",
    "    # We are long 1 CE and 1 PE\n",
    "    option_cost = CE_entry + PE_entry\n",
    "\n",
    "    # 6) Start delta hedge\n",
    "    hedge_pos = 0.0      # futures contracts\n",
    "    hedge_cash_pnl = 0.0 # cash from futures trades\n",
    "    hedge_trades = 0\n",
    "\n",
    "    # 7) Time loop\n",
    "    for t in time_index:\n",
    "        S = S_t.loc[t]\n",
    "        CE = CE_t.loc[t]\n",
    "        PE = PE_t.loc[t]\n",
    "\n",
    "        # Time to expiry at time t\n",
    "        T_t = (EXPIRY_DATE - t).total_seconds() / (365.0 * 24 * 3600)\n",
    "        T_t = max(T_t, 1e-6)\n",
    "\n",
    "        # Call delta using CE's implied vol (gamma mostly from CE for ATM)\n",
    "        delta_call = bs_call_delta(S, K, T_t, sigma_ce)\n",
    "        # Put delta from call delta via parity: Δ_put = Δ_call - 1\n",
    "        delta_put = delta_call - 1.0\n",
    "\n",
    "        opt_delta = delta_call + delta_put  # total delta of straddle\n",
    "\n",
    "        # Desired futures position to be net delta ~ 0\n",
    "        desired_hedge_pos = -opt_delta  # 1 future = 1 delta per point\n",
    "\n",
    "        # Adjust only if significant change\n",
    "        delta_change = desired_hedge_pos - hedge_pos\n",
    "        if abs(delta_change) > HEDGE_STEP_THRESHOLD:\n",
    "            # Trade this much futures at price S\n",
    "            # Negative delta_change => we buy futures (spend cash)\n",
    "            hedge_cash_pnl -= delta_change * S\n",
    "            hedge_pos = desired_hedge_pos\n",
    "            hedge_trades += abs(delta_change)\n",
    "\n",
    "    # 8) At EXIT: mark to market\n",
    "    S_exit = S_t.iloc[-1]\n",
    "    CE_exit = CE_t.iloc[-1]\n",
    "    PE_exit = PE_t.iloc[-1]\n",
    "\n",
    "    option_pnl = (CE_exit + PE_exit) - option_cost\n",
    "    futures_pnl = hedge_pos * S_exit + hedge_cash_pnl\n",
    "\n",
    "    gross_pnl_points = option_pnl + futures_pnl\n",
    "\n",
    "    # Hedge costs: per-contract per trade in points\n",
    "    # Treat hedge_trades as \"futures contracts traded\" approx\n",
    "    hedge_cost_points = hedge_trades * HEDGE_COST_PER_CONTRACT\n",
    "\n",
    "    net_pnl_points = gross_pnl_points - hedge_cost_points\n",
    "    net_pnl_rupees = net_pnl_points * LOT_SIZE\n",
    "\n",
    "    return {\n",
    "        \"Date\": entry_ts.date(),\n",
    "        \"Entry_Time\": entry_ts,\n",
    "        \"Exit_Time\": exit_ts,\n",
    "        \"ATM_Strike\": atm_strike,\n",
    "        \"S_Entry\": S_entry,\n",
    "        \"S_Exit\": S_exit,\n",
    "        \"CE_Entry\": CE_entry,\n",
    "        \"CE_Exit\": CE_exit,\n",
    "        \"PE_Entry\": PE_entry,\n",
    "        \"PE_Exit\": PE_exit,\n",
    "        \"Sigma_CE\": sigma_ce,\n",
    "        \"Sigma_PE\": sigma_pe,\n",
    "        \"Option_PnL_pts\": option_pnl,\n",
    "        \"Futures_PnL_pts\": futures_pnl,\n",
    "        \"Gross_PnL_pts\": gross_pnl_points,\n",
    "        \"Hedge_Trades\": hedge_trades,\n",
    "        \"Hedge_Cost_pts\": hedge_cost_points,\n",
    "        \"Net_PnL_pts\": net_pnl_points,\n",
    "        \"Net_PnL_rupees\": net_pnl_rupees\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RUN OVER ALL TRADES\n",
    "# ==========================================\n",
    "results = []\n",
    "for i, row in trades_raw.iterrows():\n",
    "    res = gamma_scalp_for_trade(row)\n",
    "    if res is not None:\n",
    "        results.append(res)\n",
    "    else:\n",
    "        print(f\"Skipped trade {i} (insufficient data or mismatch).\")\n",
    "\n",
    "if not results:\n",
    "    print(\"\\nNo valid gamma-scalping simulations completed.\")\n",
    "else:\n",
    "    res_df = pd.DataFrame(results)\n",
    "    print(\"\\n========= GAMMA SCALPING SUMMARY =========\")\n",
    "    print(res_df[['Date', 'Entry_Time', 'Exit_Time', 'ATM_Strike',\n",
    "                  'Net_PnL_pts', 'Net_PnL_rupees']].head())\n",
    "\n",
    "    total_pts = res_df['Net_PnL_pts'].sum()\n",
    "    total_rs  = res_df['Net_PnL_rupees'].sum()\n",
    "    print(\"\\nTOTAL Net Gamma PnL:\")\n",
    "    print(f\"  {total_pts:.2f} points\")\n",
    "    print(f\"  ₹{total_rs:,.2f}\")\n",
    "\n",
    "    print(\"\\nPer-trade stats:\")\n",
    "    print(f\"  Trades: {len(res_df)}\")\n",
    "    print(f\"  Avg per trade: {res_df['Net_PnL_pts'].mean():.2f} pts \"\n",
    "          f\"(₹{res_df['Net_PnL_rupees'].mean():.2f})\")\n",
    "    print(f\"  Win rate: \"\n",
    "          f\"{(res_df['Net_PnL_pts'] > 0).mean() * 100:.1f}%\")\n",
    "\n",
    "    # Save to CSV\n",
    "    out_file = \"gamma_scalping_results.csv\"\n",
    "    res_df.to_csv(out_file, index=False)\n",
    "    print(f\"\\nDetailed gamma scalping results saved to: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bcc86d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HYPER-ADAPTIVE SCALPER - 11/2025\n",
      "Logic: Kill Side < -1000.0 | BE @ +25.0 | Trail @ +50.0\n",
      "============================================================\n",
      "\n",
      "\n",
      "01/11/2025... No data\n",
      "\n",
      "02/11/2025... No data\n",
      "\n",
      "03/11/2025... No data\n",
      "\n",
      "04/11/2025... Trades: 19 (SL:1/BE:1) | PnL: ₹7,793 [L:-2557 S:10350]\n",
      "\n",
      "05/11/2025... No data\n",
      "\n",
      "06/11/2025... Trades: 3 (SL:2/BE:1) | PnL: ₹-4,868 [L:-2543 S:-2325]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "07/11/2025... Trades: 3 (SL:2/BE:0) | PnL: ₹-3,743 [L:-2325 S:-1418]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "08/11/2025... No data\n",
      "\n",
      "09/11/2025... No data\n",
      "\n",
      "10/11/2025... No data\n",
      "\n",
      "11/11/2025... Trades: 15 (SL:6/BE:1) | PnL: ₹-3,547 [L:-2325 S:-1222]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "12/11/2025... Trades: 2 (SL:2/BE:0) | PnL: ₹-4,695 [L:-2370 S:-2325]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "13/11/2025... Trades: 21 (SL:6/BE:0) | PnL: ₹-1,545 [L:-1088 S:-458]\n",
      "\n",
      "14/11/2025... No data\n",
      "\n",
      "15/11/2025... No data\n",
      "\n",
      "16/11/2025... No data\n",
      "\n",
      "17/11/2025... Trades: 2 (SL:2/BE:0) | PnL: ₹-5,010 [L:-2460 S:-2550]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "18/11/2025... Trades: 2 (SL:2/BE:0) | PnL: ₹-4,703 [L:-2325 S:-2378]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "19/11/2025... Trades: 3 (SL:1/BE:1) | PnL: ₹-4,170 [L:-2325 S:-1845]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "20/11/2025... Trades: 4 (SL:1/BE:1) | PnL: ₹-3,382 [L:-2362 S:-1020]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "21/11/2025... Trades: 20 (SL:2/BE:2) | PnL: ₹18,142 [L:8040 S:10102]\n",
      "\n",
      "22/11/2025... No data\n",
      "\n",
      "23/11/2025... No data\n",
      "\n",
      "24/11/2025... Trades: 19 (SL:3/BE:1) | PnL: ₹5,602 [L:-1838 S:7440]\n",
      "\n",
      "25/11/2025... Trades: 6 (SL:3/BE:0) | PnL: ₹-4,215 [L:-1868 S:-2347]\n",
      "   [RISK] Global Stop Hit!\n",
      "\n",
      "26/11/2025... No data\n",
      "\n",
      "27/11/2025... No data\n",
      "\n",
      "28/11/2025... No data\n",
      "\n",
      "29/11/2025... No data\n",
      "\n",
      "30/11/2025... No data\n",
      "\n",
      "============================================================\n",
      "HYPER-ADAPTIVE SUMMARY: 11/2025\n",
      "============================================================\n",
      "Total Net PnL:      ₹-8,340.00\n",
      "Win Rate:           48.7%\n",
      "Total Trades:       119\n",
      "  - Longs:          51 (₹-18,345)\n",
      "  - Shorts:         68 (₹10,005)\n",
      "\n",
      "Results saved: data/nov_2025_hyper_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS FUTURES SCALPER: HYPER-ADAPTIVE + TRAILING\n",
    "===============================================\n",
    "Logic: \n",
    "1. Core: RSI Kinetic Engine (51% Win Rate).\n",
    "2. Defense: Side-Specific Kill Switch tightened to -1000 (Fail Fast).\n",
    "3. Offense: Active Trailing Stop to lock profits.\n",
    "   - +25 pts -> Move SL to Breakeven.\n",
    "   - +50 pts -> Move SL to +25 pts.\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"\n",
    "\n",
    "# Strategy Parameters\n",
    "LOT_SIZE = 75\n",
    "KINETIC_THRESHOLD = 37500\n",
    "MAX_HOLD_SECONDS = 1200  # 20 mins\n",
    "\n",
    "# RSI Filter Settings\n",
    "RSI_PERIOD = 200     \n",
    "RSI_OVERBOUGHT = 70.0\n",
    "RSI_OVERSOLD = 30.0\n",
    "\n",
    "# Trade Management\n",
    "STOP_LOSS_POINTS = 30.0  \n",
    "TAKE_PROFIT_POINTS = 80.0 # Extended TP to allow trailing\n",
    "\n",
    "# Trailing Settings\n",
    "BE_TRIGGER = 25.0       # Points profit to move SL to BE\n",
    "TRAIL_TRIGGER = 50.0    # Points profit to start trailing\n",
    "TRAIL_LOCK = 25.0       # Points locked when trailing starts\n",
    "\n",
    "# Risk Management\n",
    "SIDE_MAX_LOSS = -1000.0  # Tighter leash (approx 13 pts)\n",
    "DAILY_MAX_LOSS = -3000.0 \n",
    "\n",
    "# Costs\n",
    "FUTURES_ROUND_TRIP_COST = 1.0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HYPER-ADAPTIVE SCALPER - {MONTH}/{YEAR}\")\n",
    "print(f\"Logic: Kill Side < {SIDE_MAX_LOSS} | BE @ +{BE_TRIGGER} | Trail @ +{TRAIL_TRIGGER}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation:\n",
    "            kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            continuation = resp.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "    return keys\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# FAST TICK RSI\n",
    "# ==========================================\n",
    "class TickRSI:\n",
    "    def __init__(self, period=200):\n",
    "        self.period = period\n",
    "        self.avg_gain = 0.0\n",
    "        self.avg_loss = 0.0\n",
    "        self.initialized = False\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, change):\n",
    "        gain = max(0, change)\n",
    "        loss = max(0, -change)\n",
    "        \n",
    "        if not self.initialized:\n",
    "            self.avg_gain += gain\n",
    "            self.avg_loss += loss\n",
    "            self.count += 1\n",
    "            if self.count >= self.period:\n",
    "                self.avg_gain /= self.period\n",
    "                self.avg_loss /= self.period\n",
    "                self.initialized = True\n",
    "        else:\n",
    "            self.avg_gain = ((self.avg_gain * (self.period - 1)) + gain) / self.period\n",
    "            self.avg_loss = ((self.avg_loss * (self.period - 1)) + loss) / self.period\n",
    "            \n",
    "    def get_rsi(self):\n",
    "        if not self.initialized: return 50.0\n",
    "        if self.avg_loss == 0: return 100.0\n",
    "        rs = self.avg_gain / self.avg_loss\n",
    "        return 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# FAST DIRECTIONAL ENGINE\n",
    "# ==========================================\n",
    "class FastDirectionalEngine:\n",
    "    def __init__(self, buffer_size=50):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.price_buffer = deque(maxlen=buffer_size)\n",
    "        self.volume_buffer = deque(maxlen=buffer_size)\n",
    "        \n",
    "    def add_tick(self, ltp, volume):\n",
    "        self.price_buffer.append(ltp)\n",
    "        self.volume_buffer.append(volume)\n",
    "    \n",
    "    def calculate_direction(self):\n",
    "        if len(self.price_buffer) < self.buffer_size:\n",
    "            return 0\n",
    "        \n",
    "        prices = np.array(self.price_buffer)\n",
    "        vols = np.array(self.volume_buffer)\n",
    "        \n",
    "        vol_diff = np.diff(vols)\n",
    "        vol_diff = np.where(vol_diff < 0, 0, vol_diff)\n",
    "        \n",
    "        if np.sum(vol_diff) == 0:\n",
    "             return 1 if prices[-1] > prices[0] else 2\n",
    "        \n",
    "        trade_prices = prices[1:]\n",
    "        vwap = np.average(trade_prices, weights=vol_diff)\n",
    "        \n",
    "        if prices[-1] > vwap: \n",
    "            return 1 # LONG\n",
    "        else: \n",
    "            return 2 # SHORT\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# RSI KINETIC BRAIN\n",
    "# ==========================================\n",
    "class RSIKineticBrain:\n",
    "    def __init__(self, threshold=37500):\n",
    "        self.threshold = threshold\n",
    "        self.ke_buffer = deque(maxlen=50)\n",
    "        self.directional = FastDirectionalEngine(buffer_size=50)\n",
    "        self.rsi = TickRSI(period=RSI_PERIOD)\n",
    "        self.last_ltp = None\n",
    "        self.last_score = 0\n",
    "    \n",
    "    def tick(self, ltp, volume):\n",
    "        # 1. Update RSI\n",
    "        if self.last_ltp is not None:\n",
    "            change = ltp - self.last_ltp\n",
    "            self.rsi.update(change)\n",
    "        self.last_ltp = ltp\n",
    "        \n",
    "        # 2. Update Buffers\n",
    "        self.ke_buffer.append((ltp, volume))\n",
    "        self.directional.add_tick(ltp, volume)\n",
    "        \n",
    "        if len(self.ke_buffer) < 50:\n",
    "            return 0\n",
    "            \n",
    "        # 3. Calculate Kinetic Energy\n",
    "        arr = np.array(self.ke_buffer)\n",
    "        prices_ke = arr[:, 0]\n",
    "        vols_ke = arr[:, 1]\n",
    "        \n",
    "        v_diff = np.diff(vols_ke)\n",
    "        v_diff = np.where(v_diff < 0, 0, v_diff)\n",
    "        traded_vol = np.sum(v_diff)\n",
    "        displacement = abs(prices_ke[-1] - prices_ke[0])\n",
    "        \n",
    "        ke_score = traded_vol / (displacement + 0.05)\n",
    "        self.last_score = ke_score\n",
    "        \n",
    "        # 4. Check Signal\n",
    "        if ke_score > self.threshold:\n",
    "            raw_dir = self.directional.calculate_direction()\n",
    "            current_rsi = self.rsi.get_rsi()\n",
    "            \n",
    "            # 5. RSI VETO\n",
    "            if raw_dir == 1: \n",
    "                if current_rsi < RSI_OVERBOUGHT: return 1\n",
    "            elif raw_dir == 2: \n",
    "                if current_rsi > RSI_OVERSOLD: return 2\n",
    "            \n",
    "        return 0\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATA LOADING\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    success = download_parquet_to_path(key, local_path)\n",
    "    if not success: return None\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except: return None\n",
    "\n",
    "    df[\"DateTime\"] = pd.to_datetime(df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str), dayfirst=True, errors=\"coerce\")\n",
    "    df[\"LTP\"] = pd.to_numeric(df[\"LTP\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"DateTime\", \"LTP\"]).sort_values(\"DateTime\").reset_index(drop=True)\n",
    "    \n",
    "    if \"Volume\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns: df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else: df[\"Volume\"] = 0.0\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_day_trades(df, day_folder):\n",
    "    brain = RSIKineticBrain(threshold=KINETIC_THRESHOLD)\n",
    "    completed_trades = []\n",
    "    \n",
    "    # Active Trade State\n",
    "    in_trade = False\n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    side = None \n",
    "    highest_pnl = 0.0 # Track max floating profit\n",
    "    \n",
    "    # RISK STATE\n",
    "    daily_pnl = 0.0\n",
    "    long_pnl_today = 0.0\n",
    "    short_pnl_today = 0.0\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if daily_pnl < DAILY_MAX_LOSS: break \n",
    "            \n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "        \n",
    "        # --- TRADE MANAGEMENT ---\n",
    "        if in_trade:\n",
    "            duration = (ts - entry_time).total_seconds()\n",
    "            exit_signal = False\n",
    "            exit_reason = \"\"\n",
    "            \n",
    "            # Calculate Floating PnL\n",
    "            if side == \"LONG\":\n",
    "                float_pnl = ltp - entry_price\n",
    "            else:\n",
    "                float_pnl = entry_price - ltp\n",
    "                \n",
    "            # Update Peak PnL for Trailing\n",
    "            if float_pnl > highest_pnl:\n",
    "                highest_pnl = float_pnl\n",
    "            \n",
    "            # --- DYNAMIC STOP LOSS LOGIC ---\n",
    "            current_sl_pts = STOP_LOSS_POINTS # Default 30\n",
    "            \n",
    "            if highest_pnl >= TRAIL_TRIGGER: # Hit +50?\n",
    "                current_sl_pts = -TRAIL_LOCK # Lock +25 (SL becomes Take Profit)\n",
    "            elif highest_pnl >= BE_TRIGGER: # Hit +25?\n",
    "                current_sl_pts = -1.0 # Breakeven (+1 for fees)\n",
    "            \n",
    "            # Check Exits\n",
    "            if float_pnl <= -current_sl_pts: \n",
    "                exit_signal = True\n",
    "                if current_sl_pts < 0: exit_reason = \"TRAIL/BE\"\n",
    "                else: exit_reason = \"SL\"\n",
    "            elif float_pnl >= TAKE_PROFIT_POINTS: \n",
    "                exit_signal = True; exit_reason = \"TP\"\n",
    "            elif duration >= MAX_HOLD_SECONDS:\n",
    "                exit_signal = True; exit_reason = \"TIME\"\n",
    "                \n",
    "            if exit_signal:\n",
    "                gross_pnl = float_pnl * LOT_SIZE\n",
    "                cost = FUTURES_ROUND_TRIP_COST * LOT_SIZE\n",
    "                net_pnl = gross_pnl - cost\n",
    "                \n",
    "                daily_pnl += net_pnl\n",
    "                if side == \"LONG\": long_pnl_today += net_pnl\n",
    "                else: short_pnl_today += net_pnl\n",
    "                \n",
    "                completed_trades.append({\n",
    "                    \"Date\": ts.date(),\n",
    "                    \"Entry_Time\": entry_time,\n",
    "                    \"Side\": side,\n",
    "                    \"Net_Pts\": float_pnl - FUTURES_ROUND_TRIP_COST,\n",
    "                    \"Net_INR\": net_pnl,\n",
    "                    \"Exit_Reason\": exit_reason\n",
    "                })\n",
    "                in_trade = False\n",
    "                highest_pnl = 0.0 # Reset\n",
    "                continue \n",
    "\n",
    "        # --- SIGNAL GENERATION ---\n",
    "        if not in_trade:\n",
    "            sig = brain.tick(ltp, vol)\n",
    "            \n",
    "            if sig == 1: \n",
    "                if long_pnl_today > SIDE_MAX_LOSS: \n",
    "                    in_trade = True; entry_time = ts; entry_price = ltp; side = \"LONG\"\n",
    "            elif sig == 2: \n",
    "                if short_pnl_today > SIDE_MAX_LOSS: \n",
    "                    in_trade = True; entry_time = ts; entry_price = ltp; side = \"SHORT\"\n",
    "        else:\n",
    "            brain.tick(ltp, vol)\n",
    "\n",
    "    trades_df = pd.DataFrame(completed_trades)\n",
    "    return trades_df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "    \n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n{day:02d}/{MONTH}/{YEAR}...\", end=\" \")\n",
    "        \n",
    "        df = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"No data\")\n",
    "            continue\n",
    "        \n",
    "        trades_df = process_day_trades(df, day_folder)\n",
    "        \n",
    "        if not trades_df.empty:\n",
    "            daily_csv = os.path.join(day_folder, \"futures_results.csv\")\n",
    "            trades_df.to_csv(daily_csv, index=False)\n",
    "            \n",
    "            pnl = trades_df['Net_INR'].sum()\n",
    "            n_trades = len(trades_df)\n",
    "            sl_hits = len(trades_df[trades_df['Exit_Reason'] == 'SL'])\n",
    "            be_hits = len(trades_df[trades_df['Exit_Reason'] == 'TRAIL/BE'])\n",
    "            \n",
    "            l_pnl = trades_df[trades_df['Side']=='LONG']['Net_INR'].sum()\n",
    "            s_pnl = trades_df[trades_df['Side']=='SHORT']['Net_INR'].sum()\n",
    "            \n",
    "            print(f\"Trades: {n_trades} (SL:{sl_hits}/BE:{be_hits}) | PnL: ₹{pnl:,.0f} [L:{l_pnl:.0f} S:{s_pnl:.0f}]\")\n",
    "            if pnl < DAILY_MAX_LOSS: print(f\"   [RISK] Global Stop Hit!\")\n",
    "            \n",
    "            all_trades.append(trades_df)\n",
    "        else:\n",
    "            print(\"No trades\")\n",
    "    \n",
    "    if all_trades:\n",
    "        full_df = pd.concat(all_trades, ignore_index=True)\n",
    "        \n",
    "        total_pnl = full_df['Net_INR'].sum()\n",
    "        win_rate = (full_df['Net_Pts'] > 0).mean() * 100\n",
    "        \n",
    "        longs = full_df[full_df['Side'] == 'LONG']\n",
    "        shorts = full_df[full_df['Side'] == 'SHORT']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"HYPER-ADAPTIVE SUMMARY: {MONTH}/{YEAR}\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total Net PnL:      ₹{total_pnl:,.2f}\")\n",
    "        print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "        print(f\"Total Trades:       {len(full_df)}\")\n",
    "        print(f\"  - Longs:          {len(longs)} (₹{longs['Net_INR'].sum():,.0f})\")\n",
    "        print(f\"  - Shorts:         {len(shorts)} (₹{shorts['Net_INR'].sum():,.0f})\")\n",
    "        \n",
    "        final_csv = f\"data/nov_{YEAR}_hyper_results.csv\"\n",
    "        full_df.to_csv(final_csv, index=False)\n",
    "        print(f\"\\nResults saved: {final_csv}\")\n",
    "    else:\n",
    "        print(\"\\nNo trades for the month.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcc98114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "KINETIC DIRECTIONAL FUTURES SCALPER v2 - 11/2025\n",
      "Symbol: NIFTY, Contract: NIFTY25NOVFUT\n",
      "============================================================\n",
      "\n",
      "01/11/2025... No data\n",
      "02/11/2025... No data\n",
      "03/11/2025... No data\n",
      "04/11/2025... No trades\n",
      "05/11/2025... No data\n",
      "06/11/2025... No trades\n",
      "07/11/2025... Trades: 1 (SL:0/TP:0) | PnL: ₹-53\n",
      "08/11/2025... No data\n",
      "09/11/2025... No data\n",
      "10/11/2025... No data\n",
      "11/11/2025... No trades\n",
      "12/11/2025... No trades\n",
      "13/11/2025... No trades\n",
      "14/11/2025... No data\n",
      "15/11/2025... No data\n",
      "16/11/2025... No data\n",
      "17/11/2025... No trades\n",
      "18/11/2025... No trades\n",
      "19/11/2025... No trades\n",
      "20/11/2025... No trades\n",
      "21/11/2025... No trades\n",
      "22/11/2025... No data\n",
      "23/11/2025... No data\n",
      "24/11/2025... No trades\n",
      "25/11/2025... No trades\n",
      "26/11/2025... No data\n",
      "27/11/2025... No data\n",
      "28/11/2025... No data\n",
      "29/11/2025... No data\n",
      "30/11/2025... No data\n",
      "\n",
      "============================================================\n",
      "KINETIC DIRECTIONAL SUMMARY v2: 11/2025\n",
      "============================================================\n",
      "Total Net PnL:      ₹-52.50\n",
      "Win Rate:           0.0%\n",
      "Total Trades:       1\n",
      "  - Longs:          1 (₹-53)\n",
      "  - Shorts:         0 (₹0)\n",
      "\n",
      "Results saved: data/nov_2025_kinetic_directional_v2_results.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "AWS FUTURES SCALPER: KINETIC DIRECTIONAL BRAIN v2\n",
    "=================================================\n",
    "Logic:\n",
    "- Detect big Kinetic bursts (volume / displacement)\n",
    "- Only trade when:\n",
    "    * Strong Kinetic burst\n",
    "    * Higher-timeframe trend (regime) is clearly UP or DOWN\n",
    "    * Signed orderflow agrees with that regime\n",
    "    * Local range position confirms (breakout / breakdown zone)\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "BUCKET = \"live-market-data\"\n",
    "\n",
    "YEAR = 2025\n",
    "MONTH = 11\n",
    "SYMBOL = \"NIFTY\"\n",
    "FUT_TS = \"NIFTY25NOVFUT\"  # change if contract differs\n",
    "\n",
    "LOT_SIZE = 75\n",
    "\n",
    "# --- Kinetic / Direction Params ---\n",
    "KINETIC_THRESHOLD = 37500\n",
    "PRICE_WINDOW = 40         # for local range\n",
    "VOL_WINDOW = 40           # for KE + signed flow\n",
    "FAST_LOOKBACK = 10        # short slope\n",
    "SLOW_LOOKBACK = 30        # medium slope\n",
    "REGIME_WINDOW = 200       # higher-timeframe trend window\n",
    "MIN_VOTES = 2             # minimum directional votes\n",
    "\n",
    "SIGNED_VOL_THRESH = 0.25  # stricter orderflow bias\n",
    "REGIME_SLOPE_THRESH = 1e-5  # normalized slope threshold\n",
    "\n",
    "# --- Trade Management ---\n",
    "MAX_HOLD_SECONDS = 900\n",
    "STOP_LOSS_POINTS = 25.0\n",
    "TAKE_PROFIT_POINTS = 50.0\n",
    "\n",
    "# --- Costs & Risk ---\n",
    "FUTURES_ROUND_TRIP_COST = 1.0   # pts per round trip\n",
    "DAILY_MAX_LOSS = -3000.0        # INR\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"KINETIC DIRECTIONAL FUTURES SCALPER v2 - {MONTH}/{YEAR}\")\n",
    "print(f\"Symbol: {SYMBOL}, Contract: {FUT_TS}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# S3 UTILITIES\n",
    "# ==========================================\n",
    "def list_s3(prefix: str):\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    keys = []\n",
    "    continuation = None\n",
    "    while True:\n",
    "        kwargs = {\"Bucket\": BUCKET, \"Prefix\": prefix}\n",
    "        if continuation:\n",
    "            kwargs[\"ContinuationToken\"] = continuation\n",
    "        resp = s3.list_objects_v2(**kwargs)\n",
    "        if \"Contents\" in resp:\n",
    "            for obj in resp[\"Contents\"]:\n",
    "                keys.append(obj[\"Key\"])\n",
    "        if resp.get(\"IsTruncated\"):\n",
    "            continuation = resp.get(\"NextContinuationToken\")\n",
    "        else:\n",
    "            break\n",
    "    return keys\n",
    "\n",
    "\n",
    "def download_parquet_to_path(key: str, local_path: str):\n",
    "    if os.path.exists(local_path):\n",
    "        return True\n",
    "    s3 = boto3.client(\"s3\")\n",
    "    try:\n",
    "        obj = s3.get_object(Bucket=BUCKET, Key=key)\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            f.write(obj[\"Body\"].read())\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# KINETIC DIRECTIONAL BRAIN v2\n",
    "# ==========================================\n",
    "class KineticDirectionalBrain:\n",
    "    \"\"\"\n",
    "    tick(ltp, volume) ->\n",
    "        0  = no signal\n",
    "        +1 = LONG\n",
    "        -1 = SHORT\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kinetic_threshold=KINETIC_THRESHOLD,\n",
    "        price_window=PRICE_WINDOW,\n",
    "        vol_window=VOL_WINDOW,\n",
    "        fast_lookback=FAST_LOOKBACK,\n",
    "        slow_lookback=SLOW_LOOKBACK,\n",
    "        regime_window=REGIME_WINDOW,\n",
    "        min_votes=MIN_VOTES,\n",
    "        signed_vol_thresh=SIGNED_VOL_THRESH,\n",
    "        regime_slope_thresh=REGIME_SLOPE_THRESH,\n",
    "    ):\n",
    "        self.kinetic_threshold = kinetic_threshold\n",
    "        self.price_window = price_window\n",
    "        self.vol_window = vol_window\n",
    "        self.fast_lookback = fast_lookback\n",
    "        self.slow_lookback = slow_lookback\n",
    "        self.regime_window = regime_window\n",
    "        self.min_votes = min_votes\n",
    "        self.signed_vol_thresh = signed_vol_thresh\n",
    "        self.regime_slope_thresh = regime_slope_thresh\n",
    "\n",
    "        self.price_buf = deque(\n",
    "            maxlen=max(price_window, vol_window, regime_window)\n",
    "        )\n",
    "        self.vol_buf = deque(maxlen=vol_window)\n",
    "        self.last_ke_score = 0.0\n",
    "\n",
    "    def _lin_slope(self, arr):\n",
    "        n = len(arr)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "        x = np.arange(n, dtype=float)\n",
    "        y = np.asarray(arr, dtype=float)\n",
    "        x_mean = x.mean()\n",
    "        y_mean = y.mean()\n",
    "        num = np.sum((x - x_mean) * (y - y_mean))\n",
    "        den = np.sum((x - x_mean) ** 2) + 1e-9\n",
    "        return num / den\n",
    "\n",
    "    def tick(self, ltp, volume):\n",
    "        ltp = float(ltp)\n",
    "        volume = float(volume)\n",
    "\n",
    "        self.price_buf.append(ltp)\n",
    "        self.vol_buf.append(volume)\n",
    "\n",
    "        if (\n",
    "            len(self.vol_buf) < self.vol_window\n",
    "            or len(self.price_buf) < self.price_window\n",
    "            or len(self.price_buf) < self.regime_window\n",
    "        ):\n",
    "            return 0\n",
    "\n",
    "        prices = np.asarray(self.price_buf, dtype=float)\n",
    "        vols = np.asarray(self.vol_buf, dtype=float)\n",
    "\n",
    "        # ---------- 1) KINETIC SCORE ----------\n",
    "        vol_diff = np.diff(vols)\n",
    "        trade_vol = np.where(vol_diff > 0, vol_diff, 0.0)\n",
    "        if trade_vol.sum() <= 0:\n",
    "            return 0\n",
    "\n",
    "        displacement = abs(prices[-1] - prices[-self.vol_window])\n",
    "        ke_score = trade_vol.sum() / (displacement + 0.05)\n",
    "        self.last_ke_score = ke_score\n",
    "\n",
    "        if ke_score < self.kinetic_threshold:\n",
    "            return 0\n",
    "\n",
    "        # ---------- 2) SIGNED ORDERFLOW ----------\n",
    "        price_short = prices[-self.vol_window:]\n",
    "        dp = np.diff(price_short)\n",
    "        v = trade_vol[-len(dp):]\n",
    "        signed_vol = np.sum(np.sign(dp) * v)\n",
    "        total_trade_vol = v.sum() + 1e-9\n",
    "        signed_vol_ratio = signed_vol / total_trade_vol   # -1..+1\n",
    "\n",
    "        # If orderflow is not clearly biased, ignore\n",
    "        if abs(signed_vol_ratio) < self.signed_vol_thresh:\n",
    "            return 0\n",
    "\n",
    "        # ---------- 3) SLOPES ----------\n",
    "        fast_len = min(self.fast_lookback, len(prices))\n",
    "        slow_len = min(self.slow_lookback, len(prices))\n",
    "        regime_len = min(self.regime_window, len(prices))\n",
    "\n",
    "        fast_slice = prices[-fast_len:]\n",
    "        slow_slice = prices[-slow_len:]\n",
    "        regime_slice = prices[-regime_len:]\n",
    "\n",
    "        fast_slope = self._lin_slope(fast_slice)\n",
    "        slow_slope = self._lin_slope(slow_slice)\n",
    "        regime_slope = self._lin_slope(regime_slice)\n",
    "\n",
    "        price_scale = np.mean(regime_slice) + 1e-9\n",
    "        fast_slope_norm = fast_slope / price_scale\n",
    "        slow_slope_norm = slow_slope / price_scale\n",
    "        regime_slope_norm = regime_slope / price_scale\n",
    "\n",
    "        # ---------- 4) REGIME FILTER ----------\n",
    "        if regime_slope_norm > self.regime_slope_thresh:\n",
    "            regime = \"UP\"\n",
    "        elif regime_slope_norm < -self.regime_slope_thresh:\n",
    "            regime = \"DOWN\"\n",
    "        else:\n",
    "            return 0  # FLAT regime -> do nothing\n",
    "\n",
    "        # ---------- 5) RANGE POSITION ----------\n",
    "        window_slice = prices[-self.price_window:]\n",
    "        p_min = window_slice.min()\n",
    "        p_max = window_slice.max()\n",
    "        rng = (p_max - p_min) + 1e-9\n",
    "        range_pos = (window_slice[-1] - p_min) / rng  # 0 = low, 1 = high\n",
    "\n",
    "        # ---------- 6) VOTES ----------\n",
    "        long_votes = 0\n",
    "        short_votes = 0\n",
    "\n",
    "        # (a) Signed orderflow\n",
    "        if signed_vol_ratio > 0:\n",
    "            long_votes += 1\n",
    "        else:\n",
    "            short_votes += 1\n",
    "\n",
    "        # (b) Fast slope\n",
    "        if fast_slope_norm > 0:\n",
    "            long_votes += 1\n",
    "        elif fast_slope_norm < 0:\n",
    "            short_votes += 1\n",
    "\n",
    "        # (c) Slow slope\n",
    "        if slow_slope_norm > 0:\n",
    "            long_votes += 1\n",
    "        elif slow_slope_norm < 0:\n",
    "            short_votes += 1\n",
    "\n",
    "        # Base direction from votes\n",
    "        if long_votes >= short_votes + 1:\n",
    "            direction = +1\n",
    "            votes = long_votes\n",
    "        elif short_votes >= long_votes + 1:\n",
    "            direction = -1\n",
    "            votes = short_votes\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "        if votes < self.min_votes:\n",
    "            return 0\n",
    "\n",
    "        # ---------- 7) ALIGN WITH REGIME ----------\n",
    "        if regime == \"UP\" and direction < 0:\n",
    "            return 0\n",
    "        if regime == \"DOWN\" and direction > 0:\n",
    "            return 0\n",
    "\n",
    "        # ---------- 8) RANGE CONFIRMATION ----------\n",
    "        if regime == \"UP\":\n",
    "            if range_pos < 0.5:\n",
    "                return 0\n",
    "        else:\n",
    "            if range_pos > 0.5:\n",
    "                return 0\n",
    "\n",
    "        return direction\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DATA LOADING\n",
    "# ==========================================\n",
    "def download_futures_for_day(year, month, day, symbol, fut_ts, day_folder):\n",
    "    key = f\"year={year}/month={month:02d}/day={day:02d}/Futures/{symbol}/{fut_ts}.parquet\"\n",
    "    local_path = os.path.join(day_folder, \"FUT.parquet\")\n",
    "    ok = download_parquet_to_path(key, local_path)\n",
    "    if not ok:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(local_path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "    if \"DateTime\" not in df.columns:\n",
    "        if \"Date\" in df.columns and \"Time\" in df.columns:\n",
    "            df[\"DateTime\"] = pd.to_datetime(\n",
    "                df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str),\n",
    "                dayfirst=True,\n",
    "                errors=\"coerce\",\n",
    "            )\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    df = df.dropna(subset=[\"DateTime\"])\n",
    "    df[\"LTP\"] = pd.to_numeric(df.get(\"LTP\"), errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"LTP\"])\n",
    "\n",
    "    if \"Volume\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"Volume\"], errors=\"coerce\")\n",
    "    elif \"OpenInterest\" in df.columns:\n",
    "        df[\"Volume\"] = pd.to_numeric(df[\"OpenInterest\"], errors=\"coerce\")\n",
    "    else:\n",
    "        df[\"Volume\"] = 0.0\n",
    "\n",
    "    df = df.sort_values(\"DateTime\").reset_index(drop=True)\n",
    "\n",
    "    df = df[\n",
    "        (df[\"DateTime\"].dt.time >= datetime.time(9, 15))\n",
    "        & (df[\"DateTime\"].dt.time <= datetime.time(15, 15))\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# DAY PROCESSING\n",
    "# ==========================================\n",
    "def process_day_trades(df):\n",
    "    brain = KineticDirectionalBrain()\n",
    "\n",
    "    trades = []\n",
    "    in_trade = False\n",
    "    entry_time = None\n",
    "    entry_price = 0.0\n",
    "    side = None\n",
    "    daily_pnl = 0.0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        ts = row[\"DateTime\"]\n",
    "        ltp = float(row[\"LTP\"])\n",
    "        vol = float(row[\"Volume\"])\n",
    "\n",
    "        if daily_pnl <= DAILY_MAX_LOSS:\n",
    "            break\n",
    "\n",
    "        if in_trade:\n",
    "            duration = (ts - entry_time).total_seconds()\n",
    "            exit_signal = False\n",
    "            exit_reason = \"\"\n",
    "            pnl_pts = 0.0\n",
    "\n",
    "            if side == \"LONG\":\n",
    "                pnl_pts = ltp - entry_price\n",
    "                if pnl_pts <= -STOP_LOSS_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"SL\"\n",
    "                elif pnl_pts >= TAKE_PROFIT_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"TP\"\n",
    "            else:\n",
    "                pnl_pts = entry_price - ltp\n",
    "                if pnl_pts <= -STOP_LOSS_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"SL\"\n",
    "                elif pnl_pts >= TAKE_PROFIT_POINTS:\n",
    "                    exit_signal = True\n",
    "                    exit_reason = \"TP\"\n",
    "\n",
    "            if not exit_signal and duration >= MAX_HOLD_SECONDS:\n",
    "                exit_signal = True\n",
    "                exit_reason = \"TIME\"\n",
    "\n",
    "            if exit_signal:\n",
    "                gross_pnl_inr = pnl_pts * LOT_SIZE\n",
    "                cost_inr = FUTURES_ROUND_TRIP_COST * LOT_SIZE\n",
    "                net_inr = gross_pnl_inr - cost_inr\n",
    "                net_pts_after_cost = pnl_pts - FUTURES_ROUND_TRIP_COST\n",
    "                daily_pnl += net_inr\n",
    "\n",
    "                trades.append({\n",
    "                    \"Date\": ts.date(),\n",
    "                    \"Entry_Time\": entry_time,\n",
    "                    \"Exit_Time\": ts,\n",
    "                    \"Side\": side,\n",
    "                    \"Entry_Price\": entry_price,\n",
    "                    \"Exit_Price\": ltp,\n",
    "                    \"Raw_PnL_Pts\": pnl_pts,\n",
    "                    \"Net_Pts\": net_pts_after_cost,\n",
    "                    \"Net_INR\": net_inr,\n",
    "                    \"Exit_Reason\": exit_reason,\n",
    "                })\n",
    "\n",
    "                in_trade = False\n",
    "                side = None\n",
    "                entry_time = None\n",
    "                entry_price = 0.0\n",
    "                continue\n",
    "\n",
    "        if not in_trade:\n",
    "            sig = brain.tick(ltp, vol)\n",
    "            if sig == 1:\n",
    "                in_trade = True\n",
    "                side = \"LONG\"\n",
    "                entry_time = ts\n",
    "                entry_price = ltp\n",
    "            elif sig == -1:\n",
    "                in_trade = True\n",
    "                side = \"SHORT\"\n",
    "                entry_time = ts\n",
    "                entry_price = ltp\n",
    "        else:\n",
    "            brain.tick(ltp, vol)\n",
    "\n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN\n",
    "# ==========================================\n",
    "def main():\n",
    "    all_trades = []\n",
    "\n",
    "    for day in range(1, 31):\n",
    "        day_folder = f\"data/{YEAR}-{MONTH:02d}-{day:02d}/\"\n",
    "        os.makedirs(day_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"{day:02d}/{MONTH}/{YEAR}...\", end=\" \")\n",
    "\n",
    "        df = download_futures_for_day(YEAR, MONTH, day, SYMBOL, FUT_TS, day_folder)\n",
    "        if df is None or df.empty:\n",
    "            print(\"No data\")\n",
    "            continue\n",
    "\n",
    "        trades_df = process_day_trades(df)\n",
    "\n",
    "        if trades_df.empty:\n",
    "            print(\"No trades\")\n",
    "            continue\n",
    "\n",
    "        day_pnl = trades_df[\"Net_INR\"].sum()\n",
    "        n_trades = len(trades_df)\n",
    "        sl_hits = (trades_df[\"Exit_Reason\"] == \"SL\").sum()\n",
    "        tp_hits = (trades_df[\"Exit_Reason\"] == \"TP\").sum()\n",
    "\n",
    "        print(f\"Trades: {n_trades} (SL:{sl_hits}/TP:{tp_hits}) | PnL: ₹{day_pnl:,.0f}\")\n",
    "        if day_pnl <= DAILY_MAX_LOSS:\n",
    "            print(\"   [RISK] Daily Stop Loss Breached!\")\n",
    "\n",
    "        daily_csv = os.path.join(day_folder, \"futures_directional_v2_results.csv\")\n",
    "        trades_df.to_csv(daily_csv, index=False)\n",
    "        all_trades.append(trades_df)\n",
    "\n",
    "    if not all_trades:\n",
    "        print(\"\\nNo trades for the month.\")\n",
    "        return\n",
    "\n",
    "    full_df = pd.concat(all_trades, ignore_index=True)\n",
    "    total_pnl = full_df[\"Net_INR\"].sum()\n",
    "    win_rate = (full_df[\"Net_Pts\"] > 0).mean() * 100\n",
    "    longs = full_df[full_df[\"Side\"] == \"LONG\"]\n",
    "    shorts = full_df[full_df[\"Side\"] == \"SHORT\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"KINETIC DIRECTIONAL SUMMARY v2: {MONTH}/{YEAR}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Net PnL:      ₹{total_pnl:,.2f}\")\n",
    "    print(f\"Win Rate:           {win_rate:.1f}%\")\n",
    "    print(f\"Total Trades:       {len(full_df)}\")\n",
    "    print(f\"  - Longs:          {len(longs)} (₹{longs['Net_INR'].sum():,.0f})\")\n",
    "    print(f\"  - Shorts:         {len(shorts)} (₹{shorts['Net_INR'].sum():,.0f})\")\n",
    "\n",
    "    out_csv = f\"data/nov_{YEAR}_kinetic_directional_v2_results.csv\"\n",
    "    full_df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\nResults saved: {out_csv}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224dc594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
